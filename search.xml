<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[MySQL引擎]]></title>
    <url>%2F2019%2F05%2F06%2Fmysql%E5%BC%95%E6%93%8E%2F</url>
    <content type="text"><![CDATA[前言数据库存储引擎是数据库底层软件组织，数据库管理系统（DBMS）使用数据引擎进行创建、查询、更新和删除数据。不同的存储引擎提供不同的存储机制、索引技巧、锁定水平等功能，使用不同的存储引擎，还可以获得特定的功能。现在许多不同的数据库管理系统都支持多种不同的数据引擎。MySQL的核心就是存储引擎。 存储引擎查看MySQL给开发者提供了查询存储引擎的功能，我这里使用的是MySQL 5.1.73，查看存储引擎的命令是SHOW ENGINES，其执行结果的输出为12345678910+------------+---------+------------------------------------------------------------+--------------+------+------------+| Engine | Support | Comment | Transactions | XA | Savepoints |+------------+---------+------------------------------------------------------------+--------------+------+------------+| MRG_MYISAM | YES | Collection of identical MyISAM tables | NO | NO | NO || CSV | YES | CSV storage engine | NO | NO | NO || MyISAM | DEFAULT | Default engine as of MySQL 3.23 with great performance | NO | NO | NO || InnoDB | YES | Supports transactions, row-level locking, and foreign keys | YES | YES | YES || MEMORY | YES | Hash based, stored in memory, useful for temporary tables | NO | NO | NO |+------------+---------+------------------------------------------------------------+--------------+------+------------+5 rows in set (0.00 sec) 由上面的输出结果可以看到MySQL给用户提供了非常多的存储引擎，包括处理事务安全表的引擎和处理非事务安全表的引擎。如果要想查看数据库默认使用哪个引擎，可以通过使用命令1SHOW VARIABLES LIKE 'storage_engine'; 来查看，其输出结果如下：123456+----------------+--------+| Variable_name | Value |+----------------+--------+| storage_engine | MyISAM |+----------------+--------+1 row in set (0.00 sec) 存储引擎比较在MySQL中，不需要在整个服务器中使用同一种存储引擎，针对具体的要求，可以对每一个表使用不同的存储引擎。Support列的值表示某种引擎是否能使用：YES表示可以使用、NO表示不能使用、DEFAULT表示该引擎为当前默认的存储引擎。下面来看一下其中几种常用的引擎 InnoDBInnoDB是事务型数据库的首选引擎，支持事务安全表（ACID），支持行锁定和外键，上面的命令行输出也看到了，InnoDB是默认的MySQL引擎。InnoDB主要特性有： InnoDB给MySQL提供了具有提交、回滚和崩溃恢复能力的事务安全（ACID兼容）存储引擎。InnoDB锁定在行级并且也在SELECT语句中提供一个类似Oracle的非锁定读。这些功能增加了多用户部署和性能。在SQL查询中，可以自由地将InnoDB类型的表和其他MySQL的表类型混合起来，甚至在同一个查询中也可以混合 InnoDB是为处理巨大数据量的最大性能设计。它的CPU效率可能是任何其他基于磁盘的关系型数据库引擎所不能匹敌的 InnoDB存储引擎完全与MySQL服务器整合，InnoDB存储引擎为在主内存中缓存数据和索引而维持它自己的缓冲池。InnoDB将它的表和索引在一个逻辑表空间中，表空间可以包含数个文件（或原始磁盘文件）。这与MyISAM表不同，比如在MyISAM表中每个表被存放在分离的文件中。InnoDB表可以是任何尺寸，即使在文件尺寸被限制为2GB的操作系统上 InnoDB支持外键完整性约束，存储表中的数据时，每张表的存储都按主键顺序存放，如果没有显示在表定义时指定主键，InnoDB会为每一行生成一个6字节的ROWID，并以此作为主键 InnoDB被用在众多需要高性能的大型数据库站点上 InnoDB不创建目录，使用InnoDB时，MySQL将在数据目录下创建一个名为ibdata1的10MB大小的自动扩展数据文件，以及两个名为ib_logfile0和ib_logfile1的5MB大小的日志文件 MyISAMMyISAM基于ISAM存储引擎，并对其进行扩展。它是在Web、数据仓储和其他应用环境下最常使用的存储引擎之一。MyISAM拥有较高的插入、查询速度，但不支持事务。MyISAM主要特性有： 大文件（达到63位文件长度）在支持大文件的文件系统和操作系统上被支持 当把删除和更新及插入操作混合使用的时候，动态尺寸的行产生更少碎片。这要通过合并相邻被删除的块，以及若下一个块被删除，就扩展到下一块自动完成 每个MyISAM表最大索引数是64，这可以通过重新编译来改变。每个索引最大的列数是16 最大的键长度是1000字节，这也可以通过编译来改变，对于键长度超过250字节的情况，一个超过1024字节的键将被用上 BLOB和TEXT列可以被索引 NULL被允许在索引的列中，这个值占每个键的0~1个字节 所有数字键值以高字节优先被存储以允许一个更高的索引压缩 每个MyISAM类型的表都有一个AUTO_INCREMENT的内部列，当INSERT和UPDATE操作的时候该列被更新，同时AUTO_INCREMENT列将被刷新。所以说，MyISAM类型表的AUTO_INCREMENT列更新比InnoDB类型的AUTO_INCREMENT更快 可以把数据文件和索引文件放在不同目录 每个字符列可以有不同的字符集 有VARCHAR的表可以固定或动态记录长度 VARCHAR和CHAR列可以多达64KB 使用MyISAM引擎创建数据库，将产生3个文件。文件的名字以表名字开始，扩展名之处文件类型：frm文件存储表定义、数据文件的扩展名为.MYD（MYData）、索引文件的扩展名时.MYI（MYIndex） MEMORYMEMORY存储引擎将表中的数据存储到内存中，来查询和引用其他表数据提供快速访问。MEMORY主要特性有 MEMORY表的每个表可以有多达32个索引，每个索引16列，以及500字节的最大键长度 MEMORY存储引擎执行HASH和BTREE索引 可以在一个MEMORY表中有非唯一键值 MEMORY表使用一个固定的记录长度格式 MEMORY不支持BLOB或TEXT列 MEMORY支持AUTO_INCREMENT列和对可包含NULL值的列的索引 MEMORY表在所由客户端之间共享（就像其他任何非TEMPORARY表） MEMORY表内存被存储在内存中，内存是MEMORY表和服务器在查询处理时的空闲中，创建的内部表共享 当不再需要MEMORY表的内容时，要释放被MEMORY表使用的内存，应该执行DELETE FROM或TRUNCATE TABLE，或者删除整个表（使用DROP TABLE） 存储引擎的选择不同的存储引擎都有各自的特点，以适应不同的需求，如下图所示 如果要提供提交、回滚、崩溃恢复能力的事务安全（ACID兼容）能力，并要求实现并发控制，InnoDB是一个好的选择。如果数据表主要用来插入和查询记录，则MyISAM引擎能提供较高的处理效率。如果只是临时存放数据，数据量不大，并且不需要较高的数据安全性，可以选择将数据保存在内存中的Memory引擎，MySQL中使用该引擎作为临时表，存放查询的中间结果。如果只有INSERT和SELECT操作，可以选择Archive，Archive支持高并发的插入操作，但是本身不是事务安全的。Archive非常适合存储归档数据，如记录日志信息可以使用Archive。使用哪一种引擎需要灵活选择，一个数据库中多个表可以使用不同引擎以满足各种性能和实际需求，使用合适的存储引擎，将会提高整个数据库的性能。]]></content>
      <categories>
        <category>MySQL</category>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>MySQL</tag>
        <tag>引擎</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 微服务架构]]></title>
    <url>%2F2019%2F05%2F01%2FSpring-Cloud-%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"><![CDATA[架构图 名词解释Sleuth-链路跟踪为服务之间的调用提供链路追踪。通过Sleuth可以很清楚的了解到一个服务请求经过了哪些服务，每个服务处理花费了多长。从而让我们可以很方便的理清各微服务间的调用关系。 断路器（Hystrix）在微服务架构中，根据业务来拆分成一个个的服务，服务与服务之间可以相互调用（RPC），在Spring Cloud可以用RestTemplate+Ribbon和Feign来调用。为了保证其高可用，单个服务通常会集群部署。由于网络原因或者自身的原因，服务并不能保证100%可用，如果单个服务出现问题，调用这个服务就会出现线程阻塞，此时若有大量的请求涌入，Servlet容器的线程资源会被消耗完毕，导致服务瘫痪。服务与服务之间的依赖性，故障会传播，会对整个微服务系统造成灾难性的严重后果，这就是服务故障的“雪崩”效应。Netflix开源了Hystrix组件，实现了断路器模式，SpringCloud对这一组件进行了整合。 Turbine集群监控Turbine 是聚合服务器发送事件流数据的一个工具，用来监控集群下 hystrix 的 metrics 情况；通过turbine可以监控集群的请求量，可以知道系统的请求高峰期，从而更好的知道系统的短板在哪里。 Consul服务治理 和Eureka服务治理由于Spring Cloud为服务治理做了一层抽象接口，所以在Spring Cloud应用中可以支持多种不同的服务治理框架，比如：Netflix Eureka、Consul、Zookeeper。Spring Cloud Consul项目是针对Consul的服务治理实现。Consul是一个分布式高可用的系统，它包含多个组件，但是作为一个整体，在微服务架构中为我们的基础设施提供服务发现和服务配置的工具。它包含了下面几个特性： 服务发现、 健康检查、 Key/Value存储、 多数据中心。由于Consul自身提供了服务端，所以我们不需要像之前实现Eureka的时候创建服务注册中心，直接通过下载consul的服务端程序就可以使用。Consul比Eureka注册支持的更多一些。 config配置管理引入spring cloud config后，我们的外部配置文件就可以集中放置在一个git仓库里，再新建一个config server，用来管理所有的配置文件，维护的时候需要更改配置时，只需要在本地更改后，推送到远程仓库，所有的服务实例都可以通过config server来获取配置文件，这时每个服务实例就相当于配置服务的客户端config client,为了保证系统的稳定，配置服务端config server可以进行集群部署。 Nginx用来做反向代理、负载均衡，当有请求的时候，根据配置的调度策略（加权轮询、IP哈希、最少连接数、一致性哈希）给请求者返回相应的服务器IP。 Zuul服务网关zuul的核心是一系列的filters, 其作用可以类比Servlet框架的Filter；Zuul的主要功能是路由和过滤器。是各种服务的统一入口，同时还会用来提供监控、授权、安全、调度等等；可以通过扩展ZuulFilter，在执行方法之前，做各种检查工作。 Spring Cloud项目简介 spring Cloud是基于Spring Boot的一整套实现微服务的框架。他提供了微服务开发所需的配置管理、服务发现、断路器、智能路由、微代理、控制总线、全局锁、决策竞选、分布式会话和集群状态管理等组件。最重要的是，跟spring boot框架一起使用的话，会让你开发微服务架构的云服务非常好的方便。SpringBoot旨在简化创建产品级的 Spring 应用和服务，简化了配置文件，使用嵌入式web服务器，含有诸多开箱即用微服务功能。Spring Cloud子项目包括： Spring Cloud Config配置管理开发工具包，可以让你把配置放到远程服务器，目前支持本地存储、Git以及Subversion。 Spring Cloud Bus事件、消息总线，用于在集群（例如，配置变化事件）中传播状态变化，可与Spring Cloud Config联合实现热部署。 Spring Cloud Netflix针对多种Netflix组件提供的开发工具包，其中包括Eureka、Hystrix、Zuul、Archaius等。 Netflix Eureka云端负载均衡，一个基于 REST 的服务，用于定位服务，以实现云端的负载均衡和中间层服务器的故障转移。 Netflix Hystrix容错管理工具，旨在通过控制服务和第三方库的节点,从而对延迟和故障提供更强大的容错能力。 Netflix Zuul边缘服务工具，是提供动态路由，监控，弹性，安全等的边缘服务。 Netflix Archaius配置管理API，包含一系列配置管理API，提供动态类型化属性、线程安全配置操作、轮询框架、回调机制等功能。 Spring Cloud for Cloud Foundry通过Oauth2协议绑定服务到Cloud Foundry，Cloud Foundry是VMware推出的开源PaaS云平台 Spring Cloud Sleuth日志收集工具包，封装了Dapper,Zipkin和HTrace操作。 Spring Cloud Data Flow大数据操作工具，通过命令行方式操作数据流 Spring Cloud Security安全工具包，为你的应用程序添加安全控制，主要是指OAuth2 Spring Cloud Consul封装了Consul操作，consul是一个服务发现与配置工具，与Docker容器可以无缝集成。 Spring Cloud Zookeeper操作Zookeeper的工具包，用于使用zookeeper方式的服务注册和发现。 Spring Cloud Stream数据流操作开发包，封装了与Redis,Rabbit、Kafka等发送接收消息。 Spring Cloud CLI基于 Spring Boot CLI，可以让你以命令行方式快速建立云组件。]]></content>
      <categories>
        <category>微服务</category>
        <category>Spring Cloud</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
        <tag>Spring Cloud</tag>
        <tag>微服务</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot && Spring Cloud]]></title>
    <url>%2F2019%2F04%2F27%2FSpring-Boot-Spring-Cloud%2F</url>
    <content type="text"><![CDATA[简介Spring Boot先于Spring Cloud问世，Spring Boot相当于脚手架，借助它可以快速搭建“房子”，它本身不具备任何功能属性，只是普通房间，没有任何其它功能。 什么是Spring BootSpring Boot简化了基于Spring的应用开发，通过少量的代码就能创建一个独立的、产品级别的Spring应用。Spring Boot为Spring平台及第三方库提供开箱即用的设置，这样你就可以有条不紊的开始；大多数的Spring Boot应用仅仅只需要少量的Spring配置。Spring Boot是由Pivotal团队提供的全新框架，其设计目的是用来简化Spring应用的初始搭建及开发工程。该框架采用了特定的方式进行配置，从而使开发人员不再需要定义样板化的配置。换句话来说，你也可以将Spring Boot理解成并不是什么新的框架，它默认配置了很多框架的使用方式，就像maven整合了所有的jar包，Spring Boot整合了所有的框架。Spring Boot的核心思想就是约定大于配置，一切自动完成。采用Spring Boot可以大大的简化你的开发模式，所有你想集成的常用框架，它都有对应的组建支持。 什么是Spring CloudSpring Cloud是一系列框架的有序集合。它利用Spring Boot的开发便利性巧妙滴简化了分布式系统基础设施的开发，如服务发现注册、配置中心、消息总线、负载均更、断路器、数据监控等，都可以用Spring Boot的开发风格做到一键启动和部署。Spring并未重复制造轮子，它只是将目前各家公司开发的比较成熟、经得起实际考验的服务框架组合起来，通过Spring Boot风格进行再封装屏蔽掉负责的配置和实现原理，最终给开发者留出了一套简单易懂、容易部署和维护的分布式系统开发工具包。微服务是可以独立部署、水平扩展、独立访问的服务单元，Spring Cloud就是这些微服务的大管家；采用微服务这种架构之后，项目的数量会变得非常多，Spring Cloud做为大管家就需要提供各种方案来维护整个生态。Spring Cloud本身并不会提供具体功能性的操作，它更专注于服务之间的通讯、熔断、监控等。因此需要很多的组建来完成只一套功能的支持。 总结Spring Boot和Spring cloud的关系如下：Spring Boot是Spring的一套快速配置脚手架，可以基于Spring Boot快速开发单个微服务，Spring Cloud是一个基于Spring Boot实现的云应用开发工具；Spring Boot专注于快速、方便集成的单个微服务个体，Spring Cloud关注全局的服务治理框架；Spring Boot是用了默认大于配置的理念，很多集成方案已经提前帮你选择好了，能不自己配置就不要自己配置，Spring Cloud很大的一部分是基于Spring Boot来实现的。Spring Boot可以脱离开Spring Cloud独立使用来开发项目，但是Spring Cloud则不能离开Spring Boot，属于依赖的关系。]]></content>
      <categories>
        <category>微服务</category>
        <category>Spring Cloud</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
        <tag>Spring Cloud</tag>
        <tag>微服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高性能服务器上进行JVM调优]]></title>
    <url>%2F2019%2F04%2F26%2F%E9%AB%98%E6%80%A7%E8%83%BD%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E8%BF%9B%E8%A1%8CJVM%E8%B0%83%E4%BC%98%2F</url>
    <content type="text"><![CDATA[本文介绍的是如何在高性能即高配置的服务器上进行JVM优化，为了充分利用高性能服务器的硬件资源，可以采用以下措施进行优化 采用64位操作系统，并为JVM分配大内存如果JVM中堆内存太小，就会频繁地发生垃圾回收，而垃圾回收都会伴随不同程度的程序停顿，因此如果扩大堆内存的话就可以减少垃圾回收的频率，从而避免程序的停顿。因此首先想到的就是扩大内存容量。而32位的操作系统理论上支持的最大内存只有4G，但是64位的操作系统最大却可以支持到128G的内存；综上所述我们可以使用64位的操作系统和64位的JVM，并为JVM分配更大的堆内存。但“幸福的烦恼”也随之而来。堆内存变大后，固然垃圾收集的频率减少了，但每次垃圾回收的时间将会变长。如果堆内存为14G，那么每次Full GC的时间将长达数十秒。如果Full GC频繁发生，那么对于任何一个网站或者程序来说都是是无法忍受的。因此，对于使用大内存的程序来说，一定要减少Full GC的频率，如果每天只有一两次Full GC，而且发生在低峰时间段内， 那完全可以接受。 减少Full GC 频率为了减少Full GC的频率则需要尽量避免太多对象进入到老年代，有下列做法可以参考： 确保对象都是“朝生夕死”的一个对象使用完后应尽快让他失效，然后尽快在新生代中被Minor GC回收掉，尽量避免对象在新生代中停留太长时间。 提高大对象直接进入老年代的门槛通过设置参数-XX:PretrnureSizeThreshold来提高大对象的门槛，尽量让对象都先进入新生代，然后尽快被Minor GC回收掉，而不要直接进入老年代。 避免大对象大对象对于JVM来说是个噩耗。如果对象过大，当前新生代的剩余空间装不下它，那么就需要使用分配担保机制，将当前新生代的对象都复制到老年代中，给大对象腾出空间，分配担保涉及到大量的复制，因此效率很低。如果将大对象直接放入老年代，虽然避免了分配担保过程，但该对象只有当Full GC时才能被回收，而Full GC的代价是高昂的。如果大对象过多时，老年代很快就装满了，这时就需要进行Full GC，如果Full GC频率过高，程序就会变得很卡。对于大对象可以参考一下几种处理方法 在写程序的时候尽量避免大对象从源头降低大对象的出现，尽量选择空间利用率较高的数据结构存储。 尽量缩短大对象的有效时间对象用完后尽快让它失效，好让垃圾收集器尽快将他回收，避免因在新生代呆的时间过长而进入老年代。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java垃圾回收(GC)机制]]></title>
    <url>%2F2019%2F04%2F25%2Fjava%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6-GC-%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[引言Java与其它语言（c/c++）对比来说，创建一个对象且使用后，不用再显式的delete/free，且能在一定程度上保证系统内存资源的及时回收，这些都要要归功于于Java特有的的垃圾回收机制（Garbage Collection，GC），但也正是因为有垃圾回收机制的存在，一旦系统内存发生泄漏或溢出时，排查问题比较困难，因此Java程序猿深入理解Java虚拟机GC机制就变得非常重要。要掌握Java GC机制，首先需要搞清楚以下几个问题： 运行时有哪些内存区域？ 运行时怎么给类、对象分配内存？ 哪些区域的内存需要回收？ 内存中的哪些对象可以回收？ 如何回收？ JVM 运行时有哪些内存区域?根据Java虚拟机的规范规定，虚拟机所管理的运行时内存分为以下区域 程序计数器每一条Java线程都有一个独立的程序计数器，我们把线程相互独立隔离的区域叫线程私有的，它的作用可以看作是当前线程所执行的字节码的行号指示器，它是一块较小的空间区域，如果执行的是Java方法，这个计数器记录的是正在执行的虚拟机字节码的指令地址，如果是native的方法，这个计数器的值为空（undefined） Java虚拟机栈Java虚拟机栈与程序计数器一样，也是线程私有的；Java虚拟机栈描述的是Java方法执行的内存模型，每个方法被执行的时候都会同时创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态链路、方法出口等信息。每一个方法从被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。 本地方法栈本地方法栈和虚拟机栈作用非常相似，不同的是Java虚拟机栈是为执行的是Java方法服务的，而本地方法栈是为native的方法执行服务的。 Java堆Java堆（heap）是Java虚拟机所管理的内存中最大的一块。Java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例以及数组都要在堆上分配内存。在堆上的内存是分代管理的，分为新生代和老年代，新生代又细分为：Eden，From Survivor，To Survivor，它们空间大小比例为8:1:1。 方法区方法区与Java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然Java虚拟机规范把方法区描述为堆得一个逻辑部分，但是它却有一个别名叫Non-Heap（非堆），目的应该是与Java堆区分开来，也称“永久代”（Permanent Generation）。hotspot虚拟机永久代已经完全在JDK 8移除，用Native Memory来的实现，命名为metaSpace， 运行时常量池运行时常量池是方法区的一部分。用于存放编译期生成的各种字面量和符号引用。 JVM 运行时怎么给类、对象分配内存?根据上面的JVM运行时数据区域的划分可以知道，几乎所有的对象都在堆上分配，而类信息、常量、静态变量在方法区分配。堆内存是分代管理的，对象优先在Eden分配；大对象（所谓的大对象是指需要连续内存空间的Java对象，如很长的字符串或者数组）直接进入老年代；长期存活的对象将进入老年代，在垃圾回收时在Survivor中每熬过一次youngGC，他的年龄就增加1，直到到达指定的年龄就会被放入老年代。 JVM 哪些区域的内存需要回收?根据JVM运行时数据区域的各个部分，程序计数器、虚拟机栈、本地方法栈三个区域随着线程而生，随线程灭而灭。栈中的栈帧随着方法的进入和退出而进栈出栈。每个栈帧分配多少内存在类结构确定下来的时候就基本已经确定。所以这个三个区域内存回收时方法或者线程结束而回收的，不需要太多关注；而Java堆和方法区则不一样，一个接口不同实现类，一个方法中不同的分支，在具体运行的时候才能确定创建那些对象，所以这部分内存是动态的，也是需要垃圾回收机制来回收处理的。 JVM 内存中的哪些对象可以回收？堆内存判断堆内的对象是否可以回收，需要判断这个对象实例是否确实没用，判断算法有两种：引用计数法和根搜索算法。 引用计数法 就是给每个对象加一个计数器，如果有一个地方引用就加1，当引用失效就减1；当计数器为0，则认为对象是无用的。这种算法最大的问题在于不能解决相互引用的对象，如：A.b=B;B.a=A，在没有其他引用的情况下，应该回收；但按照引用计数法来计算，他们的引用都不为0，显然不能回收。 根搜索算法 这个算法的思路是通过一系列名为“GC Roots”的对象作为起点，从这个节点向下搜索，搜索所经过的路径称为引用链（Reference Chain），当一个对象到GC Roots没有任何引用链相连时，则证明该对象不可用。 Java等一大部分商用语言是用根搜索算法来管理内存的，Java中可以做为GC Roots的对象有如下几种： 虚拟机栈（栈帧中的本地变量表）中的引用的对象 方法区中的类静态属性引用的对象 方法区中常量引用的对象 本地方法栈JNI(Native)的引用对象 方法区方法区回收主要有两部分：废弃的常量和无用的类。废弃的常量判断方法和堆中的对象类似，只要判断没有地方引用就可以回收。相比之下，判断一个类是否无用，条件就比较苛刻，需要同时满足以下3个条件才能算是“无用的类”： 该类的所有实例都已经被回收，也就是Java堆中不存在该类的任何实例 加载该类的ClassLoader已经被回收 该类对应的Java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法虚拟机可以对于满足上面三个条件的无用类进行回收，仅仅是可以回收，具体能否回收，JVM提供了-Xnoclassgc参数进行控制。 JVM 如何回收？JVM gc有多种算法，根据不同的算法实现了不同的垃圾回收器，每种收集器可以在不同的应用场景使用。 回收算法 标记-清除（Mark-Sweep）算法如它的名字一样，算法分“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收掉被标记的对象。该方法主要有两个缺点：一个是效率问题，标记和清除效率都不高；另一个是空间问题：标记清除后会产生大量空间碎片。 复制（Copying）算法该算法将内存按容量分成大小相等的两块，每次只用一块，当这一块内存用完后，就将可用的对象复制到另外一块上面，然后一次性清除已用过那块的内存空间。优点是实现简单，运行效率高，缺点是内存缩小为原来的一半。 标记整理（Mark-Compact）算法该算法仍然与标记-清除算法一样，第一步标记，第二步不是对无用对象清理，而是，让所有可用对象都向一端移动，然后直接清理掉端边界以外的内存。标记整理算法的优点是不会产生空间碎片。 分代收集（Generation Collection）算法分代收集算法根据对象存活周期的不同将内存划为几块，一般把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最合适的收集算法。在新生代中，每次垃圾回收时都发现大批对象死去，只有少量存活，那就选用复制算法，付出少量复制成本就可以完成收集。而老年代中对象存活率较高且没有空间进行担保，就必须使用“标记-清除”或者“标记-整理”算法。垃圾回收器垃圾回收器是垃圾回收算法的具体实现，一般不同的厂商或者不同版本的虚拟机都包含不同的垃圾收集器，并且一般会提供参数供用户选择在不用业务场景下组合出各个年代所使用的收集器。 Serial(串行GC)收集器Serial收集器是一个新生代收集器，单线程执行，使用复制算法。它在进行垃圾收集时，必须暂停其他所有的工作线程(用户线程)。是Jvm client模式下默认的新生代收集器。对于限定单个CPU的环境来说，Serial收集器由于没有线程交互的开销，专心做垃圾收集自然可以获得最高的单线程收集效率。 ParNew(并行GC)收集器ParNew收集器其实就是Serial收集器的多线程版本，除了使用多条线程进行垃圾收集之外，其余行为与Serial收集器一样。 Parallel Scavenge(并行回收GC)收集器Parallel Scavenge收集器也是一个新生代收集器，它也是使用复制算法的收集器，又是并行多线程收集器。Parallel Scavenge收集器的特点是它的关注点与其他收集器不同，CMS等收集器的关注点是尽可能地缩短垃圾收集时用户线程的停顿时间，而Parallel Scavenge收集器的目标则是达到一个可控制的吞吐量。吞吐量 = 程序运行时间/(程序运行时间 + 垃圾收集时间)，虚拟机总共运行了100分钟。其中垃圾收集花掉1分钟，那吞吐量就是99%。 Serial Old(串行GC)收集器Serial Old是Serial收集器的老年代版本，它同样使用一个单线程执行收集，使用“标记-整理”算法。主要使用在Client模式下的虚拟机。 Parallel Old(并行GC)收集器Parallel Old 是Parallel Scavenge收集器的老年代版本，使用多线程和“标记-整理”算法。 CMS(并发GC)收集器CMS(Concurrent Mark Sweep)收集器是一种以获取最短回收停顿时间为目标的收集器。CMS收集器是基于“标记-清除”算法实现的，整个收集过程大致分为4个步骤：①.初始标记(CMS initial mark)；②.并发标记(CMS concurrenr mark)；③.重新标记(CMS remark)；④.并发清除(CMS concurrent sweep)。 其中初始标记、重新标记这两个步骤任然需要停顿其他用户线程。初始标记仅仅只是标记出GC ROOTS能直接关联到的对象，速度很快，并发标记阶段是进行GC ROOTS 根搜索算法阶段，会判定对象是否存活。而重新标记阶段则是为了修正并发标记期间，因用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间会被初始标记阶段稍长，但比并发标记阶段要短。由于整个过程中耗时最长的并发标记和并发清除过程中，收集器线程都可以与用户线程一起工作，所以整体来说，CMS收集器的内存回收过程是与用户线程一起并发执行的。CMS收集器的优点：并发收集、低停顿，但是CMS还远远达不到完美，器主要有三个显著缺点： CMS收集器对CPU资源非常敏感。在并发阶段，虽然不会导致用户线程停顿，但是会占用CPU资源而导致引用程序变慢，总吞吐量下降。CMS默认启动的回收线程数是：(CPU数量+3) / 4。 CMS收集器无法处理浮动垃圾，可能出现“Concurrent Mode Failure“，失败后而导致另一次Full GC的产生。由于CMS并发清理阶段用户线程还在运行，伴随程序的运行自热会有新的垃圾不断产生，这一部分垃圾出现在标记过程之后，CMS无法在本次收集中处理它们，只好留待下一次GC时将其清理掉。这一部分垃圾称为“浮动垃圾”。也是由于在垃圾收集阶段用户线程还需要运行，即需要预留足够的内存空间给用户线程使用，因此CMS收集器不能像其他收集器那样等到老年代几乎完全被填满了再进行收集，需要预留一部分内存空间提供并发收集时的程序运作使用。在默认设置下，CMS收集器在老年代使用了68%的空间时就会被激活，也可以通过参数-XX:CMSInitiatingOccupancyFraction的值来提供触发百分比，以降低内存回收次数提高性能。要是CMS运行期间预留的内存无法满足程序其他线程需要，就会出现“Concurrent Mode Failure”失败，这时候虚拟机将启动后备预案：临时启用Serial Old收集器来重新进行老年代的垃圾收集，这样停顿时间就很长了。所以说参数-XX:CMSInitiatingOccupancyFraction设置的过高将会很容易导致“Concurrent Mode Failure”失败，性能反而降低。 CMS是基于“标记-清除”算法实现的收集器，使用“标记-清除”算法收集后，会产生大量碎片。空间碎片太多时，将会给对象分配带来很多麻烦，比如说大对象，内存空间找不到连续的空间来分配不得不提前触发一次Full GC。为了解决这个问题，CMS收集器提供了一个-XX:UseCMSCompactAtFullCollection开关参数，用于在Full GC之后增加一个碎片整理过程，还可通过-XX:CMSFullGCBeforeCompaction参数设置执行多少次不压缩的Full GC之后，跟着来一次碎片整理过程。 G1收集器在G1中，堆被划分成 许多个连续的区域(region)。每个区域大小相等，在1M~32M之间。JVM最多支持2000个区域，可推算G1能支持的最大内存为2000*32M=62.5G。区域(region)的大小在JVM初始化的时候决定，也可以用-XX:G1HeapReginSize设置。在G1中没有物理上的Yong(Eden/Survivor)/Old Generation，它们是逻辑的，使用一些非连续的区域(Region)组成的。 垃圾收集（Garbage Collection）新生代的GC叫YongGC，也叫MinorGC，指发生在新生代的垃圾回收动作，因为Java具备朝生夕灭特性，所以YongGC非常频繁，一般回收集比较快；老年代GC叫FullGC，也叫Major GC，一般都伴有YongGC，GC的速度一般比YongGC慢10倍以上。目前虚拟机实现都是分代收集(G1物理上是不连续的，是逻辑分代，这里主要以jdk1.7之前为例)，当要给对象分配空间时，在Eden上分配空间，如果空间不够，则触发一次YongGC，如果空间够，则分配空间，如果还不够则直接进入老年代；当一次YongGC后，从Eden，From Survivor的对象放入To Survivor，如果放不下，则进入老年代；每次Yong GC 后还留在Survivor中的对象，对象的年龄Age加1，达到一定年龄（默认为15，可用参数-XX:MaxTenuringThreshold设置）后自动进入老年代；在发生Yong GC时，虚拟机会检测之前每次晋升到老年代的平均大小是否大于老年代的剩余空间大小，如果大于，则改为直接进行一次Full GC。如果小于则看HandlePromotionFailure设置是否允许担保失败，如果允许，那只会进行Minor GC；如果不允许，则也要改为进行一次Full GC。 总结Java GC主要主要指Java堆和方法区的对象回收，哪些对象可以回收是通过根搜索算法来判断的，在堆中是分代收集的，怎么回收是由具体的垃圾收集器来完成的，在不同的应用场景下，开发者可以选择不同的收集器来满足业务需求，达到最佳性能。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>full gc</tag>
        <tag>jvm</tag>
        <tag>虚拟机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高并发秒发系统]]></title>
    <url>%2F2019%2F04%2F25%2F%E9%AB%98%E5%B9%B6%E5%8F%91%E7%A7%92%E5%8F%91%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[在每年的双十一、618等促销活动中，淘宝、京东等电商平台都会推出众多的秒杀活动，作为一个开发人员都会有一个疑问“这些秒杀活动是如何设计及支持如此大量的瞬时请求的”？ 秒杀活动的特点 秒杀业务简单，卖家查询，买家下订单减库存 秒杀时网站访问流量激增，出现峰值 访问请求数量远大于实际需求量 秒杀系统设计方案概述 一个秒杀系统从前到后，依次有： 前端浏览器秒杀页面 ---&gt; 中间代理服务 ---&gt; 后端服务层 ---&gt; 数据库层根据上面这个流程，一般优化设计思路：将请求拦截在系统上游，降低下游压力。在一个并发量大，实际需求小的系统中，应当尽量在前端拦截无效流量，降低下游服务器和数据库的压力，不然很可能造成数据库读写锁冲突，甚至导致死锁，最终请求超时。设计思路与优化点： 限流：屏蔽掉无用的流量，允许少部分流量流向后端。 削峰：瞬时大流量峰值容易压垮系统，解决这个问题是重中之重。常用的消峰方法有异步处理、缓存和消息中间件等技术。 异步处理：秒杀系统是一个高并发系统，采用异步处理模式可以极大地提高系统并发量，其实异步处理就是削峰的一种实现方式。 内存缓存：秒杀系统最大的瓶颈一般都是数据库读写，由于数据库读写属于磁盘IO，性能很低，如果能够把部分数据或业务逻辑转移到内存缓存，效率会有极大地提升。 可拓展：当然如果我们想支持更多用户，更大的并发，最好就将系统设计成弹性可拓展的，如果流量来了，拓展机器就好了。像淘宝、京东等双十一活动时会增加大量机器应对交易高峰。 消息队列：消息队列可以削峰，将拦截大量并发请求，这也是一个异步处理过程，后台业务根据自己的处理能力，从消息队列中主动的拉取请求消息进行业务处理。 充分利用缓存：利用缓存可极大提高系统读写速度。 详细方案前端方案 静态资源缓存：将活动页面上的所有可以静态的元素全部静态化，尽量减少动态元素；通过CDN缓存静态资源，来抗峰值。 禁止重复提交：用户提交之后按钮置灰，禁止重复提交 用户限流：在某一时间段内只允许用户提交一次请求，比如可以采取IP限流 中间代理层可利用负载均衡（例如反响代理Nginx等）使用多个服务器并发处理请求，减小服务器压力。 后端方案控制层(网关层)限制同一UserID访问频率：尽量拦截浏览器请求，但针对某些恶意攻击或其它插件，在服务端控制层需要针对同一个访问uid，限制访问频率。 服务层当用户量非常大的时候，拦截流量后的请求访问量还是非常大，此时仍需进一步优化。 业务分离:将秒杀业务系统和其他业务分离，单独放在高配服务器上，可以集中资源对访问请求抗压。 采用消息队列缓存请求：将大流量请求写到消息队列缓存，利用服务器根据自己的处理能力主动到消息缓存队列中抓取任务处理请求，数据库层订阅消息减库存，减库存成功的请求返回秒杀成功，失败的返回秒杀结束。 利用缓存应对读请求：对于读多写少业务，大部分请求是查询请求，所以可以读写分离，利用缓存分担数据库压力。 利用缓存应对写请求：缓存也是可以应对写请求的，可把数据库中的库存数据转移到Redis缓存中，所有减库存操作都在Redis中进行，然后再通过后台进程把Redis中的用户秒杀请求同步到数据库中。 数据库层 数据库层是最脆弱的一层，一般在应用设计时在上游就需要把请求拦截掉，数据库层只承担“能力范围内”的访问请求。所以，上面通过在服务层引入队列和缓存，让最底层的数据库高枕无忧。如果不使用缓存来作为中间缓冲而是直接访问数据库的话，可以对数据库进行优化，减少数据库压力。 对于秒杀系统，直接访问数据库的话，存在一个【事务竞争优化】问题，可使用存储过程（或者触发器）等技术绑定操作，整个事务在MySQL端完成，把整个热点执行放在一个过程当中一次性完成，可以屏蔽掉网络延迟时间，减少行级锁持有时间，提高事务并发访问速度。]]></content>
      <tags>
        <tag>并发</tag>
        <tag>秒杀</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sentinel 与 Hystrix 的对比]]></title>
    <url>%2F2019%2F04%2F24%2FSentinel-%E4%B8%8E-Hystrix-%E7%9A%84%E5%AF%B9%E6%AF%94%2F</url>
    <content type="text"><![CDATA[Sentinel 是阿里中间件团队开源的，面向分布式服务架构的轻量级高可用流量控制组件，主要以流量为切入点，从流量控制、熔断降级、系统负载保护等多个维度来帮助用户保护服务的稳定性。大家可能会问：Sentinel 和之前常用的熔断降级库 Netflix Hystrix 有什么异同呢？本文将从多个角度对 Sentinel 和 Hystrix 进行对比，帮助大家进行技术选型。 综述HystrixHystrix的官方介绍 Hystrix is a library that helps you control the interactions between these distributed services by adding latency tolerance and fault tolerance logic. Hystrix does this by isolating points of access between the services, stopping cascading failures across them, and providing fallback options, all of which improve your system’s overall resiliency. 由上可以看到 Hystrix 的关注点在于以 隔离 和 熔断 为主的容错机制，超时或被熔断的调用将会快速失败，并可以提供 fallback 机制。 SentinelSentinel 的侧重点在于： 多样化的流量控制 熔断降级 系统负载保护 实时监控和控制台 共同特性资源模型和执行模型上的对比 Hystrix 的资源模型设计上采用了命令模式，将对外部资源的调用和 fallback 逻辑封装成一个命令对象（HystrixCommand / HystrixObservableCommand），其底层的执行是基于 RxJava 实现的。每个 Command 创建时都要指定 commandKey 和 groupKey（用于区分资源）以及对应的隔离策略（线程池隔离 or 信号量隔离）。线程池隔离模式下需要配置线程池对应的参数（线程池名称、容量、排队超时等），然后 Command 就会在指定的线程池按照指定的容错策略执行；信号量隔离模式下需要配置最大并发数，执行 Command 时 Hystrix 就会限制其并发调用。 Sentinel 的设计则更为简单。相比 Hystrix Command 强依赖隔离规则，Sentinel 的资源定义与规则配置的耦合度更低。Hystrix 的 Command 强依赖于隔离规则配置的原因是隔离规则会直接影响 Command 的执行。在执行的时候 Hystrix 会解析 Command 的隔离规则来创建 RxJava Scheduler 并在其上调度执行，若是线程池模式则 Scheduler 底层的线程池为配置的线程池，若是信号量模式则简单包装成当前线程执行的 Scheduler。而 Sentinel 并不指定执行模型，也不关注应用是如何执行的。Sentinel 的原则非常简单：根据对应资源配置的规则来为资源执行相应的限流/降级/负载保护策略。在 Sentinel 中资源定义和规则配置是分离的。用户先通过 Sentinel API 给对应的业务逻辑定义资源（埋点），然后可以在需要的时候配置规则。埋点方式有两种： try-catch 方式（通过 SphU.entry(…)），用户在 catch 块中执行异常处理 / fallback if-else 方式（通过 SphO.entry(…)），当返回 false 时执行异常处理 / fallback从 0.1.1 版本开始，Sentinel 还支持基于注解的资源定义方式，可以通过注解参数指定异常处理函数和 fallback 函数。从 0.2.0 版本开始，Sentinel 引入异步调用链路支持，可以方便地统计异步调用资源的数据，维护异步调用链路，同时具备了适配异步框架/库的能力。可以参考 相关文档。Sentinel 提供多样化的规则配置方式。除了直接通过 loadRules API 将规则注册到内存态之外，用户还可以注册各种外部数据源来提供动态的规则。用户可以根据系统当前的实时情况去动态地变更规则配置，数据源会将变更推送至 Sentinel 并即时生效。 隔离设计上的对比隔离是 Hystrix 的核心功能之一。Hystrix 提供两种隔离策略：线程池隔离（Bulkhead Pattern）和信号量隔离，其中最推荐也是最常用的是线程池隔离。Hystrix 的线程池隔离针对不同的资源分别创建不同的线程池，不同服务调用都发生在不同的线程池中，在线程池排队、超时等阻塞情况时可以快速失败，并可以提供 fallback 机制。线程池隔离的好处是隔离度比较高，可以针对某个资源的线程池去进行处理而不影响其它资源，但是代价就是线程上下文切换的 overhead 比较大，特别是对低延时的调用有比较大的影响。但是，实际情况下，线程池隔离并没有带来非常多的好处。首先就是过多的线程池会非常影响性能。考虑这样一个场景，在 Tomcat 之类的 Servlet 容器使用 Hystrix，本身 Tomcat 自身的线程数目就非常多了（可能到几十或一百多），如果加上 Hystrix 为各个资源创建的线程池，总共线程数目会非常多（几百个线程），这样上下文切换会有非常大的损耗。另外，线程池模式比较彻底的隔离性使得 Hystrix 可以针对不同资源线程池的排队、超时情况分别进行处理，但这其实是超时熔断和流量控制要解决的问题，如果组件具备了超时熔断和流量控制的能力，线程池隔离就显得没有那么必要了。Hystrix 的信号量隔离限制对某个资源调用的并发数。这样的隔离非常轻量级，仅限制对某个资源调用的并发数，而不是显式地去创建线程池，所以 overhead 比较小，但是效果不错，也支持超时失败。Sentinel 可以通过并发线程数模式的流量控制来提供信号量隔离的功能。并且结合基于响应时间的熔断降级模式，可以在不稳定资源的平均响应时间比较高的时候自动降级，防止过多的慢调用占满并发数，影响整个系统。 熔断降级对比Sentinel 和 Hystrix 的熔断降级功能本质上都是基于熔断器模式（Circuit Breaker Pattern）。Sentinel 与 Hystrix 都支持基于失败比率（异常比率）的熔断降级，在调用达到一定量级并且失败比率达到设定的阈值时自动进行熔断，此时所有对该资源的调用都会被 block，直到过了指定的时间窗口后才启发性地恢复。上面提到过，Sentinel 还支持基于平均响应时间的熔断降级，可以在服务响应时间持续飙高的时候自动熔断，拒绝掉更多的请求，直到一段时间后才恢复。这样可以防止调用非常慢造成级联阻塞的情况。 实时指标统计实现对比Hystrix 和 Sentinel 的实时指标数据统计实现都是基于滑动窗口的。Hystrix 1.5 之前的版本是通过环形数组实现的滑动窗口，通过锁配合 CAS 的操作对每个桶的统计信息进行更新。Hystrix 1.5 开始对实时指标统计的实现进行了重构，将指标统计数据结构抽象成了响应式流（reactive stream）的形式，方便消费者去利用指标信息。同时底层改造成了基于 RxJava 的事件驱动模式，在服务调用成功/失败/超时的时候发布相应的事件，通过一系列的变换和聚合最终得到实时的指标统计数据流，可以被熔断器或 Dashboard 消费。Sentinel 目前抽象出了 Metric 指标统计接口，底层可以有不同的实现，目前默认的实现是基于 LeapArray 的高性能滑动窗口，后续根据需要可能会引入 reactive stream 等实现。 Sentinel 的特色轻量级、高性能Sentinel 作为一个功能完备的高可用流量管控组件，其核心 sentinel-core 没有任何多余依赖，打包后只有不到 200 KB，非常轻量级。开发者可以放心地引入 sentinel-core 而不需担心依赖问题。同时，Sentinel 提供了多种扩展点，用户可以很方便地根据需求去进行扩展，并且无缝地切合到 Sentinel 中。引入 Sentinel 带来的性能损耗非常小。只有在业务单机量级超过 25W QPS 的时候才会有一些显著的影响（5% - 10% 左右），单机 QPS 不太大的时候损耗几乎可以忽略不计。 流量控制Sentinel 可以针对不同的调用关系，以不同的运行指标（如 QPS、并发调用数、系统负载等）为基准，对资源调用进行流量控制，将随机的请求调整成合适的形状。Sentinel 支持多样化的流量整形策略，在 QPS 过高的时候可以自动将流量调整成合适的形状。常用的有： 直接拒绝模式：即超出的请求直接拒绝。 慢启动预热模式：当流量激增的时候，控制流量通过的速率，让通过的流量缓慢增加，在一定时间内逐渐增加到阈值上限，给冷系统一个预热的时间，避免冷系统被压垮。 匀速器模式：利用 Leaky Bucket 算法实现的匀速模式，严格控制了请求通过的时间间隔，同时堆积的请求将会排队，超过超时时长的请求直接被拒绝。Sentinel 还支持 基于调用关系的限流，包括基于调用方限流、基于调用链入口限流、关联流量限流等，依托于 Sentinel 强大的调用链路统计信息，可以提供精准的不同维度的限流。Sentinel 0.2.0 开始支持 热点参数限流，能够实时的统计热点参数并针对热点参数的资源调用进行流量控制。系统负载保护Sentinel 对系统的维度提供保护，负载保护算法借鉴了 TCP BBR 的思想。当系统负载较高的时候，如果仍持续让请求进入，可能会导致系统崩溃，无法响应。在集群环境下，网络负载均衡会把本应这台机器承载的流量转发到其它的机器上去。如果这个时候其它的机器也处在一个边缘状态的时候，这个增加的流量就会导致这台机器也崩溃，最后导致整个集群不可用。针对这个情况，Sentinel 提供了对应的保护机制，让系统的入口流量和系统的负载达到一个平衡，保证系统在能力范围之内处理最多的请求。 实时监控与控制面板Sentinel 提供 HTTP API 用于获取实时的监控信息，如调用链路统计信息、簇点信息、规则信息等。如果用户正在使用 Spring Boot/Spring Cloud 并使用了 Sentinel Spring Cloud Starter，还可以方便地通过其暴露的 Actuator Endpoint 来获取运行时的一些信息，如动态规则等。未来 Sentinel 还会支持标准化的指标监控 API，可以方便地整合各种监控系统和可视化系统，如 Prometheus、Grafana 等。Sentinel 控制台（Dashboard）提供了机器发现、配置规则、查看实时监控、查看调用链路信息等功能，使得用户可以非常方便地去查看监控和进行配置。 生态Sentinel 目前已经针对 Servlet、Dubbo、Spring Boot/Spring Cloud、gRPC 等进行了适配，用户只需引入相应依赖并进行简单配置即可非常方便地享受 Sentinel 的高可用流量防护能力。未来 Sentinel 还会对更多常用框架进行适配，并且会为 Service Mesh 提供集群流量防护的能力。 总结 Sentinel Hystrix 隔离策略 信号量隔离 线程池隔离/信号量隔离 熔断降级策略 基于响应时间或失败比率 基于失败比率 实时指标实现 滑动窗口 滑动窗口（基于 RxJava） 规则配置 支持多种数据源 支持多种数据源 扩展性 多个扩展点 插件的形式 基于注解的支持 支持 支持 限流 基于 QPS，支持基于调用关系的限流 有限的支持 流量整形 支持慢启动、匀速器模式 不支持 系统负载保护 支持 不支持 控制台 开箱即用，可配置规则、查看秒级监控、机器发现等 不完善 常见框架的适配 Servlet、Spring Cloud、Dubbo、gRPC 等 Servlet、Spring Cloud Netflix]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>Sentinel</tag>
        <tag>Hystrix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式事务]]></title>
    <url>%2F2019%2F04%2F24%2F%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[什么是事务事务提供一种机制将一个活动涉及的所有操作纳入到一个不可分割的执行单元，组成事务的所有操作只有在所有操作均能正常执行的情况下方能提交，只要其中任一操作执行失败，都将导致整个事务的回滚。简单地说，事务提供一种“要么什么都不做，要么做全套（All Do or Nothing Do）”机制。 ACID(事务四大特性)A:原子性(Atomicity)一个事务(transaction)中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。 C:一致性(Consistency)事务的一致性指的是在一个事务执行之前和执行之后数据库都必须处于一致性状态。如果事务成功地完成，那么系统中所有变化将正确地应用，系统处于有效状态。如果在事务中出现错误，那么系统中的所有变化将自动地回滚，系统返回到原始状态。 I:隔离性(Isolation)指的是在并发环境中，当不同的事务同时操纵相同的数据时，每个事务都有各自的完整数据空间。由并发事务所做的修改必须与任何其他并发事务所做的修改隔离。事务查看数据更新时，数据所处的状态要么是另一事务修改它之前的状态，要么是另一事务修改它之后的状态，事务不会查看到中间状态的数据。 D:持久性(Durability)指的是只要事务成功结束，它对数据库所做的更新就必须永久保存下来。即使发生系统崩溃，重新启动数据库系统后，数据库还能恢复到事务成功结束时的状态。 分布式事务什么是分布式事务分布式事务就是指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点之上。简单的说，就是一次大的操作由不同的小操作组成，这些小的操作分布在不同的服务器上，且属于不同的应用，分布式事务需要保证这些小操作要么全部成功，要么全部失败。本质上来说，分布式事务就是为了保证不同数据库的数据一致性。 分布式事务产生的原因分布式事务产生的原因可以分为两块，一个是service产生多个节点，另一个是resource产生多个节点。 service多个节点随着互联网快速发展，微服务，SOA等服务架构模式正在被大规模的使用，举个简单的例子，一个公司之内，用户的资产可能分为好多个部分，比如余额，积分，优惠券等等。在公司内部有可能积分功能由一个微服务团队维护，优惠券又是另外的团队维护。这样的话就无法保证积分扣减了之后，优惠券能否扣减成功。 resource多个节点同样的，互联网发展得太快了，我们的Mysql一般来说装千万级的数据就得进行分库分表，对于一个支付系统的转账业务来说，你给你的朋友转钱，有可能你的数据库是在北京，而你的朋友的钱是存在上海，所以我们依然无法保证他们能同时成功。 分布式事务的基础从上面来看分布式事务是随着互联网高速发展应运而生的，这是一个必然的我们之前说过数据库的ACID四大特性，已经无法满足我们分布式事务，这个时候又有一些技术大佬提出一些新的理论: CAPCAP定理，又被叫作布鲁尔定理。对于设计分布式系统来说(不仅仅是分布式事务)的架构师来说，CAP就是你的入门理论。 C (一致性):对某个指定的客户端来说，读操作能返回最新的写操作。对于数据分布在不同节点上的数据上来说，如果在某个节点更新了数据，那么在其他节点如果都能读取到这个最新的数据，那么就称为强一致，如果有某个节点没有读取到，那就是分布式不一致。 A (可用性)：非故障的节点在合理的时间内返回合理的响应(不是错误和超时的响应)。可用性的两个关键一个是合理的时间，一个是合理的响应。合理的时间指的是请求不能无限被阻塞，应该在合理的时间给出返回。合理的响应指的是系统应该明确返回结果并且结果是正确的，这里的正确指的是比如应该返回50，而不是返回40。 P (分区容错性):当出现网络分区后，系统能够继续工作。打个比方，这里个集群有多台机器，有台机器网络出现了问题，但是这个集群仍然可以正常工作。 熟悉CAP的人都知道，三者不能共有，如果感兴趣可以搜索CAP的证明，在分布式系统中，网络无法100%可靠，分区其实是一个必然现象，如果我们选择了CA而放弃了P，那么当发生分区现象时，为了保证一致性，这个时候必须拒绝请求，但是A又不允许，所以分布式系统理论上不可能选择CA架构，只能选择CP或者AP架构。对于CP来说，放弃可用性，追求一致性和分区容错性，我们的zookeeper其实就是追求的强一致。对于AP来说，放弃一致性(这里说的一致性是强一致性)，追求分区容错性和可用性，这是很多分布式系统设计时的选择，后面的BASE也是根据AP来扩展。顺便一提，CAP理论中是忽略网络延迟，也就是当事务提交时，从节点A复制到节点B，但是在现实中这个是明显不可能的，所以总会有一定的时间是不一致。同时CAP中选择两个，比如你选择了CP，并不是叫你放弃A。因为P出现的概率实在是太小了，大部分的时间你仍然需要保证CA。就算分区出现了你也要为后来的A做准备，比如通过一些日志的手段，是其他机器回复至可用。 BASEBASE 是 Basically Available(基本可用)、Soft state(软状态)和 Eventually consistent (最终一致性)三个短语的缩写。是对CAP中AP的一个扩展。 基本可用:分布式系统在出现故障时，允许损失部分可用功能，保证核心功能可用。 软状态:允许系统中存在中间状态，这个状态不影响系统可用性，这里指的是CAP中的不一致。 最终一致:最终一致是指经过一段时间后，所有节点数据都将会达到一致。 BASE解决了CAP中理论没有网络延迟，在BASE中用软状态和最终一致，保证了延迟后的一致性。BASE和 ACID 是相反的，它完全不同于ACID的强一致性模型，而是通过牺牲强一致性来获得可用性，并允许数据在一段时间内是不一致的，但最终达到一致状态。 分布式事务解决方案是否真的要分布式事务在说方案之前，首先你一定要明确你是否真的需要分布式事务？上面说过出现分布式事务的两个原因，其中有个原因是因为微服务过多。我见过太多团队一个人维护几个微服务，太多团队过度设计，搞得所有人疲劳不堪，而微服务过多就会引出分布式事务，这个时候我不会建议你去采用下面任何一种方案，而是请把需要事务的微服务聚合成一个单机服务，使用数据库的本地事务。因为不论任何一种方案都会增加你系统的复杂度，这样的成本实在是太高了，千万不要因为追求某些设计，而引入不必要的成本和复杂度。 2PC说到2PC就不得不聊数据库分布式事务中的 XA Transactions。在XA协议中分为两阶段: 第一阶段：事务管理器要求每个涉及到事务的数据库预提交(precommit)此操作，并反映是否可以提交. 第二阶段：事务协调器要求每个数据库提交数据，或者回滚数据。优点： 尽量保证了数据的强一致，实现成本较低，在各大主流数据库都有自己实现，对于MySQL是从5.5开始支持。缺点: 单点问题:事务管理器在整个流程中扮演的角色很关键，如果其宕机，比如在第一阶段已经完成，在第二阶段正准备提交的时候事务管理器宕机，资源管理器就会一直阻塞，导致数据库无法使用。 同步阻塞:在准备就绪之后，资源管理器中的资源一直处于阻塞，直到提交完成，释放资源。 数据不一致:两阶段提交协议虽然为分布式数据强一致性所设计，但仍然存在数据不一致性的可能，比如在第二阶段中，假设协调者发出了事务commit的通知，但是因为网络问题该通知仅被一部分参与者所收到并执行了commit操作，其余的参与者则因为没有收到通知一直处于阻塞状态，这时候就产生了数据的不一致性。总的来说，XA协议比较简单，成本较低，但是其单点问题，以及不能支持高并发(由于同步阻塞)依然是其最大的弱点。TCC关于TCC（Try-Confirm-Cancel）的概念，最早是由Pat Helland于2007年发表的一篇名为《Life beyond Distributed Transactions:an Apostate’s Opinion》的论文提出。TCC事务机制相比于上面介绍的XA，解决了其几个缺点: 1.解决了协调者单点，由主业务方发起并完成这个业务活动。业务活动管理器也变成多点，引入集群。 2.同步阻塞:引入超时，超时后进行补偿，并且不会锁定整个资源，将资源转换为业务逻辑形式，粒度变小。 3.数据一致性，有了补偿机制之后，由业务活动管理器控制一致性。对于TCC的解释: Try阶段：尝试执行,完成所有业务检查（一致性）,预留必须业务资源（准隔离性） Confirm阶段：确认执行真正执行业务，不作任何业务检查，只使用Try阶段预留的业务资源，Confirm操作满足幂等性。要求具备幂等设计，Confirm失败后需要进行重试。 Cancel阶段：取消执行，释放Try阶段预留的业务资源Cancel操作满足幂等性Cancel阶段的异常和Confirm阶段异常处理方案基本上一致。本地消息表本地消息表这个方案最初是ebay提出的 ebay的完整方案https://queue.acm.org/detail.cfm?id=1394128。此方案的核心是将需要分布式处理的任务通过消息日志的方式来异步执行。消息日志可以存储到本地文本、数据库或消息队列，再通过业务规则自动或人工发起重试。人工重试更多的是应用于支付场景，通过对账系统对事后问题的处理。对于本地消息队列来说核心是把大事务转变为小事务。还是举上面用100元去买一瓶水的例子。1.当你扣钱的时候，你需要在你扣钱的服务器上新增加一个本地消息表，你需要把你扣钱和写入减去水的库存到本地消息表放入同一个事务(依靠数据库本地事务保证一致性。2.这个时候有个定时任务去轮询这个本地事务表，把没有发送的消息，扔给商品库存服务器，叫他减去水的库存，到达商品服务器之后这个时候得先写入这个服务器的事务表，然后进行扣减，扣减成功后，更新事务表中的状态。3.商品服务器通过定时任务扫描消息表或者直接通知扣钱服务器，扣钱服务器本地消息表进行状态更新。4.针对一些异常情况，定时扫描未成功处理的消息，进行重新发送，在商品服务器接到消息之后，首先判断是否是重复的，如果已经接收，在判断是否执行，如果执行在马上又进行通知事务，如果未执行，需要重新执行需要由业务保证幂等，也就是不会多扣一瓶水。本地消息队列是BASE理论，是最终一致模型，适用于对一致性要求不高的。实现这个模型时需要注意重试的幂等。MQ在RocketMQ中实现了分布式事务，实际上其实是对本地消息表的一个封装，将本地消息表移动到了MQ内部，下面简单介绍一下MQ事务。基本流程如下:第一阶段Prepared消息，会拿到消息的地址。第二阶段执行本地事务。第三阶段通过第一阶段拿到的地址去访问消息，并修改状态。消息接受者就能使用这个消息。如果确认消息失败，在RocketMq Broker中提供了定时扫描没有更新状态的消息，如果有消息没有得到确认，会向消息发送者发送消息，来判断是否提交，在rocketmq中是以listener的形式给发送者，用来处理。如果消费超时，则需要一直重试，消息接收端需要保证幂等。如果消息消费失败，这个就需要人工进行处理，因为这个概率较低，如果为了这种小概率时间而设计这个复杂的流程反而得不偿失Saga事务Saga是30年前一篇数据库伦理提到的一个概念。其核心思想是将长事务拆分为多个本地短事务，由Saga事务协调器协调，如果正常结束那就正常完成，如果某个步骤失败，则根据相反顺序一次调用补偿操作。Saga的组成：每个Saga由一系列sub-transaction Ti 组成每个Ti 都有对应的补偿动作Ci，补偿动作用于撤销Ti造成的结果,这里的每个T，都是一个本地事务。可以看到，和TCC相比，Saga没有“预留 try”动作，它的Ti就是直接提交到库。Saga的执行顺序有两种：T1, T2, T3, …, TnT1, T2, …, Tj, Cj,…, C2, C1，其中0 &lt; j &lt; nSaga定义了两种恢复策略：向后恢复，即上面提到的第二种执行顺序，其中j是发生错误的sub-transaction，这种做法的效果是撤销掉之前所有成功的sub-transation，使得整个Saga的执行结果撤销。向前恢复，适用于必须要成功的场景，执行顺序是类似于这样的：T1, T2, …, Tj(失败), Tj(重试),…, Tn，其中j是发生错误的sub-transaction。该情况下不需要Ci。这里要注意的是，在saga模式中不能保证隔离性，因为没有锁住资源，其他事务依然可以覆盖或者影响当前事务。还是拿100元买一瓶水的例子来说，这里定义T1=扣100元 T2=给用户加一瓶水 T3=减库存一瓶水C1=加100元 C2=给用户减一瓶水 C3=给库存加一瓶水我们一次进行T1,T2，T3如果发生问题，就执行发生问题的C操作的反向。上面说到的隔离性的问题会出现在，如果执行到T3这个时候需要执行回滚，但是这个用户已经把水喝了(另外一个事务)，回滚的时候就会发现，无法给用户减一瓶水了。这就是事务之间没有隔离性的问题可以看见saga模式没有隔离性的影响还是较大，可以参照华为的解决方案:从业务层面入手加入一 Session 以及锁的机制来保证能够串行化操作资源。也可以在业务层面通过预先冻结资金的方式隔离这部分资源， 最后在业务操作的过程中可以通过及时读取当前状态的方式获取到最新的更新。]]></content>
      <categories>
        <category>事务</category>
      </categories>
      <tags>
        <tag>事务</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring-cloud熔断器]]></title>
    <url>%2F2019%2F04%2F23%2Fspring-cloud%E7%86%94%E6%96%AD%E5%99%A8%2F</url>
    <content type="text"><![CDATA[雪崩效应在微服务架构中通常会有多个服务层调用，基础服务的故障可能会导致级联故障，进而造成整个系统不可用的情况，这种现象被称为服务雪崩效应。服务雪崩效应是一种因“服务提供者”的不可用导致“服务消费者”的不可用,并将不可用逐渐放大的过程。 熔断器（CircuitBreaker）熔断器的原理很简单，如同电力过载保护器。它可以实现快速失败，如果它在一段时间内侦测到许多类似的错误，会强迫其以后的多个调用快速失败，不再访问远程服务器，从而防止应用程序不断地尝试执行可能会失败的操作，使得应用程序继续执行而不用等待修正错误，或者浪费CPU时间去等到长时间的超时产生。熔断器也可以使应用程序能够诊断错误是否已经修正，如果已经修正，应用程序会再次尝试调用操作。熔断器模式就像是那些容易导致错误的操作的一种代理。这种代理能够记录最近调用发生错误的次数，然后决定使用允许操作继续，或者立即返回错误。熔断器就是保护服务高可用的最后一道防线。 Hystrix特性1.断路器机制断路器很好理解, 当Hystrix Command请求后端服务失败数量超过一定比例(默认50%), 断路器会切换到开路状态(Open). 这时所有请求会直接失败而不会发送到后端服务. 断路器保持在开路状态一段时间后(默认5秒), 自动切换到半开路状态(HALF-OPEN). 这时会判断下一次请求的返回情况, 如果请求成功, 断路器切回闭路状态(CLOSED), 否则重新切换到开路状态(OPEN). Hystrix的断路器就像我们家庭电路中的保险丝, 一旦后端服务不可用, 断路器会直接切断请求链, 避免发送大量无效请求影响系统吞吐量, 并且断路器有自我检测并恢复的能力. 2.FallbackFallback相当于是降级操作. 对于查询操作, 我们可以实现一个fallback方法, 当请求后端服务出现异常的时候, 可以使用fallback方法返回的值. fallback方法的返回值一般是设置的默认值或者来自缓存. 3.资源隔离在Hystrix中, 主要通过线程池来实现资源隔离. 通常在使用的时候我们会根据调用的远程服务划分出多个线程池. 例如调用产品服务的Command放入A线程池, 调用账户服务的Command放入B线程池. 这样做的主要优点是运行环境被隔离开了. 这样就算调用服务的代码存在bug或者由于其他原因导致自己所在线程池被耗尽时, 不会对系统的其他服务造成影响. 但是带来的代价就是维护多个线程池会对系统带来额外的性能开销. 如果是对性能有严格要求而且确信自己调用服务的客户端代码不会出问题的话, 可以使用Hystrix的信号模式(Semaphores)来隔离资源.]]></content>
      <categories>
        <category>spring cloud</category>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>Hystrix</tag>
        <tag>spring cloud</tag>
        <tag>熔断器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring cloud版本]]></title>
    <url>%2F2019%2F04%2F23%2Fspring-cloud%E7%89%88%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[Spring Cloud是一个由众多独立子项目组成的大型综合项目，每个子项目有不同的发行节奏，都维护着自己的发布版本号。Spring Cloud通过一个资源清单BOM（Bill of Materials）来管理每个版本的子项目清单。为避免与子项目的发布号混淆，所以没有采用版本号的方式，而是通过命名的方式。这些版本名称的命名方式采用了伦敦地铁站的名称，同时根据字母表的顺序来对应版本时间顺序，比如：最早的Release版本：Angel，第二个Release版本：Brixton，然后是Camden、Dalston、Edgware，目前最新的是Finchley版本。当一个版本的Spring Cloud项目的发布内容积累到临界点或者解决了一个严重bug后，就会发布一个“service releases”版本，简称SRX版本，其中X是一个递增数字。当前官网上最新的稳定版本是Edgware.SR5，里程碑版本是Finchley.M9。下表列出了这两个版本所包含的子项目及各子项目的版本号。]]></content>
      <categories>
        <category>spring cloud</category>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>spring cloud</tag>
        <tag>version</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Protobuf简介]]></title>
    <url>%2F2019%2F03%2F26%2FProtobuf%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[protobuf是google提供的一个开源序列化框架，类似于XML，JSON这样的数据表示语言，其最大的特点是基于二进制，因此比传统的XML表示高效短小得多。虽然是二进制数据格式，但并没有因此变得复杂，开发人员通过按照一定的语法定义结构化的消息格式，然后送给命令行工具，工具将自动生成相关的类，可以支持PHP、Java、c++、Python等语言环境。通过将这些类包含在项目中，可以很轻松的调用相关方法来完成业务消息的序列化与反序列化工作。protobuf在google中是一个比较核心的基础库，作为分布式运算涉及到大量的不同业务消息的传递，如何高效简洁的表示、操作这些业务消息在google这样的大规模应用中是至关重要的。而protobuf这样的库正好是在效率、数据大小、易用性之间取得了很好的平衡。 Protobuf消息定义字段格式：限定修饰符① | 数据类型② | 字段名称③ | = | 字段编码值④ | [字段默认值⑤] ①．限定修饰符包含 required\optional\repeated Required: 表示是一个必须字段，必须相对于发送方，在发送消息之前必须设置该字段的值，对于接收方，必须能够识别该字段的意思。发送之前没有设置required字段或者无法识别required字段都会引发编解码异常，导致消息被丢弃。 Optional：表示是一个可选字段，可选对于发送方，在发送消息时，可以有选择性的设置或者不设置该字段的值。对于接收方，如果能够识别可选字段就进行相应的处理，如果无法识别，则忽略该字段，消息中的其它字段正常处理。—因为optional字段的特性，很多接口在升级版本中都把后来添加的字段都统一的设置为optional字段，这样老的版本无需升级程序也可以正常的与新的软件进行通信，只不过新的字段无法识别而已，因为并不是每个节点都需要新的功能，因此可以做到按需升级和平滑过渡。 Repeated：表示该字段可以包含0~N个元素。其特性和optional一样，但是每一次可以包含多个值。可以看作是在传递一个数组的值。 ②．数据类型Protobuf定义了一套基本数据类型。几乎都可以映射到C++\Java等语言的基础数据类型. protobuf 数据类型 描述 打包 C++语言映射 bool 布尔类型 1字节 bool double 64位浮点数 N double float 32为浮点数 N float int32 32位整数 N int uin32 无符号32位整数 N unsigned int int64 64位整数 N __int64 uint64 64位无符号整数 N unsigned __int64 sint32 32位整数，处理负数效率更高 N int32 sing64 64位整数 处理负数效率更高 N __int64 fixed32 32位无符号整数 4 unsigned int32 fixed64 64位无符号整数 8 unsigned __int64 sfixed32 32位整数、能以更高的效率处理负数 4 unsigned int32 sfixed64 64位整数 8 unsigned __int64 string 只能处理 ASCII字符 N std::string bytes 用于处理多字节的语言字符、如中文 N std::string enum 可以包含一个用户自定义的枚举类型uint32 N(uint32) enum message 可以包含一个用户自定义的消息类型 N object of class N 表示打包的字节并不是固定。而是根据数据的大小或者长度。例如int32，如果数值比较小，在0~127时，使用一个字节打包。 关于枚举的打包方式和uint32相同。 关于message，类似于c语言中的结构包含另外一个结构作为数据成员一样。 关于 fixed32 和int32的区别。fixed32的打包效率比int32的效率高，但是使用的空间一般比int32多。因此一个属于时间效率高，一个属于空间效率高。根据项目的实际情况，一般选择fixed32，如果遇到对传输数据量要求比较苛刻的环境，可以选择int32. ③．字段名称字段名称的命名与C、C++、Java等语言的变量命名方式几乎是相同的。protobuf建议字段的命名采用以下划线分割的驼峰式。例如 first_name 而不是firstName. ④．字段编码值有了该值，通信双方才能互相识别对方的字段。当然相同的编码值，其限定修饰符和数据类型必须相同。编码值的取值范围为 1~2^32（4294967296）。其中 1~15的编码时间和空间效率都是最高的，编码值越大，其编码的时间和空间效率就越低（相对于1-15），当然一般情况下相邻的2个值编码效率的是相同的，除非2个值恰好实在4字节，12字节，20字节等的临界区。比如15和16.1900~2000编码值为Google protobuf 系统内部保留值，建议不要在自己的项目中使用。protobuf 还建议把经常要传递的值把其字段编码设置为1-15之间的值。消息中的字段的编码值无需连续，只要是合法的，并且不能在同一个消息中有字段包含相同的编码值。建议：项目投入运营以后涉及到版本升级时的新增消息字段全部使用optional或者repeated，尽量不实用required。如果使用了required，需要全网统一升级，如果使用optional或者repeated可以平滑升级。 ⑤．默认值。当在传递数据时，对于required数据类型，如果用户没有设置值，则使用默认值传递到对端。当接受数据是，对于optional字段，如果没有接收到optional字段，则设置为默认值。 关于importprotobuf 接口文件可以像C语言的h文件一个，分离为多个，在需要的时候通过 import导入需要对文件。其行为和C语言的#include或者java的import的行为大致相同。 关于package避免名称冲突，可以给每个文件指定一个package名称，对于java解析为java中的包。对于C++则解析为名称空间。 关于message支持嵌套消息，消息可以包含另一个消息作为其字段。也可以在消息内定义一个新的消息。 关于enum枚举的定义和C++相同，但是有一些限制。枚举值必须大于等于0的整数。使用分号(;)分隔枚举变量而不是C++语言中的逗号(,) 参考： 官方文档 Google Protocol Buffer 的使用和原理]]></content>
      <categories>
        <category>protobuf</category>
      </categories>
      <tags>
        <tag>protobuf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot跨域]]></title>
    <url>%2F2019%2F03%2F25%2Fspringboot%E8%B7%A8%E5%9F%9F%2F</url>
    <content type="text"><![CDATA[什么是跨域跨域，按照字面意思是跨到了另外的域；域不仅指的是不同的域名网站，也可以是同一个域名不同的端口号也算不同的域；以浏览器的角度来看，只要协议、域名、端口有任何一个不同，都被当作是不同的域。 CORScors全称是Cross-Origin Resource Sharing,跨域资源共享，这是浏览器的标准，基本上现在市面上的浏览器都支持。 跨域支持目前有两种主流的跨域支持方式，一种是在反向代理层配置（如nginx），另一种是直接在后端（如Java）代码中支持。关于nginx层面的反向代理层配置详见Nginx配置跨域请求 Access-Control-Allow-Origin *，本文章主要介绍在后端如何配置对跨域的支持，代码如下12345678910111213141516171819202122232425262728293031323334353637383940import org.springframework.boot.web.servlet.FilterRegistrationBean;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.web.cors.CorsConfiguration;import org.springframework.web.cors.UrlBasedCorsConfigurationSource;import org.springframework.web.filter.CorsFilter;/** * 全局跨域设置 * * @author wangjunfeng * @date 2019-03-21 */@Configurationpublic class GlobalCorsConfig &#123; @Bean public FilterRegistrationBean corsFilter() &#123; UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource(); CorsConfiguration corsConfiguration = new CorsConfiguration(); corsConfiguration.setAllowCredentials(true); corsConfiguration.addAllowedHeader("origin"); corsConfiguration.addAllowedHeader("content-type"); corsConfiguration.addAllowedHeader("token"); corsConfiguration.addAllowedHeader("text/plain charset=UTF-8"); corsConfiguration.addAllowedOrigin("*"); corsConfiguration.addAllowedMethod("POST"); corsConfiguration.addAllowedMethod("GET"); corsConfiguration.addAllowedMethod("OPTIONS"); corsConfiguration.addAllowedMethod("DELETE"); corsConfiguration.addAllowedMethod("PUT"); corsConfiguration.addAllowedMethod("HEAD"); corsConfiguration.addAllowedMethod("TRACE"); corsConfiguration.addAllowedMethod("PATCH"); source.registerCorsConfiguration("/**", corsConfiguration); FilterRegistrationBean bean = new FilterRegistrationBean(new CorsFilter(source)); // 这个顺序很重要哦，为避免麻烦请设置在最前 bean.setOrder(0); return bean; &#125;&#125;]]></content>
      <categories>
        <category>springboot</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mvnw && mvnw.cmd]]></title>
    <url>%2F2019%2F03%2F19%2Fmvnw-mvnw-cmd%2F</url>
    <content type="text"><![CDATA[当创见一个Spring Boot的应用程序时，在程序的根目录下可以看到 mvnw 和 mvnw.cmd 这个两个文件，那么这两个文件各自的用途是什么呢？ 简介mvnw全程是maven wrapper，它的原理是在maven-wrapper.properties文件中记录你要使用的maven版本，当用户执行mvnw clean 命令时，发现当前用户的maven版本和期望的版本不一致，那么就可以下载期望的版本，然后用期望的版本来执行mvn命令，比如mvn clean。Maven是一个常用的构建工具，但是Maven的版本和插件的配合并不是那么完美，有时候你需要切换到一个统一的版本，以保证所有东西正常工作。Gradle提供了一个Wrapper，可以很好解决maven版本切换的问题，并且更重要的是不需要预先安装Gradle。 安装123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293mvn -N io.takari:maven:wrapper[INFO] Scanning for projects...Downloading from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/io/takari/maven/maven-metadata.xmlDownloaded from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/io/takari/maven/maven-metadata.xml (662 B at 812 B/s)Downloading from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/io/takari/maven/0.7.4/maven-0.7.4.pomDownloaded from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/io/takari/maven/0.7.4/maven-0.7.4.pom (2.3 kB at 4.9 kB/s)Downloading from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/io/takari/takari/27/takari-27.pomDownloaded from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/io/takari/takari/27/takari-27.pom (14 kB at 24 kB/s)Downloading from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/io/takari/maven/0.7.4/maven-0.7.4.jarDownloaded from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/io/takari/maven/0.7.4/maven-0.7.4.jar (9.0 kB at 24 kB/s)[INFO] [INFO] -------------------------&lt; com.kiwi:kiwismart &gt;-------------------------[INFO] Building spring-boot-basic 0.0.1-SNAPSHOT[INFO] --------------------------------[ jar ]---------------------------------[INFO] [INFO] --- maven:0.7.4:wrapper (default-cli) @ kiwismart ---Downloading from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/io/takari/maven-wrapper/0.5.3/maven-wrapper-0.5.3.pomDownloaded from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/io/takari/maven-wrapper/0.5.3/maven-wrapper-0.5.3.pom (2.4 kB at 6.8 kB/s)Downloading from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/io/takari/takari-archiver/0.1.9/takari-archiver-0.1.9.pomDownloaded from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/io/takari/takari-archiver/0.1.9/takari-archiver-0.1.9.pom (1.8 kB at 4.1 kB/s)Downloading from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/io/takari/takari/15/takari-15.pomDownloaded from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/io/takari/takari/15/takari-15.pom (15 kB at 30 kB/s)Downloading from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/com/google/guava/guava/14.0.1/guava-14.0.1.pomDownloaded from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/com/google/guava/guava/14.0.1/guava-14.0.1.pom (5.4 kB at 105 kB/s)Downloading from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/com/google/guava/guava-parent/14.0.1/guava-parent-14.0.1.pomDownloaded from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/com/google/guava/guava-parent/14.0.1/guava-parent-14.0.1.pom (2.6 kB at 12 kB/s)Downloading from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/org/apache/commons/commons-compress/1.8.1/commons-compress-1.8.1.pomDownloaded from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/org/apache/commons/commons-compress/1.8.1/commons-compress-1.8.1.pom (11 kB at 286 kB/s)Downloading from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/io/takari/graph/takari-graph/0.0.3/takari-graph-0.0.3.pomDownloaded from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/io/takari/graph/takari-graph/0.0.3/takari-graph-0.0.3.pom (4.7 kB at 13 kB/s)Downloading from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/io/takari/takari/14/takari-14.pomDownloaded from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/io/takari/takari/14/takari-14.pom (13 kB at 33 kB/s)Downloading from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/org/codehaus/plexus/plexus-utils/3.0.16/plexus-utils-3.0.16.pomDownloaded from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/org/codehaus/plexus/plexus-utils/3.0.16/plexus-utils-3.0.16.pom (3.4 kB at 9.2 kB/s)Downloading from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/com/tinkerpop/blueprints/blueprints-core/2.6.0/blueprints-core-2.6.0.pomDownloaded from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/com/tinkerpop/blueprints/blueprints-core/2.6.0/blueprints-core-2.6.0.pom (3.6 kB at 8.4 kB/s)Downloading from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/com/tinkerpop/blueprints/blueprints/2.6.0/blueprints-2.6.0.pomDownloaded from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/com/tinkerpop/blueprints/blueprints/2.6.0/blueprints-2.6.0.pom (7.0 kB at 19 kB/s)Downloading from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/org/apache/maven/maven-model/3.2.3/maven-model-3.2.3.pomDownloaded from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/org/apache/maven/maven-model/3.2.3/maven-model-3.2.3.pom (4.1 kB at 9.6 kB/s)Downloading from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/org/apache/maven/maven/3.2.3/maven-3.2.3.pomDownloaded from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/org/apache/maven/maven/3.2.3/maven-3.2.3.pom (23 kB at 45 kB/s)Downloading from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/com/github/spullara/mustache/java/compiler/0.8.15/compiler-0.8.15.pomDownloaded from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/com/github/spullara/mustache/java/compiler/0.8.15/compiler-0.8.15.pom (5.6 kB at 11 kB/s)Downloading from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/com/github/spullara/mustache/java/mustache.java/0.8.15/mustache.java-0.8.15.pomDownloaded from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/com/github/spullara/mustache/java/mustache.java/0.8.15/mustache.java-0.8.15.pom (3.5 kB at 8.6 kB/s)Downloading from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/com/squareup/javapoet/1.0.0/javapoet-1.0.0.pomDownloaded from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/com/squareup/javapoet/1.0.0/javapoet-1.0.0.pom (3.5 kB at 9.4 kB/s)Downloading from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/io/airlift/airline/0.6/airline-0.6.pomDownloaded from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/io/airlift/airline/0.6/airline-0.6.pom (6.8 kB at 7.2 kB/s)Downloading from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/com/google/guava/guava/12.0/guava-12.0.pomDownloaded from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/com/google/guava/guava/12.0/guava-12.0.pom (5.3 kB at 152 kB/s)Downloading from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/com/google/guava/guava-parent/12.0/guava-parent-12.0.pomDownloaded from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/com/google/guava/guava-parent/12.0/guava-parent-12.0.pom (2.8 kB at 110 kB/s)Downloading from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/org/antlr/antlr4-runtime/4.5/antlr4-runtime-4.5.pomDownloaded from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/org/antlr/antlr4-runtime/4.5/antlr4-runtime-4.5.pom (2.7 kB at 62 kB/s)Downloading from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/org/abego/treelayout/org.abego.treelayout.core/1.0.1/org.abego.treelayout.core-1.0.1.pomDownloaded from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/org/abego/treelayout/org.abego.treelayout.core/1.0.1/org.abego.treelayout.core-1.0.1.pom (3.1 kB at 6.3 kB/s)Downloading from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/io/takari/maven-wrapper/0.5.3/maven-wrapper-0.5.3.jarDownloading from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/io/takari/takari-archiver/0.1.9/takari-archiver-0.1.9.jarDownloading from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/com/google/guava/guava/14.0.1/guava-14.0.1.jarDownloading from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/org/apache/commons/commons-compress/1.8.1/commons-compress-1.8.1.jarDownloading from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/io/takari/graph/takari-graph/0.0.3/takari-graph-0.0.3.jarDownloaded from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/org/apache/commons/commons-compress/1.8.1/commons-compress-1.8.1.jar (366 kB at 2.0 MB/s)Downloading from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/com/tinkerpop/blueprints/blueprints-core/2.6.0/blueprints-core-2.6.0.jarDownloaded from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/io/takari/maven-wrapper/0.5.3/maven-wrapper-0.5.3.jar (51 kB at 87 kB/s)Downloading from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/org/apache/maven/maven-model/3.2.3/maven-model-3.2.3.jarDownloaded from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/io/takari/takari-archiver/0.1.9/takari-archiver-0.1.9.jar (41 kB at 58 kB/s)Downloading from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/com/github/spullara/mustache/java/compiler/0.8.15/compiler-0.8.15.jarDownloaded from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/com/google/guava/guava/14.0.1/guava-14.0.1.jar (2.2 MB at 2.6 MB/s)Downloading from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/com/squareup/javapoet/1.0.0/javapoet-1.0.0.jarDownloaded from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/io/takari/graph/takari-graph/0.0.3/takari-graph-0.0.3.jar (173 kB at 132 kB/s)Downloading from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/io/airlift/airline/0.6/airline-0.6.jarDownloaded from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/org/apache/maven/maven-model/3.2.3/maven-model-3.2.3.jar (160 kB at 121 kB/s)Downloading from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/org/antlr/antlr4-runtime/4.5/antlr4-runtime-4.5.jarDownloaded from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/com/github/spullara/mustache/java/compiler/0.8.15/compiler-0.8.15.jar (116 kB at 87 kB/s)Downloading from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/org/abego/treelayout/org.abego.treelayout.core/1.0.1/org.abego.treelayout.core-1.0.1.jarDownloaded from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/org/abego/treelayout/org.abego.treelayout.core/1.0.1/org.abego.treelayout.core-1.0.1.jar (26 kB at 19 kB/s)Downloaded from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/org/antlr/antlr4-runtime/4.5/antlr4-runtime-4.5.jar (374 kB at 250 kB/s)Downloaded from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/com/tinkerpop/blueprints/blueprints-core/2.6.0/blueprints-core-2.6.0.jar (274 kB at 177 kB/s)Downloaded from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/io/airlift/airline/0.6/airline-0.6.jar (87 kB at 50 kB/s)Downloaded from pp-nexus: http://nexus.pengpengla.com:8081/nexus/content/groups/public/com/squareup/javapoet/1.0.0/javapoet-1.0.0.jar (65 kB at 37 kB/s)[INFO] [INFO] Maven Wrapper version 0.5.3 has been successfully set up for your project.[INFO] Using Apache Maven: 3.6.0[INFO] Repo URL in properties file: http://nexus.pengpengla.com:8081/nexus/content/groups/public/[INFO] [INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 13.001 s[INFO] Finished at: 2019-03-19T11:45:00+08:00[INFO] ------------------------------------------------------------------------ 运行12 mvn -N io.takari:maven:wrapper -Dmaven=3.1.0 ##指定maven版本./mvnw clean install 区别mvnw适用于Linux(bash),mvnw.cmd 适用于Windows环境]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>mvn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis数据结构]]></title>
    <url>%2F2019%2F03%2F15%2FRedis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[如上图所示，Redis有5个基本数据结构(string、list、hash、set和zset)，它们是日常开发中使用频率非常高应用最为广泛的数据结构，把这5个数据结构都掌握了，面试的时候又可以给自己加分了。 string Redis的字符串是动态字符串，是可以修改的字符串，内部结构实现上类似于Java的ArrayList，采用预分配冗余空间的方式来减少内存的频繁分配，如图中所示，内部为当前字符串实际分配的空间capacity一般要高于实际字符串长度len。当字符串长度小于1M时，扩容都是加倍现有的空间，如果超过1M，扩容时一次只会多扩1M的空间。需要注意的是字符串最大长度为512M。 初始化字符串12&gt; set today:news hellowordOK 获取字符串的内容12&gt; get today:news"helloword" 获取字符串的长度12&gt; strlen today:news(integer) 9 获取子串12&gt; getrange today:news 0 5"hellow" 覆盖子串1234&gt; setrange today:news 5 hi(integer) 9&gt; get today:news"hellohird" 追加子串1234&gt; append today:news ^_^(integer) 12&gt; get today:news"hellohird^_^" 过期和删除12345678&gt; expire today:news 60000 #设置过期时间(integer) 1&gt; ttl today:news # 查看剩余过期时间(integer) 59972&gt; del today:news # 删除key(integer) 1&gt; get today:news # 检索key(nil) 计数器如果字符串的内容是一个整数，那么还可以将字符串当成计数器来使用。12345678910&gt; set numbers 100OK&gt; incrby numbers 20(integer) 120&gt; decrby numbers 100(integer) 20&gt; incr numbers #等同于 incrby numbers 1(integer) 21&gt; decr numbers # 等同于 decrby numbers 1(integer) 20 计数器是有范围的，它不能超过Long.Max，不能低于Long.MIN list Redis将列表数据结构命名为list而不是array，是因为列表的存储结构用的是链表而不是数组，而且链表还是双向链表。因为它是链表，所以随机定位性能较弱，首尾插入删除性能较优。如果list的列表长度很长，使用时我们一定要关注链表相关操作的时间复杂度。 负下标链表元素的位置使用自然数0,1,2,….n-1表示，还可以使用负数-1,-2,…-n来表示，-1表示「倒数第一」，-2表示「倒数第二」，那么-n就表示第一个元素，对应的下标为0。 队列／堆栈链表可以从表头和表尾追加和移除元素，结合使用rpush/rpop/lpush/lpop四条指令，可以将链表作为队列或堆栈使用，左向右向进行都可以123456789101112131415161718192021222324252627&gt; rpush queue go #右进左出(integer) 1&gt; rpush queue java python(integer) 3&gt; lpop queue"go"&gt; lpop queue"java"&gt; lpop queue"python"# 左进右出&gt; lpush queue go java python(integer) 3&gt; rpop queue"go"...# 右进右出&gt; rpush queue go java python(integer) 3&gt; rpop queue "python"...# 左进左出&gt; lpush queue go java python(integer) 3&gt; lpop queue"python" 长度使用llen指令获取链表长度1234&gt; rpush queue go java python(integer) 3&gt; llen queue(integer) 3 随机读可以使用lindex指令访问指定位置的元素，使用lrange指令来获取链表子元素列表，提供start和end下标参数使用lrange获取全部元素时，需要提供end_index，如果没有负下标，就需要首先通过llen指令获取长度，才可以得出end_index的值，有了负下标，使用-1代替end_index就可以达到相同的效果。123456789101112&gt; rpush queue go java python(integer) 3&gt; lindex queue 1"java"&gt; lrange queue 0 21) "go"2) "java"3) "python"&gt; lrange queue 0 -1 # -1表示倒数第一1) "go"2) "java"3) "python" 修改元素使用lset指令在指定位置修改元素12345678&gt; rpush queue go java python(integer) 3&gt; lset queue 1 javascriptOK&gt; lrange queue 0 -11) "go"2) "javascript"3) "python" 插入元素使用linsert指令在列表的中间位置插入元素，有经验的程序员都知道在插入元素时，我们经常搞不清楚是在指定位置的前面插入还是后面插入，所以antirez在linsert指令里增加了方向参数before/after来显示指示前置和后置插入。不过让人意想不到的是linsert指令并不是通过指定位置来插入，而是通过指定具体的值。这是因为在分布式环境下，列表的元素总是频繁变动的，意味着上一时刻计算的元素下标在下一时刻可能就不是你所期望的下标了。123456789&gt; rpush queue go java python(integer) 3&gt; linsert queue before java ruby(integer) 4&gt; lrange queue 0 -11) "go"2) "ruby"3) "java"4) "python" 删除元素列表的删除操作也不是通过指定下标来确定元素的，你需要指定删除的最大个数以及元素的值1234567&gt; rpush queue go java python(integer) 3&gt; lrem queue 1 java(integer) 1&gt; lrange queue 0 -11) "go"2) "python" 定长列表在实际应用场景中，我们有时候会遇到「定长列表」的需求。比如要以走马灯的形式实时显示中奖用户名列表，因为中奖用户实在太多，能显示的数量一般不超过100条，那么这里就会使用到定长列表。维持定长列表的指令是ltrim，需要提供两个参数start和end，表示需要保留列表的下标范围，范围之外的所有元素都将被移除。12345678&gt; rpush quene go java python javascript ruby erlang rust cpp(integer) 8&gt; ltrim quene -3 -1OK&gt; lrange quene 0 -11) "erlang"2) "rust"3) "cpp" 快速列表如果再深入一点，你会发现Redis底层存储的还不是一个简单的linkedlist，而是称之为快速链表quicklist的一个结构。首先在列表元素较少的情况下会使用一块连续的内存存储，这个结构是ziplist，也即是压缩列表。它将所有的元素紧挨着一起存储，分配的是一块连续的内存。当数据量比较多的时候才会改成quicklist。因为普通的链表需要的附加指针空间太大，会比较浪费空间。比如这个列表里存的只是int类型的数据，结构上还需要两个额外的指针prev和next。所以Redis将链表和ziplist结合起来组成了quicklist。也就是将多个ziplist使用双向指针串起来使用。这样既满足了快速的插入删除性能，又不会出现太大的空间冗余。 hash 哈希等价于Java语言的HashMap或者是Python语言的dict，在实现结构上它使用二维结构，第一维是数组，第二维是链表，hash的内容key和value存放在链表中，数组里存放的是链表的头指针。通过key查找元素时，先计算key的hashcode，然后用hashcode对数组的长度进行取模定位到链表的表头，再对链表进行遍历获取到相应的value值，链表的作用就是用来将产生了「hash碰撞」的元素串起来。Java语言开发者会感到非常熟悉，因为这样的结构和HashMap是没有区别的。哈希的第一维数组的长度也是2^n。 增加元素可以使用hset一次增加一个键值对，也可以使用hmset一次增加多个键值对1234&gt; hset sets go fast(integer) 1&gt; hmset sets java fast python slowOK 获取元素可以通过hget定位具体key对应的value，可以通过hmget获取多个key对应的value，可以使用hgetall获取所有的键值对，可以使用hkeys和hvals分别获取所有的key列表和value列表。这些操作和Java语言的Map接口是类似的。12345678910111213141516171819202122&gt; hmset sets go fast java fast python slowOK&gt; hget sets go"fast"&gt; hmget sets go python1) "fast"2) "slow"&gt; hgetall sets1) "go"2) "fast"3) "java"4) "fast"5) "python"6) "slow"&gt; hkeys sets1) "go"2) "java"3) "python"&gt; hvals sets1) "fast"2) "fast"3) "slow" 删除元素可以使用hdel删除指定key，hdel支持同时删除多个key123456&gt; hmset sets go fast java fast python slowOK&gt; hdel sets go(integer) 1&gt; hdel sets java python(integer) 2 判断元素是否存在通常我们使用hget获得key对应的value是否为空就直到对应的元素是否存在了，不过如果value的字符串长度特别大，通过这种方式来判断元素存在与否就略显浪费，这时可以使用hexists指令。1234&gt; hmset sets go fast java fast python slowOK&gt; hexists sets go(integer) 1 扩容当hash内部的元素比较拥挤时(hash碰撞比较频繁)，就需要进行扩容。扩容需要申请新的两倍大小的数组，然后将所有的键值对重新分配到新的数组下标对应的链表中(rehash)。如果hash结构很大，比如有上百万个键值对，那么一次完整rehash的过程就会耗时很长。这对于单线程的Redis里来说有点压力山大。所以Redis采用了渐进式rehash的方案。它会同时保留两个新旧hash结构，在后续的定时任务以及hash结构的读写指令中将旧结构的元素逐渐迁移到新的结构中。这样就可以避免因扩容导致的线程卡顿现象。 缩容Redis的hash结构不但有扩容还有缩容，从这一点出发，它要比Java的HashMap要厉害一些，Java的HashMap只有扩容。缩容的原理和扩容是一致的，只不过新的数组大小要比旧数组小一倍。 set Java程序员都知道HashSet的内部实现使用的是HashMap，只不过所有的value都指向同一个对象。Redis的set结构也是一样，它的内部也使用hash结构，所有的value都指向同一个内部值。 增加元素可以一次增加多个元素12&gt; sadd keys4sets go java python(integer) 3 读取元素使用smembers列出所有元素，使用scard获取集合长度，使用srandmember获取随机count个元素，如果不提供count参数，默认为112345678910&gt; sadd keys4sets go java python(integer) 3&gt; smembers keys4sets1) "java"2) "python"3) "go"&gt; scard keys4sets(integer) 3&gt; srandmember keys4sets"java" 删除元素使用srem删除一到多个元素，使用spop删除随机一个元素123456&gt; sadd keys4sets go java python rust erlang(integer) 5&gt; srem keys4sets go java(integer) 2&gt; spop keys4sets"erlang" 判断元素是否存在使用sismember指令，只能接收单个元素123456&gt; sadd keys4sets go java python rust erlang(integer) 5&gt; sismember keys4sets rust(integer) 1&gt; sismember keys4sets javascript(integer) 0 sortedsetSortedSet(zset)是Redis提供的一个非常特别的数据结构，一方面它等价于Java的数据结构Map&lt;String, Double&gt;，可以给每一个元素value赋予一个权重score，另一方面它又类似于TreeSet，内部的元素会按照权重score进行排序，可以得到每个元素的名次，还可以通过score的范围来获取元素的列表。zset底层实现使用了两个数据结构，第一个是hash，第二个是跳跃列表，hash的作用就是关联元素value和权重score，保障元素value的唯一性，可以通过元素value找到相应的score值。跳跃列表的目的在于给元素value排序，根据score的范围获取元素列表。 增加元素通过zadd指令可以增加一到多个value/score对，score放在前面1234&gt; zadd key4Sortedset 4.0 python(integer) 1&gt; zadd key4Sortedset 4.0 java 1.0 go(integer) 2 长度通过指令zcard可以得到zset的元素个数12&gt; zcard key4Sortedset(integer) 3 删除元素通过指令zrem可以删除zset中的元素，可以一次删除多个12&gt; zrem key4Sortedset go python(integer) 2 获取排名和分数通过zscore指令获取指定元素的权重，通过zrank指令获取指定元素的正向排名，通过zrevrank指令获取指定元素的反向排名[倒数第一名]。正向是由小到大，负向是由大到小。12345678910&gt; zscore key4Sortedset python"5"&gt; zrank key4Sortedset go # 分数低的排名考前，rank值小(integer) 0&gt; zrank key4Sortedset java(integer) 1&gt; zrank key4Sortedset python(integer) 2&gt; zrevrank key4Sortedset python(integer) 0 根据排名范围获取元素列表通过zrange指令指定排名范围参数获取对应的元素列表，携带withscores参数可以一并获取元素的权重。通过zrevrange指令按负向排名获取元素列表[倒数]。正向是由小到大，负向是由大到小。123456789101112131415161718&gt; zrange key4Sortedset 0 -1 # 获取所有元素1) "go"2) "java"3) "python"&gt; zrange key4Sortedset 0 -1 withscores1) "go"2) "1"3) "java"4) "4"5) "python"6) "5"&gt; zrevrange key4Sortedset 0 -1 withscores1) "python"2) "5"3) "java"4) "4"5) "go"6) "1" 根据score范围获取列表通过zrangebyscore指令指定score范围获取对应的元素列表。通过zrevrangebyscore指令获取倒排元素列表。正向是由小到大，负向是由大到小。参数-inf表示负无穷，+inf表示正无穷。123456789101112131415161718&gt; zrangebyscore key4Sortedset 0 51) "go"2) "java"3) "python"&gt; zrangebyscore key4Sortedset -inf +inf withscores1) "go"2) "1"3) "java"4) "4"5) "python"6) "5"&gt; zrevrangebyscore key4Sortedset +inf -inf withscores # 注意正负反过来了1) "python"2) "5"3) "java"4) "4"5) "go"6) "1" 根据范围移除元素列表可以通过排名范围，也可以通过score范围来一次性移除多个元素12345678&gt; zremrangebyrank key4Sortedset 0 1(integer) 2 # 删掉了2个元素&gt; zadd key4Sortedset 4.0 java 1.0 go(integer) 2&gt; zremrangebyscore key4Sortedset -inf 4(integer) 2&gt; zrange key4Sortedset 0 -11) "python" 跳跃列表 zset内部的排序功能是通过「跳跃列表」数据结构来实现的，它的结构非常特殊，也比较复杂。这一块的内容深度读者要有心理准备。 因为zset要支持随机的插入和删除，所以它不好使用数组来表示。我们先看一个普通的链表结构。 我们需要这个链表按照score值进行排序。这意味着当有新元素需要插入时，需要定位到特定位置的插入点，这样才可以继续保证链表是有序的。通常我们会通过二分查找来找到插入点，但是二分查找的对象必须是数组，只有数组才可以支持快速位置定位，链表做不到，那该怎么办？想想一个创业公司，刚开始只有几个人，团队成员之间人人平等，都是联合创始人。随着公司的成长，人数渐渐变多，团队沟通成本随之增加。这时候就会引入组长制，对团队进行划分。每个团队会有一个组长。开会的时候分团队进行，多个组长之间还会有自己的会议安排。公司规模进一步扩展，需要再增加一个层级——部门，每个部门会从组长列表中推选出一个代表来作为部长。部长们之间还会有自己的高层会议安排。跳跃列表就是类似于这种层级制，最下面一层所有的元素都会串起来。然后每隔几个元素挑选出一个代表来，再将这几个代表使用另外一级指针串起来。然后在这些代表里再挑出二级代表，再串起来。最终就形成了金字塔结构。想想你老家在世界地图中的位置：亚洲–&gt;中国-&gt;安徽省-&gt;安庆市-&gt;枞阳县-&gt;汤沟镇-&gt;田间村-&gt;xxxx号，也是这样一个类似的结构。 「跳跃列表」之所以「跳跃」，是因为内部的元素可能「身兼数职」，比如上图中间的这个元素，同时处于L0、L1和L2层，可以快速在不同层次之间进行「跳跃」。定位插入点时，先在顶层进行定位，然后下潜到下一级定位，一直下潜到最底层找到合适的位置，将新元素插进去。你也许会问那新插入的元素如何才有机会「身兼数职」呢？跳跃列表采取一个随机策略来决定新元素可以兼职到第几层，首先L0层肯定是100%了，L1层只有50%的概率，L2层只有25%的概率，L3层只有12.5%的概率，一直随机到最顶层L31层。绝大多数元素都过不了几层，只有极少数元素可以深入到顶层。列表中的元素越多，能够深入的层次就越深，能进入到顶层的概率就会越大。]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7.0 关闭firewalld防火墙指令 及更换Iptables防火墙]]></title>
    <url>%2F2019%2F03%2F14%2FCentOS%207.0%20%E5%85%B3%E9%97%ADfirewalld%E9%98%B2%E7%81%AB%E5%A2%99%E6%8C%87%E4%BB%A4%20%E5%8F%8A%E6%9B%B4%E6%8D%A2Iptables%E9%98%B2%E7%81%AB%E5%A2%99%2F</url>
    <content type="text"><![CDATA[Disable Firewalld Service.1systemctl mask firewalld Stop Firewalld Service.1systemctl stop firewalld Install iptables service related packages.1yum -y install iptables-services Make sure service starts at boot:1systemctl enable iptables Now, Finally Let’s start the iptables services.1systemctl start iptables]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>防火墙</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac使用技巧总结]]></title>
    <url>%2F2018%2F11%2F01%2FMac%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[显示|隐藏文件夹隐藏文件夹/opt1sudo chflags hidden /opt 显示文件夹/opt1sudo chflags nohidden /opt 创建软链1vim ~/.bash_profile 12alias ll='ls -l'alias la='ls -al' 安装软件显示所有来源1sudo spctl --master-disable]]></content>
      <categories>
        <category>Mac</category>
      </categories>
      <tags>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP、TCP、UDP、Socket、HTTPS区别]]></title>
    <url>%2F2018%2F10%2F11%2FHTTP%E3%80%81TCP%E3%80%81UDP%E3%80%81Socket%E3%80%81HTTPS%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[简介 TCP/IP是个协议组，可分为四个层次：网络接口层、网络层、传输层和应用层，如下图所示 在网络层有IP协议、ICMP协议、ARP协议、RARP协议和BOOTP协议。 在传输层中有TCP协议与UDP协议。 在应用层有HTTP,FTP、TELNET、SMTP、DNS等协议。 详细介绍HTTP(HyperText Transfer Protocal)HTTP(HyperText Transfer Protocal),超文本传输协议，HTTP连接最显著的特点是客户端发送的每次请求都需要服务器回送响应，在请求结束后，会主动释放连接。从建立连接到关闭连接的过程称为”一次连接”。 优点 基于应用级的接口使用方便 程序员开发水平要求不高，容错性强 缺点 传输速度慢，数据包大（Http协议中包含辅助应用信息） 如实时交互，服务器性能压力大。 数据传输安全性差 适用范围基于http协议传输方式适合于对传输速度，安全性要求不是很高，且需要快速开发的应用。如公司OA系统，互联网服务等。 HTTPSHTTPS(Secure Hypertext Transfer Protocol),安全超文本传输协议，它是一个安全通信通道。HTTPS是HTTP over SSL/TLS，HTTP是应用层协议，TCP是传输层协议，在应用层和传输层之间，增加了一个安全套接层SSL/TLS： SSL (Secure Socket Layer，安全套接字层) TLS (Transport Layer Security，传输层安全协议) SSL使用40位关键字作为RC4流加密算法 Https和Http区别 https协议需要到CA申请证书。 http是超文本传输协议，信息是明文传输；https 则是具有安全性的ssl加密传输协议。 http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。 http的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。 TCP传送控制协议(Transmission Control Protocol) UDP用户数据报协议 （UDP：User Datagram Protocol） socket这是为了实现以上的通信过程而建立成来的通信管道，其真实的代表是客户端和服务器端的一个通信进程，双方进程通过socket进行通信，而通信的规则采用指定的协议。socket只是一种连接模式，不是协议，socket是对TCP/IP协议的封装，Socket本身并不是协议，而是一个调用接口（API），通过Socket，我们才能使用TCP/IP协议。tcp、udp，简单的说（虽然不准确）是两个最基本的协议,很多其它协议都是基于这两个协议如，http就是基于tcp的，用socket可以创建tcp连接，也可以创建udp连接，这意味着，用socket可以创建任何协议的连接，因为其它协议都是基于此的。 优点 传输数据为字节级，传输数据可自定义，数据量小（对于手机应用讲：费用低） 传输数据时间短，性能高 适合于客户端和服务器端之间信息实时交互 可以加密,数据安全性强 缺点 需对传输的数据进行解析，转化成应用级的数据 对开发人员的开发水平要求高 相对于Http协议传输，增加了开发量 适用范围Socket传输方式适合于对传输速度，安全性，实时交互，费用等要求高的应用中，如网络游戏，手机应用，银行内部交互等 参考资料 HTTP、TCP、UDP，Socket，HTTPS]]></content>
      <categories>
        <category>http</category>
      </categories>
      <tags>
        <tag>http</tag>
        <tag>tcp</tag>
        <tag>udp</tag>
        <tag>socket</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mvn常用命令大全]]></title>
    <url>%2F2018%2F10%2F10%2Fmvn%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E5%A4%A7%E5%85%A8%2F</url>
    <content type="text"><![CDATA[maven命令除了常用的几个，大部分经常记不住，整理一下，方便查询。maven 命令的格式为 mvn [plugin-name]:[goal-name]，可以接受的参数如下： -D 指定参数，如 -Dmaven.test.skip=true 跳过单元测试； -P 指定 Profile 配置，可以用于区分环境； -e 显示maven运行出错的信息； -o 离线执行命令,即不去远程仓库更新包； -X 显示maven允许的debug信息； -U 强制去远程更新snapshot的插件或依赖，默认每天只更新一次。 项目相关 mvn archetype:create 创建maven项目 创建maven项目：mvn archetype:create 指定 group： -DgroupId=packageName 指定 artifact：-DartifactId=projectName 创建web项目：-DarchetypeArtifactId=maven-archetype-webapp mvn validate 验证项目是否正确 mvn package maven 打包 mvn jar:jar 只打jar包 mvn source:jar 生成源码jar包 mvn generate-sources 产生应用需要的任何额外的源代码 mvn compile 编译源代码 mvn test-compile 译测试代码 mvn test 运行测试 mvn verify运行检查 mvn clean清理maven项目 mvn eclipse:eclipse生成eclipse项目 mvn eclipse:clean清理eclipse配置 mvn idea:idea生成idea项目 mvn install安装项目到本地仓库 mvn:deploy发布项目到远程仓库 mvn integration-test在集成测试可以运行的环境中处理和发布包 mvn dependency:tree显示maven依赖树 mvn dependency:list显示maven依赖列表 mvn dependency:sources下载依赖包的源码 mvn install:install-file -DgroupId=packageName -DartifactId=projectName -Dversion=version -Dpackaging=jar -Dfile=path安装本地jar到本地仓库 web相关命令 mvn tomcat:run 启动tomcat mvn jetty:run 启动jetty mvn tomcat:deploy 运行打包部署 mvn tomcat:undeploy 撤销部署 mvn tomcat:start 启动web应用： mvn tomcat:stop 停止web应用 mvn tomcat:redeploy 重新部署 mvn war:exploded tomcat:exploded 署展开的war文件 参考资料 30 个常用 Maven 命令]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>mvn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java开发规范]]></title>
    <url>%2F2018%2F10%2F08%2FJava%E5%BC%80%E5%8F%91%E8%A7%84%E8%8C%83%2F</url>
    <content type="text"><![CDATA[前言 本文章是将网上PDF版本的Java开发规范转换成的Markdown版本 Java 开发手册 版本号 作者 日期 备注 1.4.0 阿里巴巴集团技术团队 2018. 5. 20 增加设计规约（详尽版） 1.4.1 王俊峰 2018. 10. 8 pdf2markdown 1.4.2 王俊峰 2018. 10. 10 去掉版本历史 一、编程规约(一) 命名风格 【强制】代码中的命名均不能以下划线或美元符号开始，也不能以下划线或美元符号 结束。 反例：_name __name $name name_ name$ name__ 【强制】代码中的命名严禁使用拼音与英文混合的方式，更不允许直接使用中文的方式。 正确的英文拼写和语法可以让阅读者易于理解，避免歧义。注意，即使纯拼音命名方式也要避免采用。 正例：alibaba taobao youku hangzhou 等国际通用的名称，可视同英文。 反例：DaZhePromotion [打折] getPingfenByName() [评分] int 某变量 = 3 【强制】类名使用UpperCamelCase风格，但以下情形例外：DO / BO / DTO / VO / AO / PO / UID等。 正例：MarcoPolo UserDO XmlService TcpUdpDeal TaPromotion 反例：macroPolo UserDo XMLService TCPUDPDeal TAPromotion 【强制】方法名、参数名、成员变量、局部变量都统一使用lowerCamelCase风格，必须遵从驼峰形式。 正例：localValue getHttpMessage() inputUserId 【强制】常量命名全部大写，单词间用下划线隔开，力求语义表达完整清楚，不要嫌名字长。 正例：MAX_STOCK_COUNT 反例：MAX_COUNT 【强制】抽象类命名使用Abstract或Base开头；异常类命名使用Exception结尾；测试类命名以它要测试的类的名称开始，以Test结尾。 【强制】类型与中括号紧挨相连来表示数组。 正例：定义整形数组int[] arrayDemo; 反例：在main参数中，使用String args[]来定义。 【强制】POJO类中布尔类型的变量，都不要加is前缀，否则部分框架解析会引起序列化错误。 反例：定义为基本数据类型Boolean isDeleted的属性，它的方法也是isDeleted()，RPC框架在反向解析的时候，”误以为”对应的属性名称是deleted，导致属性获取不到，进而抛出异常。 【强制】包名统一使用小写，点分隔符之间有且仅有一个自然语义的英语单词。包名统一使用单数形式，但是类名如果有复数含义，类名可以使用复数形式。 正例：应用工具类包名为com.alibaba.ai.util、类名为MessageUtils（此规则参考spring的框架结构） 【强制】杜绝完全不规范的缩写，避免望文不知义。反例：AbstractClass“缩写”命名成AbsClass；condition“缩写”命名成 condi，此类随意缩写严重降低了代码的可阅读性。 【推荐】为了达到代码自解释的目标，任何自定义编程元素在命名时，使用尽量完整的单词组合来表达其意。正例：在JDK中，表达原子更新的类名为：AtomicReferenceFieldUpdater。反例：变量int a的随意命名方式。 【推荐】如果模块、接口、类、方法使用了设计模式，在命名时需体现出具体模式。 将设计模式体现在名字中，有利于阅读者快速理解架构设计理念。 正例： 123public class OrderFactory;public class LoginProxy;public class ResourceObserver; 【推荐】接口类中的方法和属性不要加任何修饰符号（public 也不要加），保持代码的简洁性，并加上有效的Javadoc注释。尽量不要在接口里定义变量，如果一定要定义变量，肯定是与接口方法相关，并且是整个应用的基础常量。正例： 1234//接口方法签名void commit();//接口基础常量String COMPANY = "alibaba"; 反例： 12//接口方法定义public abstract void f(); 说明：JDK 8 中接口允许有默认实现，那么这个default方法，是对所有实现类都有价值的默认实现。 接口和实现类的命名有两套规则：1 ）【强制】对于Service和DAO类，基于SOA的理念，暴露出来的服务一定是接口，内部的实现类用Impl的后缀与接口区别。正例：CacheServiceImpl实现CacheService接口。2 ） 【推荐】 如果是形容能力的接口名称，取对应的形容词为接口名（通常是–able的形式）。正例：AbstractTranslator实现 Translatable接口。 【参考】枚举类名建议带上Enum后缀，枚举成员名称需要全大写，单词间用下划线隔开。 说明：枚举其实就是特殊的类，域成员均为常量，且构造方法被默认强制是私有。 正例：枚举名字为ProcessStatusEnum的成员名称：SUCCESS、UNKNOWN_REASON。 【参考】各层命名规约：A) Service/DAO层方法命名规约1 ） 获取单个对象的方法用get做前缀。 2 ） 获取多个对象的方法用list做前缀，复数形式结尾如：listObjects。 3 ） 获取统计值的方法用count做前缀。 4 ） 插入的方法用save/insert做前缀。 5 ） 删除的方法用remove/delete做前缀。 6 ） 修改的方法用update做前缀。 B) 领域模型命名规约1 ） 数据对象：xxxDO，xxx即为数据表名。 2 ） 数据传输对象：xxxDTO，xxx为业务领域相关的名称。 3 ） 展示对象：xxxVO，xxx一般为网页名称。 4 ） POJO是DO/DTO/BO/VO的统称，禁止命名成xxxPOJO。 (二) 常量定义 【强制】不允许任何魔法值（即未经预先定义的常量）直接出现在代码中。 反例： 12String key = "Id#taobao_" + tradeId;cache.put(key, value); 【强制】在long或者Long赋值时，数值后使用大写的L，不能是小写的l，小写容易跟数字1混淆，造成误解。 说明：Long a = 2l; 写的是数字的 21 ，还是Long型的2? 【推荐】不要使用一个常量类维护所有常量，要按常量功能进行归类，分开维护。 说明：大而全的常量类，杂乱无章，使用查找功能才能定位到修改的常量，不利于理解和维护。 正例：缓存相关常量放在类CacheConsts下；系统配置相关常量放在类ConfigConsts下。 【推荐】常量的复用层次有五层：跨应用共享常量、应用内共享常量、子工程内共享常量、包内共享常量、类内共享常量。 1 ） 跨应用共享常量：放置在二方库中，通常是client.jar中的constant目录下。 2 ） 应用内共享常量：放置在一方库中，通常是子模块中的constant目录下。 反例：易懂变量也要统一定义成应用内共享常量，两位攻城师在两个类中分别定义了表示”是”的变量： 12345//类A中：public static final String YES = "yes";//类B中：public static final String YES = "y";//A.YES.equals(B.YES)，预期是true，但实际返回为false，导致线上问题。 3 ） 子工程内部共享常量：即在当前子工程的constant目录下。 4 ） 包内共享常量：即在当前包下单独的constant目录下。 5 ） 类内共享常量：直接在类内部private static final定义。 【推荐】如果变量值仅在一个固定范围内变化用enum类型来定义。 说明：如果存在名称之外的延伸属性应使用enum类型，下面正例中的数字就是延伸信息，表示一年中的第几个季节。 正例： 1234567public enum SeasonEnum &#123; SPRING( 1 ), SUMMER( 2 ), AUTUMN( 3 ), WINTER( 4 ); private int seq; SeasonEnum(int seq)&#123; this.seq = seq; &#125;&#125; (三) 代码格式 【强制】大括号的使用约定。如果是大括号内为空，则简洁地写成{}即可，不需要换行；如果是非空代码块则： 1 ） 左大括号前不换行。 2 ） 左大括号后换行。 3 ） 右大括号前换行。 4 ） 右大括号后还有else等代码则不换行；表示终止的右大括号后必须换行。 【强制】左小括号和字符之间不出现空格；同样，右小括号和字符之间也不出现空格；而左大括号前需要空格。详见第 5 条下方正例提示。 反例：if (空格a == b空格) 【强制】if/for/while/switch/do等保留字与括号之间都必须加空格。 【强制】任何二目、三目运算符的左右两边都需要加一个空格。 说明：运算符包括赋值运算符=、逻辑运算符&amp;&amp;、加减乘除符号等。 【强制】采用 4 个空格缩进，禁止使用tab字符。 说明：如果使用tab缩进，必须设置 1 个tab为 4 个空格。IDEA设置tab为 4 个空格时，请勿勾选Use tab character；而在eclipse中，必须勾选insert spaces for tabs。 正例： （涉及 1 - 5 点） 123456789101112131415161718public static void main(String[] args) &#123; // 缩进 4 个空格 String say = "hello"; // 运算符的左右必须有一个空格 int flag = 0; // 关键词if与括号之间必须有一个空格，括号内的f与左括号， 0 与右括号不需要空格 if (flag == 0) &#123; System.out.println(say); &#125; // 左大括号前加空格且不换行；左大括号后换行 if (flag == 1) &#123; System.out.println("world"); // 右大括号前换行，右大括号后有else，不用换行 &#125; else &#123; System.out.println("ok"); // 在右大括号后直接结束，则必须换行 &#125;&#125; 【强制】注释的双斜线与注释内容之间有且仅有一个空格。 正例： 12// 这是示例注释，请注意在双斜线之后有一个空格String ygb = new String(); 【强制】单行字符数限制不超过 120 个，超出需要换行，换行时遵循如下原则： 1 ） 第二行相对第一行缩进 4 个空格，从第三行开始，不再继续缩进，参考示例。 2 ） 运算符与下文一起换行。 3 ） 方法调用的点符号与下文一起换行。 4 ） 方法调用中的多个参数需要换行时，在逗号后进行。 5 ） 在括号前不要换行，见反例。 正例： 123456StringBuffer sb = new StringBuffer();// 超过 120 个字符的情况下，换行缩进 4 个空格，点号和方法名称一起换行sb.append("zi").append("xin")....append("huang")....append("huang")....append("huang"); 反例： 1234567StringBuffer sb = new StringBuffer();// 超过 120 个字符的情况下，不要在括号前换行sb.append("zi").append("xin")...append("huang");// 参数很多的方法调用可能超过 120 个字符，不要在逗号前换行method(args1, args2, args3, ..., argsX); 【强制】方法参数在定义和传入时，多个参数逗号后边必须加空格。 正例：下例中实参的args1，后边必须要有一个空格。 method(args1, args2, args3); 【强制】IDE的text file encoding设置为UTF- 8 ; IDE中文件的换行符使用Unix格式，不要使用Windows格式。 【推荐】单个方法的总行数不超过 80 行。 说明：包括方法签名、结束右大括号、方法内代码、注释、空行、回车及任何不可见字符的总行数不超过 80 行。 正例：代码逻辑分清红花和绿叶，个性和共性，绿叶逻辑单独出来成为额外方法，使主干代码更加清晰；共性逻辑抽取成为共性方法，便于复用和维护。 【推荐】没有必要增加若干空格来使某一行的字符与上一行对应位置的字符对齐。正例： 1234int one = 1;long two = 2L;float three = 3F;StringBuffer sb = new StringBuffer(); 说明：增加sb这个变量，如果需要对齐，则给a、b、c都要增加几个空格，在变量比较多的情况下，是非常累赘的事情。 【推荐】不同逻辑、不同语义、不同业务的代码之间插入一个空行分隔开来以提升可读性。 说明：任何情形，没有必要插入多个空行进行隔开。 (四) OOP规约 【强制】避免通过一个类的对象引用访问此类的静态变量或静态方法，无谓增加编译器解析成本，直接用类名来访问即可。 【强制】所有的覆写方法，必须加@Override注解。 说明：getObject()与get 0 bject()的问题。一个是字母的O，一个是数字的 0 ，加@Override可以准确判断是否覆盖成功。另外，如果在抽象类中对方法签名进行修改，其实现类会马上编译报错。 【强制】相同参数类型，相同业务含义，才可以使用Java的可变参数，避免使用Object。 说明：可变参数必须放置在参数列表的最后。（提倡同学们尽量不用可变参数编程） 正例： 1public List&lt;User&gt; listUsers(String type, Long... ids) &#123;...&#125; 【强制】外部正在调用或者二方库依赖的接口，不允许修改方法签名，避免对接口调用方产生影响。接口过时必须加@Deprecated注解，并清晰地说明采用的新接口或者新服务是什么。 【强制】不能使用过时的类或方法。 说明：java.net.URLDecoder 中的方法decode(String encodeStr) 这个方法已经过时，应该使用双参数decode(String source, String encode)。接口提供方既然明确是过时接口，那么有义务同时提供新的接口；作为调用方来说，有义务去考证过时方法的新实现是什么。 【强制】Object的equals方法容易抛空指针异常，应使用常量或确定有值的对象来调用equals。 正例：&quot;test&quot;.equals(object); 反例：object.equals(&quot;test&quot;); 说明：推荐使用java.util.Objects#equals（JDK 7 引入的工具类） 【强制】所有的相同类型的包装类对象之间值的比较，全部使用equals方法比较。 说明：对于Integer var =? 在-128 至 127 范围内的赋值，Integer对象是在IntegerCache.cache产生，会复用已有对象，这个区间内的Integer值可以直接使用==进行判断，但是这个区间之外的所有数据，都会在堆上产生，并不会复用已有对象，这是一个大坑，推荐使用equals方法进行判断。 关于基本数据类型与包装数据类型的使用标准如下： 1 ）【强制】所有的POJO类属性必须使用包装数据类型。 2 ）【强制】RPC方法的返回值和参数必须使用包装数据类型。 3 ）【推荐】所有的局部变量使用基本数据类型。 说明：POJO类属性没有初值是提醒使用者在需要使用时，必须自己显式地进行赋值，任何NPE问题，或者入库检查，都由使用者来保证。 正例：数据库的查询结果可能是null，因为自动拆箱，用基本数据类型接收有NPE风险。 反例：比如显示成交总额涨跌情况，即正负x%，x为基本数据类型，调用的RPC服务，调用不成功时，返回的是默认值，页面显示为0%，这是不合理的，应该显示成中划线。所以包装数据类型的null值，能够表示额外的信息，如：远程调用失败，异常退出。 【强制】定义DO/DTO/VO等POJO类时，不要设定任何属性默认值。 反例：POJO类的gmtCreate默认值为new Date()，但是这个属性在数据提取时并没有置入具体值，在更新其它字段时又附带更新了此字段，导致创建时间被修改成当前时间。 【强制】序列化类新增属性时，请不要修改serialVersionUID字段，避免反序列失败；如果完全不兼容升级，避免反序列化混乱，那么请修改serialVersionUID值。 说明：注意serialVersionUID不一致会抛出序列化运行时异常。 【强制】构造方法里面禁止加入任何业务逻辑，如果有初始化逻辑，请放在init方法中。 【强制】POJO类必须写toString方法。使用IDE中的工具：source&gt; generate toString时，如果继承了另一个POJO类，注意在前面加一下super.toString。 说明：在方法执行抛出异常时，可以直接调用POJO的toString()方法打印其属性值，便于排查问题。 【强制】禁止在POJO类中，同时存在对应属性xxx的isXxx()和getXxx()方法。 说明：框架在调用属性xxx的提取方法时，并不能确定哪个方法一定是被优先调用到。 【推荐】使用索引访问用String的split方法得到的数组时，需做最后一个分隔符后有无内容的检查，否则会有抛IndexOutOfBoundsException的风险。说明： 1234String str = "a,b,c,,";String[] ary = str.split(",");// 预期大于 3 ，结果是 3System.out.println(ary.length); 【推荐】当一个类有多个构造方法，或者多个同名方法，这些方法应该按顺序放置在一起，便于阅读，此条规则优先于第 16 条规则。 【推荐】 类内方法定义的顺序依次是：公有方法或保护方法 &gt; 私有方法 &gt; getter/ setter方法。 说明：公有方法是类的调用者和维护者最关心的方法，首屏展示最好；保护方法虽然只是子类关心，也可能是”模板设计模式”下的核心方法；而私有方法外部一般不需要特别关心，是一个黑盒实现；因为承载的信息价值较低，所有Service和DAO的getter/setter方法放在类体最后。 【推荐】setter方法中，参数名称与类成员变量名称一致，this.成员名 = 参数名。在getter/setter方法中，不要增加业务逻辑，增加排查问题的难度。反例： 1234567public Integer getData() &#123; if (condition) &#123; return this.data + 100; &#125; else &#123; return this.data - 100; &#125;&#125; 【推荐】循环体内，字符串的连接方式，使用StringBuilder的append方法进行扩展。 说明：下例中，反编译出的字节码文件显示每次循环都会new出一个StringBuilder对象，然后进行append操作，最后通过toString方法返回String对象，造成内存资源浪费。 反例： 1234String str = "start";for (int i = 0; i &lt; 100; i++) &#123; str = str + "hello";&#125; 【推荐】final可以声明类、成员变量、方法、以及本地变量，下列情况使用final关键字：1 ）不允许被继承的类，如：String类。2 ）不允许修改引用的域对象。3 ）不允许被重写的方法，如：POJO类的setter方法。4 ）不允许运行过程中重新赋值的局部变量。5 ）避免上下文重复使用一个变量，使用final描述可以强制重新定义一个变量，方便更好地进行重构。 【推荐】慎用Object的clone方法来拷贝对象。说明：对象的clone方法默认是浅拷贝，若想实现深拷贝需要重写clone方法实现域对象的深度遍历式拷贝。 【推荐】类成员与方法访问控制从严：1 ）如果不允许外部直接通过new来创建对象，那么构造方法必须是private。2 ）工具类不允许有public或default构造方法。3 ）类非static成员变量并且与子类共享，必须是protected。4 ）类非static成员变量并且仅在本类使用，必须是private。5 ）类static成员变量如果仅在本类使用，必须是private。6 ）若是static成员变量，考虑是否为final。7 ）类成员方法只供类内部调用，必须是private。8 ）类成员方法只对继承类公开，那么限制为protected。 说明：任何类、方法、参数、变量，严控访问范围。过于宽泛的访问范围，不利于模块解耦。 思考：如果是一个private的方法，想删除就删除，可是一个public的service成员方法或成员变量，删除一下，不得手心冒点汗吗？变量像自己的小孩，尽量在自己的视线内，变量作用域太大，无限制的到处跑，那么你会担心的。 (五) 集合处理 【强制】关于hashCode和equals的处理，遵循如下规则： 1 ）只要重写equals，就必须重写hashCode。 2 ）因为Set存储的是不重复的对象，依据hashCode和equals进行判断，所以Set存储的对象必须重写这两个方法。 3 ）如果自定义对象作为Map的键，那么必须重写hashCode和equals。 说明：String重写了hashCode和equals方法，所以我们可以非常愉快地使用String对象作为key来使用。 【强制】 ArrayList的subList结果不可强转成ArrayList，否则会抛出ClassCastException异常，即java.util.RandomAccessSubList cannot be cast to java.util.ArrayList。 说明：subList 返回的是 ArrayList的内部类 SubList，并不是 ArrayList而是ArrayList的一个视图，对于SubList子列表的所有操作最终会反映到原列表上。 【强制】在subList场景中，高度注意对原集合元素的增加或删除，均会导致子列表的遍历、增加、删除产生ConcurrentModificationException 异常。 【强制】使用集合转数组的方法，必须使用集合的toArray(T[] array)，传入的是类型完全一样的数组，大小就是list.size()。 说明：使用toArray带参方法，入参分配的数组空间不够大时，toArray方法内部将重新分配内存空间，并返回新数组地址；如果数组元素个数大于实际所需，下标为[ list.size() ]的数组元素将被置为null，其它数组元素保持原值，因此最好将方法入参数组大小定义与集合元素个数一致。 正例： 12345List&lt;String&gt; list = new ArrayList&lt;String&gt;(2);list.add("guan");list.add("bao");String[] array = new String[list.size()];array = list.toArray(array); 反例：直接使用toArray无参方法存在问题，此方法返回值只能是Object[]类，若强转其它类型数组将出现ClassCastException错误。 【强制】使用工具类Arrays.asList()把数组转换成集合时，不能使用其修改集合相关的方法，它的add/remove/clear方法会抛出UnsupportedOperationException异常。 说明：asList的返回对象是一个Arrays内部类，并没有实现集合的修改方法。Arrays.asList体现的是适配器模式，只是转换接口，后台的数据仍是数组。 123456String[] str = new String[] &#123; "you", "wu" &#125;;List list = Arrays.asList(str);//第一种情况：list.add("yangguanbao"); //运行时异常。//第二种情况：str[0] = "gujin"; //那么list.get(0)也会随之修改。 【强制】泛型通配符&lt;? extends T&gt;来接收返回的数据，此写法的泛型集合不能使用add方法，而&lt;? super T&gt;不能使用get方法，作为接口调用赋值时易出错。 说明：扩展说一下PECS(Producer Extends Consumer Super)原则：第一、频繁往外读取内容的，适合用&lt;? extends T&gt;。第二、经常往里插入的，适合用&lt;? super T&gt;。 【强制】不要在foreach循环里进行元素的remove/add操作。remove元素请使用Iterator方式，如果并发操作，需要对Iterator对象加锁。 正例： 12345678910List&lt;String&gt; list = new ArrayList&lt;&gt;();list.add("1");list.add("2");Iterator&lt;String&gt; iterator = list.iterator();while (iterator.hasNext()) &#123; String item = iterator.next(); if (删除元素的条件) &#123; iterator.remove(); &#125;&#125; 反例 12345for (String item : list) &#123; if ("1".equals(item)) &#123; list.remove(item); &#125;&#125; 说明：以上代码的执行结果肯定会出乎大家的意料，那么试一下把”1”换成”2”，会是同样的结果吗？ 【强制】 在JDK 7 版本及以上，Comparator实现类要满足如下三个条件，不然Arrays.sort，Collections.sort会报IllegalArgumentException异常。 说明：三个条件如下 1 ） x，y的比较结果和y，x的比较结果相反。 2 ） x&gt;y，y&gt;z，则x&gt;z。 3 ） x=y，则x，z比较结果和y，z比较结果相同。 反例：下例中没有处理相等的情况，实际使用中可能会出现异常： 123456new Comparator&lt;Student&gt;() &#123; @Override public int compare(Student o1, Student o2) &#123; return o1.getId() &gt; o2.getId()? 1 : -1; &#125;&#125;; 【推荐】集合泛型定义时，在JDK7及以上，使用diamond语法或全省略。 说明：菱形泛型，即diamond，直接使用&lt;&gt;来指代前边已经指定的类型。 正例： 1234//diamond方式HashMap&lt;String, String&gt; userCache = new HashMap&lt;String, String&gt;(16);//全省略方式ArrayList&lt;User&gt; users = new ArrayList(10); 【推荐】集合初始化时，指定集合初始值大小。 说明：HashMap使用HashMap(int initialCapacity) 初始化。 正例：initialCapacity = (需要存储的元素个数 / 负载因子) + 1。注意负载因子（即loaderfactor）默认为0.75，如果暂时无法确定初始值大小，请设置为 16 （即默认值）。反例：HashMap需要放置 1024 个元素，由于没有设置容量初始大小，随着元素不断增加，容量 7 次被迫扩大，resize需要重建hash表，严重影响性能。 【推荐】使用entrySet遍历Map类集合KV，而不是keySet方式进行遍历。 说明：keySet其实是遍历了 2 次，一次是转为Iterator对象，另一次是从hashMap中取出key所对应的value。而entrySet只是遍历了一次就把key和value都放到了entry中，效率更高。如果是JDK 8 ，使用Map.foreach方法。 正例：values()返回的是V值集合，是一个list集合对象；keySet()返回的是K值集合，是一个Set集合对象；entrySet()返回的是K-V值组合集合。 【推荐】高度注意Map类集合K/V能不能存储null值的情况，如下表格： 集合类 Key Value Super 说明 Hashtable 不允许为null 不允许为null Dictionary 线程安全 ConcurrentHashMap 不允许为null 不允许为null AbstractMap 锁分段技术（JDK8:CAS） TreeMap 不允许为null 允许为null AbstractMap 线程不安全 HashMap 允许为null 允许为null AbstractMap 线程不安全 反例： 由于HashMap的干扰，很多人认为ConcurrentHashMap是可以置入null值，而事实上，存储null值时会抛出NPE异常。 【参考】合理利用好集合的有序性(sort)和稳定性(order)，避免集合的无序性(unsort)和不稳定性(unorder)带来的负面影响。 说明：有序性是指遍历的结果是按某种比较规则依次排列的。稳定性指集合每次遍历的元素次序是一定的。如：ArrayList是order/unsort；HashMap是unorder/unsort；TreeSet是order/sort。 【参考】利用Set元素唯一的特性，可以快速对一个集合进行去重操作，避免使用List的contains方法进行遍历、对比、去重操作。 (六) 并发处理 【强制】获取单例对象需要保证线程安全，其中的方法也要保证线程安全。 说明：资源驱动类、工具类、单例工厂类都需要注意。 【强制】创建线程或线程池时请指定有意义的线程名称，方便出错时回溯。 正例：123456public class TimerTaskThread extends Thread &#123; public TimerTaskThread() &#123; super.setName("TimerTaskThread"); ... &#125;&#125; 【强制】线程资源必须通过线程池提供，不允许在应用中自行显式创建线程。 说明：使用线程池的好处是减少在创建和销毁线程上所消耗的时间以及系统资源的开销，解决资源不足的问题。如果不使用线程池，有可能造成系统创建大量同类线程而导致消耗完内存或者”过度切换“的问题。 【强制】线程池不允许使用Executors去创建，而是通过ThreadPoolExecutor的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。 说明：Executors返回的线程池对象的弊端如下： 1 ）FixedThreadPool和SingleThreadPool:允许的请求队列长度为Integer.MAX_VALUE，可能会堆积大量的请求，从而导致OOM。2 ）CachedThreadPool和ScheduledThreadPool:允许的创建线程数量为Integer.MAX_VALUE，可能会创建大量的线程，从而导致OOM。 【强制】SimpleDateFormat 是线程不安全的类，一般不要定义为static变量，如果定义为 static，必须加锁，或者使用DateUtils工具类。 正例：注意线程安全，使用DateUtils。亦推荐如下处理： 123456private static final ThreadLocal&lt;DateFormat&gt; df = new ThreadLocal&lt;DateFormat&gt;() &#123; @Override protected DateFormat initialValue() &#123; return new SimpleDateFormat("yyyy-MM-dd"); &#125;&#125;; 说明：如果是JDK 8 的应用，可以使用Instant代替Date，LocalDateTime代替Calendar，DateTimeFormatter代替SimpleDateFormat，官方给出的解释：simple beautiful stron immutable thread-safe。 【强制】高并发时，同步调用应该去考量锁的性能损耗。能用无锁数据结构，就不要用锁；能锁区块，就不要锁整个方法体；能用对象锁，就不要用类锁。 说明：尽可能使加锁的代码块工作量尽可能的小，避免在锁代码块中调用RPC方法。 【强制】对多个资源、数据库表、对象同时加锁时，需要保持一致的加锁顺序，否则可能会造成死锁。 说明：线程一需要对表A、B、C依次全部加锁后才可以进行更新操作，那么线程二的加锁顺序也必须是A、B、C，否则可能出现死锁。 【强制】并发修改同一记录时，避免更新丢失，需要加锁。要么在应用层加锁，要么在缓存加锁，要么在数据库层使用乐观锁，使用version作为更新依据。 说明：如果每次访问冲突概率小于20%，推荐使用乐观锁，否则使用悲观锁。乐观锁的重试次数不得小于 3 次。 【强制】多线程并行处理定时任务时，Timer运行多个TimeTask时，只要其中之一没有捕获抛出的异常，其它任务便会自动终止运行，使用ScheduledExecutorService则没有这个问题。 【推荐】使用CountDownLatch进行异步转同步操作，每个线程退出前必须调用countDown方法，线程执行代码注意catch异常，确保countDown方法被执行到，避免主线程无法执行至await方法，直到超时才返回结果。 说明：注意，子线程抛出异常堆栈，不能在主线程try-catch到。 【推荐】避免Random实例被多线程使用，虽然共享该实例是线程安全的，但会因竞争同一seed 导致的性能下降。 说明：Random实例包括java.util.Random 的实例或者 Math.random()的方式。 正例：在JDK 7 之后，可以直接使用API ThreadLocalRandom，而在 JDK 7 之前，需要编码保证每个线程持有一个实例。 【推荐】在并发场景下，通过双重检查锁（double-checked locking）实现延迟初始化的优化问题隐患(可参考 The &quot;Double-Checked Locking is Broken&quot; Declaration)，推荐解决方案中较为简单一种（适用于JDK 5 及以上版本），将目标属性声明为 volatile型。反例：1234567891011 class LazyInitDemo &#123; private Helper helper = null; public Helper getHelper() &#123; if (helper == null) synchronized(this) &#123; if (helper == null) helper = new Helper(); &#125; return helper; &#125; // other methods and fields...&#125; 【参考】volatile解决多线程内存不可见问题。对于一写多读，是可以解决变量同步问题，但是如果多写，同样无法解决线程安全问题。如果是count++操作，使用如下类实现：AtomicInteger count = new AtomicInteger(); count.addAndGet( 1 ); 如果是JDK 8 ，推荐使用LongAdder对象，比AtomicLong性能更好（减少乐观锁的重试次数）。 【参考】 HashMap在容量不够进行resize时由于高并发可能出现死链，导致CPU飙升，在开发过程中可以使用其它数据结构或加锁来规避此风险。 【参考】ThreadLocal无法解决共享对象的更新问题，ThreadLocal对象建议使用static修饰。这个变量是针对一个线程内所有操作共享的，所以设置为静态变量，所有此类实例共享此静态变量 ，也就是说在类第一次被使用时装载，只分配一块存储空间，所有此类的对象(只要是这个线程内定义的)都可以操控这个变量。 (七) 控制语句 【强制】在一个switch块内，每个case要么通过break/return等来终止，要么注释说明程序将继续执行到哪一个case为止；在一个switch块内，都必须包含一个default语句并且放在最后，即使空代码。 【强制】在if/else/for/while/do语句中必须使用大括号。即使只有一行代码，避免采用单行的编码方式：if (condition) statements; 【强制】在高并发场景中，避免使用&quot;等于&quot;判断作为中断或退出的条件。 说明：如果并发控制没有处理好，容易产生等值判断被”击穿“的情况，使用大于或小于的区间判断条件来代替。 反例：判断剩余奖品数量等于 0 时，终止发放奖品，但因为并发处理错误导致奖品数量瞬间变成了负数，这样的话，活动无法终止。 【推荐】表达异常的分支时，少用if-else方式，这种方式可以改写成： 1234if (condition) &#123;...return obj;&#125; 说明：如果非得使用if()…else if()…else…方式表达逻辑，【强制】避免后续代码维护困难，请勿超过 3 层。 正例：超过 3 层的 if-else 的逻辑判断代码可以使用卫语句、策略模式、状态模式等来实现，其中卫语句示例如下：123456789101112public void today() &#123; if (isBusy()) &#123; System.out.println("change time."); return; &#125; if (isFree()) &#123; System.out.println("go to travel."); return; &#125; System.out.println("stay at home to learn Alibaba Java Coding Guidelines."); return;&#125; 【推荐】除常用方法（如getXxx/isXxx）等外，不要在条件判断中执行其它复杂的语句，将复杂逻辑判断的结果赋值给一个有意义的布尔变量名，以提高可读性。 说明：很多if语句内的逻辑相当复杂，阅读者需要分析条件表达式的最终结果，才能明确什么样的条件执行什么样的语句，那么，如果阅读者分析逻辑表达式错误呢？ 正例： 12345// 伪代码如下final boolean existed = (file.open(fileName, "w") != null) &amp;&amp; (...) || (...);if (existed) &#123;...&#125; 反例： if ((file.open(fileName, &quot;w&quot;) != null) &amp;&amp; (...) || (...)) { ... } 【推荐】循环体中的语句要考量性能，以下操作尽量移至循环体外处理，如定义对象、变量、获取数据库连接，进行不必要的try-catch操作（这个try-catch是否可以移至循环体外）。 【推荐】避免采用取反逻辑运算符。 说明：取反逻辑不利于快速理解，并且取反逻辑写法必然存在对应的正向逻辑写法。 正例：使用if (x &lt; 628) 来表达 x 小于 628 。 反例：使用if (!(x &gt;= 628)) 来表达 x 小于 628 。 【推荐】接口入参保护，这种场景常见的是用作批量操作的接口。 【参考】下列情形，需要进行参数校验： 1 ）调用频次低的方法。 2 ）执行时间开销很大的方法。此情形中，参数校验时间几乎可以忽略不计，但如果因为参数错误导致中间执行回退，或者错误，那得不偿失。 3 ）需要极高稳定性和可用性的方法。 4 ）对外提供的开放接口，不管是RPC/API/HTTP接口。 5 ） 敏感权限入口。 【参考】下列情形，不需要进行参数校验：1 ）极有可能被循环调用的方法。但在方法说明里必须注明外部参数检查要求。2 ）底层调用频度比较高的方法。毕竟是像纯净水过滤的最后一道，参数错误不太可能到底层才会暴露问题。一般DAO层与Service层都在同一个应用中，部署在同一台服务器中，所以DAO的参数校验，可以省略。3 ）被声明成private只会被自己代码所调用的方法，如果能够确定调用方法的代码传入参数已经做过检查或者肯定不会有问题，此时可以不校验参数。 (八) 注释规约 【强制】类、类属性、类方法的注释必须使用Javadoc规范，使用/**内容*/格式，不得使用// xxx方式。 说明：在IDE编辑窗口中，Javadoc方式会提示相关注释，生成Javadoc可以正确输出相应注释；在IDE中，工程调用方法时，不进入方法即可悬浮提示方法、参数、返回值的意义，提高阅读效率。 【强制】所有的抽象方法（包括接口中的方法）必须要用Javadoc注释、除了返回值、参数、异常说明外，还必须指出该方法做什么事情，实现什么功能。 说明：对子类的实现要求，或者调用注意事项，请一并说明。 【强制】所有的类都必须添加创建者和创建日期。 【强制】方法内部单行注释，在被注释语句上方另起一行，使用//注释。方法内部多行注释使用/* */注释，注意与代码对齐。 【强制】所有的枚举类型字段必须要有注释，说明每个数据项的用途。 【推荐】与其”半吊子”英文来注释，不如用中文注释把问题说清楚。专有名词与关键字保持英文原文即可。 反例：”TCP连接超时”解释成”传输控制协议连接超时”，理解反而费脑筋。 【推荐】代码修改的同时，注释也要进行相应的修改，尤其是参数、返回值、异常、核心逻辑等的修改。 说明：代码与注释更新不同步，就像路网与导航软件更新不同步一样，如果导航软件严重滞后，就失去了导航的意义。 【参考】谨慎注释掉代码。在上方详细说明，而不是简单地注释掉。如果无用，则删除。 说明：代码被注释掉有两种可能性： 1 ）后续会恢复此段代码逻辑。 2 ）永久不用。前者如果没有备注信息，难以知晓注释动机。后者建议直接删掉（代码仓库保存了历史代码）。 【参考】对于注释的要求：第一、能够准确反应设计思想和代码逻辑；第二、能够描述业务含义，使别的程序员能够迅速了解到代码背后的信息。完全没有注释的大段代码对于阅读者形同天书，注释是给自己看的，即使隔很长时间，也能清晰理解当时的思路；注释也是给继任者看的，使其能够快速接替自己的工作。 【参考】好的命名、代码结构是自解释的，注释力求精简准确、表达到位。避免出现注释的一个极端：过多过滥的注释，代码的逻辑一旦修改，修改注释是相当大的负担。反例： 123// put elephant into fridgeput(elephant, fridge);//方法名put，加上两个有意义的变量名elephant和fridge，已经说明了这是在干什么，语义清晰的代码不需要额外的注释。 【参考】特殊注释标记，请注明标记人与标记时间。注意及时处理这些标记，通过标记扫描，经常清理此类标记。线上故障有时候就是来源于这些标记处的代码。1 ） 待办事宜（TODO）:（ 标记人，标记时间，[预计处理时间]）表示需要实现，但目前还未实现的功能。这实际上是一个Javadoc的标签，目前的Javadoc还没有实现，但已经被广泛使用。只能应用于类，接口和方法（因为它是一个Javadoc标签）2 ） 错误，不能工作（FIXME）:（标记人，标记时间，[预计处理时间]）在注释中用FIXME标记某代码是错误的，而且不能工作，需要及时纠正的情况。 (九) 其它 【强制】在使用正则表达式时，利用好其预编译功能，可以有效加快正则匹配速度。 说明：不要在方法体内定义：Pattern pattern = Pattern.compile(&quot;规则&quot;); 【强制】velocity调用POJO类的属性时，建议直接使用属性名取值即可，模板引擎会自动按规范调用POJO的getXxx()，如果是boolean基本数据类型变量（boolean命名不需要加is前缀），会自动调用isXxx()方法。 说明：注意如果是Boolean包装类对象，优先调用getXxx()的方法。 【强制】后台输送给页面的变量必须加**$!{var}——**中间的感叹号。 说明：如果var等于null或者不存在，那么${var}会直接显示在页面上。 【强制】注意 Math.random() 这个方法返回是double类型，注意取值的范围 0≤x&lt;1（能够取到零值，注意除零异常），如果想获取整数类型的随机数，不要将x放大 10 的若干倍然后取整，直接使用Random对象的nextInt或者nextLong方法。 【强制】获取当前毫秒数System.currentTimeMillis(); 而不是new Date().getTime(); 说明：如果想获取更加精确的纳秒级时间值，使用System.nanoTime()的方式。在JDK 8中，针对统计时间等场景，推荐使用Instant类。 【推荐】不要在视图模板中加入任何复杂的逻辑。 说明：根据MVC理论，视图的职责是展示，不要抢模型和控制器的活。 【推荐】任何数据结构的构造或初始化，都应指定大小，避免数据结构无限增长吃光内存。 【推荐】及时清理不再使用的代码段或配置信息。 说明：对于垃圾代码或过时配置，坚决清理干净，避免程序过度臃肿，代码冗余。 正例：对于暂时被注释掉，后续可能恢复使用的代码片断，在注释代码上方，统一规定使用三个斜杠(///)来说明注释掉代码的理由。 二、异常日志(一) 异常处理 【强制】Java 类库中定义的可以通过预检查方式规避的RuntimeException异常不应该通过catch的方式来处理，比如：NullPointerException、IndexOutOfBoundsException等等。 说明：无法通过预检查的异常除外，比如，在解析字符串形式的数字时，不得不通过catch NumberFormatException来实现。 正例：if (obj != null) {...} 反例：try { obj.method(); } catch (NullPointerException e) {...} 【强制】异常不要用来做流程控制，条件控制。 说明：异常设计的初衷是解决程序运行中的各种意外情况，且异常的处理效率比条件判断方式要低很多。 【强制】catch时请分清稳定代码和非稳定代码，稳定代码指的是无论如何不会出错的代码。对于非稳定代码的catch尽可能进行区分异常类型，再做对应的异常处理。 说明：对大段代码进行try-catch，使程序无法根据不同的异常做出正确的应激反应，也不利于定位问题，这是一种不负责任的表现。 正例：用户注册的场景中，如果用户输入非法字符，或用户名称已存在，或用户输入密码过于简单，在程序上作出分门别类的判断，并提示给用户。 【强制】捕获异常是为了处理它，不要捕获了却什么都不处理而抛弃之，如果不想处理它，请将该异常抛给它的调用者。最外层的业务使用者，必须处理异常，将其转化为用户可以理解的内容。 【强制】有try块放到了事务代码中，catch异常后，如果需要回滚事务，一定要注意手动回滚事务。 【强制】finally块必须对资源对象、流对象进行关闭，有异常也要做try-catch。 说明：如果JDK 7 及以上，可以使用try-with-resources方式。 【强制】不要在finally块中使用return。 说明：finally块中的return返回后方法结束执行，不会再执行try块中的return语句。 【强制】捕获异常与抛异常，必须是完全匹配，或者捕获异常是抛异常的父类。 说明：如果预期对方抛的是绣球，实际接到的是铅球，就会产生意外情况。 【推荐】方法的返回值可以为null，不强制返回空集合，或者空对象等，必须添加注释充分说明什么情况下会返回null值。 说明：本手册明确防止NPE是调用者的责任。即使被调用方法返回空集合或者空对象，对调用者来说，也并非高枕无忧，必须考虑到远程调用失败、序列化失败、运行时异常等场景返回null的情况。 【推荐】防止NPE，是程序员的基本修养，注意NPE产生的场景：1 ）返回类型为基本数据类型，return包装数据类型的对象时，自动拆箱有可能产生NPE。反例：public int f() { return Integer对象}， 如果为null，自动解箱抛NPE。2 ） 数据库的查询结果可能为null。3 ） 集合里的元素即使isNotEmpty，取出的数据元素也可能为null。4 ） 远程调用返回对象时，一律要求进行空指针判断，防止NPE。5 ） 对于Session中获取的数据，建议NPE检查，避免空指针。6 ） 级联调用obj.getA().getB().getC()；一连串调用，易产生NPE。正例：使用JDK8的Optional类来防止NPE问题。 【推荐】定义时区分unchecked / checked 异常，避免直接抛出new RuntimeException()，更不允许抛出Exception或者Throwable，应使用有业务含义的自定义异常。推荐业界已定义过的自定义异常，如：DAOException / ServiceException等。 【参考】对于公司外的http/api开放接口必须使用”错误码“；而应用内部推荐异常抛出；跨应用间RPC调用优先考虑使用Result方式，封装isSuccess()方法、”错误码”、”错误简短信息”。 说明：关于RPC方法返回方式使用Result方式的理由： 使用抛异常返回方式，调用方如果没有捕获到就会产生运行时错误。 如果不加栈信息，只是new自定义异常，加入自己的理解的error message，对于调用端解决问题的帮助不会太多。如果加了栈信息，在频繁调用出错的情况下，数据序列化和传输的性能损耗也是问题。 【参考】避免出现重复的代码（Don’t Repeat Yourself），即DRY原则。 说明：随意复制和粘贴代码，必然会导致代码的重复，在以后需要修改时，需要修改所有的副本，容易遗漏。必要时抽取共性方法，或者抽象公共类，甚至是组件化。 正例：一个类中有多个public方法，都需要进行数行相同的参数校验操作，这个时候请抽取： 1private boolean checkParam(DTO dto) &#123;...&#125; (二) 日志规约 【强制】应用中不可直接使用日志系统（Log4j、Logback）中的API，而应依赖使用日志框架SLF4J中的API，使用门面模式的日志框架，有利于维护和各个类的日志处理方式统一。 123import org.slf4j.Logger;import org.slf4j.LoggerFactory;private static final Logger logger = LoggerFactory.getLogger(Abc.class); 【强制】日志文件至少保存 15 天，因为有些异常具备以”周”为频次发生的特点。 【强制】应用中的扩展日志（如打点、临时监控、访问日志等）命名方式：appName_logType_logName.log。logType:日志类型，如stats/monitor/access等；logName:日志描述。这种命名的好处：通过文件名就可知道日志文件属于什么应用，什么类型，什么目的，也有利于归类查找。 正例：mppserver应用中单独监控时区转换异常，如：ppserver_monitor_timeZoneConvert.log 说明：推荐对日志进行分类，如将错误日志和业务日志分开存放，便于开发人员查看，也便于通过日志对系统进行及时监控。 【强制】对trace/debug/info级别的日志输出，必须使用条件输出形式或者使用占位符的方式。 说明：logger.debug(&quot;Processing trade with id: &quot; + id + &quot; and symbol: &quot; + symbol);如果日志级别是warn，上述日志不会打印，但是会执行字符串拼接操作，如果symbol是对象，会执行toString()方法，浪费了系统资源，执行了上述操作，最终日志却没有打印。 正例：（条件）建设采用如下方式 123if (logger.isDebugEnabled()) &#123; logger.debug("Processing trade with id: " + id + " and symbol: " + symbol);&#125; 正例：（占位符） 1logger.debug("Processing trade with id: &#123;&#125; and symbol : &#123;&#125; ", id, symbol); 【强制】避免重复打印日志，浪费磁盘空间，务必在log4j.xml中设置additivity=false。 正例： 1&lt;logger name="com.taobao.dubbo.config" additivity="false"&gt; 【强制】异常信息应该包括两类信息：案发现场信息和异常堆栈信息。如果不处理，那么通过关键字throws往上抛出。 正例：logger.error(各类参数或者对象toString() + &quot;_&quot; + e.getMessage(), e); 【推荐】谨慎地记录日志。生产环境禁止输出debug日志；有选择地输出info日志；如果使用warn来记录刚上线时的业务行为信息，一定要注意日志输出量的问题，避免把服务器磁盘撑爆，并记得及时删除这些观察日志。 说明：大量地输出无效日志，不利于系统性能提升，也不利于快速定位错误点。记录日志时请思考：这些日志真的有人看吗？看到这条日志你能做什么？能不能给问题排查带来好处？ 【推荐】可以使用warn日志级别来记录用户输入参数错误的情况，避免用户投诉时，无所适从。如非必要，请不要在此场景打出error级别，避免频繁报警。 说明：注意日志输出的级别，error级别只记录系统逻辑出错、异常或者重要的错误信息。 【推荐】尽量用英文来描述日志错误信息，如果日志中的错误信息用英文描述不清楚的话使用中文描述即可，否则容易产生歧义。国际化团队或海外部署的服务器由于字符集问题，【强制】使用全英文来注释和描述日志错误信息。 三、单元测试 【强制】好的单元测试必须遵守AIR原则。 说明：单元测试在线上运行时，感觉像空气（AIR）一样并不存在，但在测试质量的保障上，却是非常关键的。好的单元测试宏观上来说，具有自动化、独立性、可重复执行的特点。 A：Automatic（自动化） I：Independent（独立性） R：Repeatable（可重复） 【强制】单元测试应该是全自动执行的，并且非交互式的。测试用例通常是被定期执行的，执行过程必须完全自动化才有意义。输出结果需要人工检查的测试不是一个好的单元测试。单元测试中不准使用System.out来进行人肉验证，必须使用assert来验证。 【强制】保持单元测试的独立性。为了保证单元测试稳定可靠且便于维护，单元测试用例之间决不能互相调用，也不能依赖执行的先后次序。 反例：method2需要依赖method1的执行，将执行结果作为method2的输入。 【强制】单元测试是可以重复执行的，不能受到外界环境的影响。 说明：单元测试通常会被放到持续集成中，每次有代码check in时单元测试都会被执行。如果单测对外部环境（网络、服务、中间件等）有依赖，容易导致持续集成机制的不可用。 正例：为了不受外界环境影响，要求设计代码时就把SUT的依赖改成注入，在测试时用spring这样的DI框架注入一个本地（内存）实现或者Mock实现。 【强制】对于单元测试，要保证测试粒度足够小，有助于精确定位问题。单测粒度至多是类级别，一般是方法级别。 说明：只有测试粒度小才能在出错时尽快定位到出错位置。单测不负责检查跨类或者跨系统的交互逻辑，那是集成测试的领域。 【强制】核心业务、核心应用、核心模块的增量代码确保单元测试通过。 说明：新增代码及时补充单元测试，如果新增代码影响了原有单元测试，请及时修正。 【强制】单元测试代码必须写在如下工程目录：src/test/java，不允许写在业务代码目录下。 说明：源码构建时会跳过此目录，而单元测试框架默认是扫描此目录。 【推荐】单元测试的基本目标：语句覆盖率达到70%；核心模块的语句覆盖率和分支覆盖率都要达到100% 说明：在工程规约的应用分层中提到的DAO层，Manager层，可重用度高的Service，都应该进行单元测试。 【推荐】编写单元测试代码遵守BCDE原则，以保证被测试模块的交付质量。 B：Border，边界值测试，包括循环边界、特殊取值、特殊时间点、数据顺序等。 C：Correct，正确的输入，并得到预期的结果。 D：Design，与设计文档相结合，来编写单元测试。 E：Error，强制错误信息输入（如：非法数据、异常流程、非业务允许输入等），并得到预期的结果。 【推荐】对于数据库相关的查询，更新，删除等操作，不能假设数据库里的数据是存在的，或者直接操作数据库把数据插入进去，请使用程序插入或者导入数据的方式来准备数据。反例：删除某一行数据的单元测试，在数据库中，先直接手动增加一行作为删除目标，但是这一行新增数据并不符合业务插入规则，导致测试结果异常。 【推荐】和数据库相关的单元测试，可以设定自动回滚机制，不给数据库造成脏数据。或者对单元测试产生的数据有明确的前后缀标识。 正例：在RDC内部单元测试中，使用RDC_UNIT_TEST_的前缀标识数据。 【推荐】对于不可测的代码建议做必要的重构，使代码变得可测，避免为了达到测试要求而书写不规范测试代码。 【推荐】在设计评审阶段，开发人员需要和测试人员一起确定单元测试范围，单元测试最好覆盖所有测试用例。 【推荐】单元测试作为一种质量保障手段，不建议项目发布后补充单元测试用例，建议在项目提测前完成单元测试。 【参考】为了更方便地进行单元测试，业务代码应避免以下情况： 构造方法中做的事情过多。 存在过多的全局变量和静态方法。 存在过多的外部依赖。 存在过多的条件语句。说明：多层条件语句建议使用卫语句、策略模式、状态模式等方式重构。 【参考】不要对单元测试存在如下误解： 那是测试同学干的事情。本文是开发手册，凡是本文内容都是与开发同学强相关的。 单元测试代码是多余的。系统的整体功能与各单元部件的测试正常与否是强相关的。 单元测试代码不需要维护。一年半载后，那么单元测试几乎处于废弃状态。 单元测试与线上故障没有辩证关系。好的单元测试能够最大限度地规避线上故障。 四、安全规约 【强制】隶属于用户个人的页面或者功能必须进行权限控制校验。 说明：防止没有做水平权限校验就可随意访问、修改、删除别人的数据，比如查看他人的私信内容、修改他人的订单。 【强制】用户敏感数据禁止直接展示，必须对展示数据进行脱敏。 说明：中国大陆个人手机号码显示为:158**9119，隐藏中间 4 位，防止隐私泄露。 【强制】用户输入的SQL参数严格使用参数绑定或者METADATA字段值限定，防止SQL注入，禁止字符串拼接SQL访问数据库。 【强制】用户请求传入的任何参数必须做有效性验证。 说明：忽略参数校验可能导致： page size过大导致内存溢出 恶意order by导致数据库慢查询 任意重定向 SQL注入 反序列化注入 正则输入源串拒绝服务ReDoS说明：Java代码用正则来验证客户端的输入，有些正则写法验证普通用户输入没有问题，但是如果攻击人员使用的是特殊构造的字符串来验证，有可能导致死循环的结果。 【强制】禁止向HTML页面输出未经安全过滤或未正确转义的用户数据。 【强制】表单、AJAX提交必须执行CSRF安全验证。 说明：CSRF(Cross-site request forgery)跨站请求伪造是一类常见编程漏洞。对于存在CSRF漏洞的应用/网站，攻击者可以事先构造好URL，只要受害者用户一访问，后台便在用户不知情的情况下对数据库中用户参数进行相应修改。 【强制】在使用平台资源，譬如短信、邮件、电话、下单、支付，必须实现正确的防重放的机制，如数量限制、疲劳度控制、验证码校验，避免被滥刷而导致资损。 说明：如注册时发送验证码到手机，如果没有限制次数和频率，那么可以利用此功能骚扰到其它用户，并造成短信平台资源浪费。 【推荐】发贴、评论、发送即时消息等用户生成内容的场景必须实现防刷、文本内容违禁词过滤等风控策略。 五、MySQL数据库(一) 建表规约 【强制】表达是与否概念的字段，必须使用is_xxx的方式命名，数据类型是unsigned tinyint（ 1 表示是， 0 表示否）。 说明：任何字段如果为非负数，必须是unsigned。 注意：POJO类中的任何布尔类型的变量，都不要加is前缀，所以，需要在&lt;resultMap&gt;设置从is_xxx到Xxx的映射关系。数据库表示是与否的值，使用tinyint类型，坚持is_xxx的命名方式是为了明确其取值含义与取值范围。 正例：表达逻辑删除的字段名is_deleted， 1 表示删除， 0 表示未删除。 【强制】表名、字段名必须使用小写字母或数字，禁止出现数字开头，禁止两个下划线中间只出现数字。数据库字段名的修改代价很大，因为无法进行预发布，所以字段名称需要慎重考虑。 说明：MySQL在Windows下不区分大小写，但在Linux下默认是区分大小写。因此，数据库名、表名、字段名，都不允许出现任何大写字母，避免节外生枝。 正例：aliyun_admin，rdc_config，level3_name 反例：AliyunAdmin，rdcConfig，level_3_name 【强制】表名不使用复数名词。 说明：表名应该仅仅表示表里面的实体内容，不应该表示实体数量，对应于DO类名也是单数形式，符合表达习惯。 【强制】禁用保留字，如desc、range、match、delayed等，请参考MySQL官方保留字。 【强制】主键索引名为pk_字段名；唯一索引名为uk_字段名；普通索引名则为idx_字段名。 说明：pk_ 即primary key；uk_ 即 unique key；idx_ 即index的简称。 【强制】小数类型为decimal，禁止使用float和double。 说明：float和double在存储的时候，存在精度损失的问题，很可能在值的比较时，得到不正确的结果。如果存储的数据范围超过decimal的范围，建议将数据拆成整数和小数分开存储。 【强制】如果存储的字符串长度几乎相等，使用char定长字符串类型。 【强制】varchar是可变长字符串，不预先分配存储空间，长度不要超过 5000 ，如果存储长度大于此值，定义字段类型为text，独立出来一张表，用主键来对应，避免影响其它字段索引效率。 【强制】表必备三字段：id, gmt_create, gmt_modified。 说明：其中id必为主键，类型为bigint unsigned、单表时自增、步长为 1 。gmt_create,gmt_modified的类型均为datetime类型，前者现在时表示主动创建，后者过去分词表示被动更新。 【推荐】表的命名最好是加上”业务名称_表的作用”。正例：alipay_task / force_project / trade_config 【推荐】库名与应用名称尽量一致。 【推荐】如果修改字段含义或对字段表示的状态追加时，需要及时更新字段注释。 【推荐】字段允许适当冗余，以提高查询性能，但必须考虑数据一致。冗余字段应遵循：1 ）不是频繁修改的字段。2 ）不是varchar超长字段，更不能是text字段。正例：商品类目名称使用频率高，字段长度短，名称基本一成不变，可在相关联的表中冗余存储类目名称，避免关联查询。 【推荐】单表行数超过 500 万行或者单表容量超过 2 GB，才推荐进行分库分表。 说明：如果预计三年后的数据量根本达不到这个级别，请不要在创建表时就分库分表。 【参考】合适的字符存储长度，不但节约数据库表空间、节约索引存储，更重要的是提升检索速度。正例：如下表，其中无符号值可以避免误存负数，且扩大了表示范围。 对象 年龄区间 类型 字节 表示范围 人 150岁之内 tinyint unsigned 1 无符号值： 0 到 255 龟 数百岁 smallint unsigned 2 无符号值： 0 到 65535 恐龙化石 数千万年 int unsigned 4 无符号值： 0 到约42.9亿 太阳 约 50 亿年 bigint unsigned 8 无符号值： 0 到约 10 的 19 次方 (二) 索引规约 【强制】业务上具有唯一特性的字段，即使是多个字段的组合，也必须建成唯一索引。 说明：不要以为唯一索引影响了insert速度，这个速度损耗可以忽略，但提高查找速度是明显的；另外，即使在应用层做了非常完善的校验控制，只要没有唯一索引，根据墨菲定律，必然有脏数据产生。 【强制】超过三个表禁止join。需要join的字段，数据类型必须绝对一致；多表关联查询时，保证被关联的字段需要有索引。 说明：即使双表join也要注意表索引、SQL性能。 【强制】在varchar字段上建立索引时，必须指定索引长度，没必要对全字段建立索引，根据实际文本区分度决定索引长度即可。 说明：索引的长度与区分度是一对矛盾体，一般对字符串类型数据，长度为 20 的索引，区分度会高达90%以上，可以使用count(distinct left(列名, 索引长度))/count(*)的区分度来确定。 【强制】页面搜索严禁左模糊或者全模糊，如果需要请走搜索引擎来解决。 说明：索引文件具有B-Tree的最左前缀匹配特性，如果左边的值未确定，那么无法使用此索引。 【推荐】如果有order by的场景，请注意利用索引的有序性。order by 最后的字段是组合索引的一部分，并且放在索引组合顺序的最后，避免出现file_sort的情况，影响查询性能。 正例：where a=? and b=? order by c; 索引：a_b_c 反例：索引中有范围查找，那么索引有序性无法利用，如：WHERE a&gt;10 ORDER BY b; 索引a_b无法排序。 【推荐】利用覆盖索引来进行查询操作，避免回表。 说明：如果一本书需要知道第 11 章是什么标题，会翻开第 11 章对应的那一页吗？目录浏览一下就好，这个目录就是起到覆盖索引的作用。 正例：能够建立索引的种类分为主键索引、唯一索引、普通索引三种，而覆盖索引只是一种查询的一种效果，用explain的结果，extra列会出现：using index。 【推荐】利用延迟关联或者子查询优化超多分页场景。 说明：MySQL并不是跳过offset行，而是取offset+N行，然后返回放弃前offset行，返回N行，那当offset特别大的时候，效率就非常的低下，要么控制返回的总页数，要么对超过特定阈值的页数进行SQL改写。 正例：先快速定位需要获取的id段，然后再关联： 1SELECT a.* FROM 表1 a, (select id from 表1 where 条件 LIMIT 100000,20 ) b where a.id=b.id 【推荐】 SQL性能优化的目标：至少要达到 range 级别，要求是ref级别，如果可以是consts最好。 说明： 1 ）consts 单表中最多只有一个匹配行（主键或者唯一索引），在优化阶段即可读取到数据。 2 ）ref 指的是使用普通的索引（normal index）。 3 ）range 对索引进行范围检索。 反例：explain表的结果，type=index，索引物理文件全扫描，速度非常慢，这个index级别比较range还低，与全表扫描是小巫见大巫。 【推荐】建组合索引的时候，区分度最高的在最左边。 正例：如果where a=? and b=? ，如果a列的几乎接近于唯一值，那么只需要单建idx_a索引即可。 说明：存在非等号和等号混合时，在建索引时，请把等号条件的列前置。如：where c&gt;? and d=? 那么即使c的区分度更高，也必须把d放在索引的最前列，即索引idx_d_c。 【推荐】防止因字段类型不同造成的隐式转换，导致索引失效。 【参考】创建索引时避免有如下极端误解：1 ）宁滥勿缺。认为一个查询就需要建一个索引。2 ）宁缺勿滥。认为索引会消耗空间、严重拖慢更新和新增速度。3 ）抵制惟一索引。认为业务的惟一性一律需要在应用层通过”先查后插”方式解决。 (三) SQL语句 【强制】不要使用count(列名)或count(常量)来替代count(*)，count(*)是SQL 92 定义的标准统计行数的语法，跟数据库无关，跟NULL和非NULL无关。 说明：count(*)会统计值为NULL的行，而count(列名)不会统计此列为NULL值的行。 【强制】count(distinct col) 计算该列除NULL之外的不重复行数，注意 count(distinct col1, col 2 ) 如果其中一列全为NULL，那么即使另一列有不同的值，也返回为 0 。 【强制】当某一列的值全是NULL时，count(col)的返回结果为 0 ，但sum(col)的返回结果为NULL，因此使用sum()时需注意NPE问题。 正例：可以使用如下方式来避免sum的NPE问题：SELECT IF(ISNULL(SUM(g)),0,SUM(g)) FROM table; 【强制】使用ISNULL()来判断是否为NULL值。 说明：NULL与任何值的直接比较都为NULL。 1 ） NULL&lt;&gt;NULL的返回结果是NULL，而不是false。 2 ） NULL=NULL的返回结果是NULL，而不是true。 3 ） NULL&lt;&gt;1的返回结果是NULL，而不是true。 【强制】 在代码中写分页查询逻辑时，若count为 0 应直接返回，避免执行后面的分页语句。 【强制】不得使用外键与级联，一切外键概念必须在应用层解决。 说明：以学生和成绩的关系为例，学生表中的student_id是主键，那么成绩表中的student_id则为外键。如果更新学生表中的student_id，同时触发成绩表中的student_id更新，即为级联更新。外键与级联更新适用于单机低并发，不适合分布式、高并发集群；级联更新是强阻塞，存在数据库更新风暴的风险；外键影响数据库的插入速度。 【强制】禁止使用存储过程，存储过程难以调试和扩展，更没有移植性。 【强制】数据订正（特别是删除、修改记录操作）时，要先select，避免出现误删除，确认无误才能执行更新语句。 【推荐】in操作能避免则避免，若实在避免不了，需要仔细评估in后边的集合元素数量，控制在 1000 个之内。 【参考】如果有国际化需要，所有的字符存储与表示，均以utf-8 编码，注意字符统计函数的区别。 说明： SELECT LENGTH(&quot;轻松工作&quot;)； 返回为 12 SELECT CHARACTER_LENGTH(&quot;轻松工作&quot;)； 返回为 4 如果需要存储表情，那么选择utf8mb4来进行存储，注意它与utf-8编码的区别。 【参考】TRUNCATE TABLE 比 DELETE 速度快，且使用的系统和事务日志资源少，但TRUNCATE无事务且不触发trigger，有可能造成事故，故不建议在开发代码中使用此语句。 说明：TRUNCATE TABLE 在功能上与不带 WHERE 子句的 DELETE 语句相同。 (四) ORM映射 【强制】在表查询中，一律不要使用 * 作为查询的字段列表，需要哪些字段必须明确写明。 说明： 1 ）增加查询分析器解析成本。 2 ）增减字段容易与resultMap配置不一致。 3 ）无用字段增加网络消耗，尤其是text类型的字段。 【强制】POJO类的布尔属性不能加is，而数据库字段必须加is_，要求在resultMap中进行字段与属性之间的映射。 说明：参见定义POJO类以及数据库字段定义规定，在&lt;resultMap&gt;中增加映射，是必须的。在MyBatis Generator生成的代码中，需要进行对应的修改。 【强制】不要用resultClass当返回参数，即使所有类属性名与数据库字段一一对应，也需要定义；反过来，每一个表也必然有一个POJO类与之对应。 说明：配置映射关系，使字段与DO类解耦，方便维护。 【强制】sql.xml配置参数使用：#{}，#param# 不要使用${} 此种方式容易出现SQL注入。 【强制】iBATIS自带的queryForList(String statementName,int start,int size)不推荐使用。 说明：其实现方式是在数据库取到statementName对应的SQL语句的所有记录，再通过subList取start,size的子集合。 正例： Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put("start", start); map.put("size", size); 【强制】不允许直接拿HashMap与Hashtable作为查询结果集的输出。 说明：resultClass=&quot;Hashtable&quot;，会置入字段名和属性值，但是值的类型不可控。 【强制】更新数据表记录时，必须同时更新记录对应的gmt_modified字段值为当前时间段，都进行update table set c1=value1,c2=value2,c3=value3; 这是不对的。执行SQL时，不要更新无改动的字段，一是易出错；二是效率低；三是增加binlog存储。 【参考】@Transactional事务不要滥用。事务会影响数据库的QPS，另外使用事务的地方需要考虑各方面的回滚方案，包括缓存回滚、搜索引擎回滚、消息补偿、统计修正等。 【参考】&lt;isEqual&gt;中的compareValue是与属性值对比的常量，一般是数字，表示相等时带上此条件；&lt;isNotEmpty&gt;表示不为空且不为null时执行；&lt;isNotNull&gt;表示不为null值时执行。 六、工程结构(一) 应用分层 【推荐】图中默认上层依赖于下层，箭头关系表示可直接依赖，如：开放接口层可以依赖于Web层，也可以直接依赖于Service层，依此类推： 开放接口层：可直接封装Service方法暴露成RPC接口；通过Web封装成http接口；进行网关安全控制、流量控制等。 终端显示层：各个端的模板渲染并执行显示的层。当前主要是velocity渲染，JS渲染，JSP渲染，移动端展示等。 Web层：主要是对访问控制进行转发，各类基本参数校验，或者不复用的业务简单处理等。 Service层：相对具体的业务逻辑服务层。 Manager层：通用业务处理层，它有如下特征： 1 ） 对第三方平台封装的层，预处理返回结果及转化异常信息； 2 ） 对Service层通用能力的下沉，如缓存方案、中间件通用处理； 3 ） 与DAO层交互，对多个DAO的组合复用。 DAO层：数据访问层，与底层MySQL、Oracle、Hbase等进行数据交互。 外部接口或第三方平台：包括其它部门RPC开放接口，基础平台，其它公司的HTTP接口。 【参考】（分层异常处理规约）在DAO层，产生的异常类型有很多，无法用细粒度的异常进行catch，使用catch(Exception e)方式，并throw new DAOException(e)，不需要打印日志，因为日志在Manager/Service层一定需要捕获并打印到日志文件中去，如果同台服务器再打日志，浪费性能和存储。在Service层出现异常时，必须记录出错日志到磁盘，尽可能带上参数信息，相当于保护案发现场。如果Manager层与Service同机部署，日志方式与DAO层处理一致，如果是单独部署，则采用与Service一致的处理方式。Web层绝不应该继续往上抛异常，因为已经处于顶层，如果意识到这个异常将导致页面无法正常渲染，那么就应该直接跳转到友好错误页面，加上用户容易理解的错误提示信息。开放接口层要将异常处理成错误码和错误信息方式返回。 【参考】分层领域模型规约： DO（Data Object）：此对象与数据库表结构一一对应，通过DAO层向上传输数据源对象。 DTO（Data Transfer Object）：数据传输对象，Service或Manager向外传输的对象。 BO（Business Object）：业务对象，由Service层输出的封装业务逻辑的对象。 AO（Application Object）：应用对象，在Web层与Service层之间抽象的复用对象模型，极为贴近展示层，复用度不高。 VO（View Object）：显示层对象，通常是Web向模板渲染引擎层传输的对象。 Query：数据查询对象，各层接收上层的查询请求。注意超过 2 个参数的查询封装，禁止使用Map类来传输。 (二) 二方库依赖 【强制】定义GAV遵从以下规则： 1 ） GroupID格式：com.{公司/BU }.业务线 [.子业务线]，最多 4 级。 说明：{公司/BU} 例如：alibaba/taobao/tmall/aliexpress等BU一级；子业务线可选。 正例：com.taobao.jstorm 或 com.alibaba.dubbo.register 2 ） ArtifactID格式：产品线名-模块名。语义不重复不遗漏，先到中央仓库去查证一下。 正例：dubbo-client / fastjson-api / jstorm-tool 3 ） Version：详细规定参考下方。 【强制】二方库版本号命名方式：主版本号.次版本号.修订号 1 ） 主版本号：产品方向改变，或者大规模API不兼容，或者架构不兼容升级。 2 ） 次版本号：保持相对兼容性，增加主要功能特性，影响范围极小的API不兼容修改。 3 ） 修订号：保持完全兼容性，修复BUG、新增次要功能特性等。 说明：注意起始版本号必须为：1.0.0，而不是0.0.1 正式发布的类库必须先去中央仓库进行查证，使版本号有延续性，正式版本号不允许覆盖升级。如当前版本：1.3.3，那么下一个合理的版本号：1.3.4 或 1.4.0 或 2.0.0 【强制】线上应用不要依赖SNAPSHOT版本（安全包除外）。 说明：不依赖SNAPSHOT版本是保证应用发布的幂等性。另外，也可以加快编译时的打包构建。 【强制】二方库的新增或升级，保持除功能点之外的其它jar包仲裁结果不变。如果有改变，必须明确评估和验证，建议进行dependency:resolve前后信息比对，如果仲裁结果完全不一致，那么通过dependency:tree命令，找出差异点，进行&lt;excludes&gt;排除jar包。 【强制】二方库里可以定义枚举类型，参数可以使用枚举类型，但是接口返回值不允许使用枚举类型或者包含枚举类型的POJO对象。 【强制】依赖于一个二方库群时，必须定义一个统一的版本变量，避免版本号不一致。 说明：依赖springframework-core,-context,-beans，它们都是同一个版本，可以定义一个变量来保存版本：${spring.version}，定义依赖的时候，引用该版本。 【强制】禁止在子项目的pom依赖中出现相同的GroupId，相同的ArtifactId，但是不同的Version。 说明：在本地调试时会使用各子项目指定的版本号，但是合并成一个war，只能有一个版本号出现在最后的lib目录中。可能出现线下调试是正确的，发布到线上却出故障的问题。 【推荐】所有pom文件中的依赖声明放在&lt;dependencies&gt;语句块中，所有版本仲裁放在&lt;dependencyManagement&gt;语句块中。 说明：&lt;dependencyManagement&gt;里只是声明版本，并不实现引入，因此子项目需要显式的声明依赖，version和scope都读取自父pom。而&lt;dependencies&gt;所有声明在主pom的&lt;dependencies&gt;里的依赖都会自动引入，并默认被所有的子项目继承。 【推荐】二方库不要有配置项，最低限度不要再增加配置项。 【参考】为避免应用二方库的依赖冲突问题，二方库发布者应当遵循以下原则：1 ）精简可控原则。移除一切不必要的API和依赖，只包含 Service API、必要的领域模型对象、Utils类、常量、枚举等。如果依赖其它二方库，尽量是provided引入，让二方库使用者去依赖具体版本号；无log具体实现，只依赖日志框架。2 ）稳定可追溯原则。每个版本的变化应该被记录，二方库由谁维护，源码在哪里，都需要能方便查到。除非用户主动升级版本，否则公共二方库的行为不应该发生变化。 (三) 服务器 【推荐】高并发服务器建议调小TCP协议的time_wait超时时间。 说明：操作系统默认 240 秒后，才会关闭处于time_wait状态的连接，在高并发访问下，服务器端会因为处于time_wait的连接数太多，可能无法建立新的连接，所以需要在服务器上调小此等待值。 正例：在linux服务器上请通过变更/etc/sysctl.conf文件去修改该缺省值（秒）： net.ipv4.tcp_fin_timeout = 30 【推荐】调大服务器所支持的最大文件句柄数（File Descriptor，简写为fd）。 说明：主流操作系统的设计是将TCP/UDP连接采用与文件一样的方式去管理，即一个连接对应于一个fd。主流的linux服务器默认所支持最大fd数量为 1024 ，当并发连接数很大时很容易因为fd不足而出现”open too many files“错误，导致新的连接无法建立。 建议将linux服务器所支持的最大句柄数调高数倍（与服务器的内存数量相关）。 【推荐】给JVM环境参数设置-XX:+HeapDumpOnOutOfMemoryError参数，让JVM碰到OOM场景时输出dump信息。 说明：OOM的发生是有概率的，甚至相隔数月才出现一例，出错时的堆内信息对解决问题非常有帮助。 【推荐】在线上生产环境，JVM的Xms和Xmx设置一样大小的内存容量，避免在GC 后调整堆大小带来的压力。 【参考】服务器内部重定向使用forward；外部重定向地址使用URL拼装工具类来生成，否则会带来URL维护不一致的问题和潜在的安全风险。 七、设计规约 【强制】存储方案和底层数据结构的设计获得评审一致通过，并沉淀成为文档。 说明：有缺陷的底层数据结构容易导致系统风险上升，可扩展性下降，重构成本也会因历史数据迁移和系统平滑过渡而陡然增加，所以，存储方案和数据结构需要认真地进行设计和评审，生产环境提交执行后，需要进行double check。 正例：评审内容包括存储介质选型、表结构设计能否满足技术方案、存取性能和存储空间能否满足业务发展、表或字段之间的辩证关系、字段名称、字段类型、索引等；数据结构变更（如在原有表中新增字段）也需要进行评审通过后上线。 【强制】在需求分析阶段，如果与系统交互的User超过一类并且相关的User Case超过 5 个，使用用例图来表达更加清晰的结构化需求。 【强制】如果某个业务对象的状态超过 3 个，使用状态图来表达并且明确状态变化的各个触发条件。 说明：状态图的核心是对象状态，首先明确对象有多少种状态，然后明确两两状态之间是否存在直接转换关系，再明确触发状态转换的条件是什么。 正例：淘宝订单状态有已下单、待付款、已付款、待发货、已发货、已收货等。比如已下单与已收货这两种状态之间是不可能有直接转换关系的。 【强制】如果系统中某个功能的调用链路上的涉及对象超过 3 个，使用时序图来表达并且明确各调用环节的输入与输出。 说明：时序图反映了一系列对象间的交互与协作关系，清晰立体地反映系统的调用纵深链路。 【强制】如果系统中模型类超过 5 个，并且存在复杂的依赖关系，使用类图来表达并且明确类之间的关系。 说明：类图像建筑领域的施工图，如果搭平房，可能不需要，但如果建造蚂蚁Z空间大楼，肯定需要详细的施工图。 【强制】如果系统中超过 2 个对象之间存在协作关系，并且需要表示复杂的处理流程，使用活动图来表示。 说明：活动图是流程图的扩展，增加了能够体现协作关系的对象泳道，支持表示并发等。 【推荐】需求分析与系统设计在考虑主干功能的同时，需要充分评估异常流程与业务边界。 反例：用户在淘宝付款过程中，银行扣款成功，发送给用户扣款成功短信，但是支付宝入款时由于断网演练产生异常，淘宝订单页面依然显示未付款，导致用户投诉。 【推荐】类在设计与实现时要符合单一原则。 说明：单一原则最易理解却是最难实现的一条规则，随着系统演进，很多时候，忘记了类设计的初衷。 【推荐】谨慎使用继承的方式来进行扩展，优先使用聚合/组合的方式来实现。 说明：不得已使用继承的话，必须符合里氏代换原则，此原则说父类能够出现的地方子类一定能够出现，比如，”把钱交出来”，钱的子类美元、欧元、人民币等都可以出现。 【推荐】系统设计时，根据依赖倒置原则，尽量依赖抽象类与接口，有利于扩展与维护。 说明：低层次模块依赖于高层次模块的抽象，方便系统间的解耦。 【推荐】系统设计时，注意对扩展开放，对修改闭合。 说明：极端情况下，交付的代码都是不可修改的，同一业务域内的需求变化，通过模块或类的扩展来实现。 【推荐】系统设计阶段，共性业务或公共行为抽取出来公共模块、公共配置、公共类、公共方法等，避免出现重复代码或重复配置的情况。 说明：随着代码的重复次数不断增加，维护成本指数级上升。 【推荐】避免如下误解：敏捷开发 = 讲故事 + 编码 + 发布。 说明：敏捷开发是快速交付迭代可用的系统，省略多余的设计方案，摒弃传统的审批流程，但核心关键点上的必要设计和文档沉淀是需要的。 反例：某团队为了业务快速发展，敏捷成了产品经理催进度的借口，系统中均是勉强能运行但像面条一样的代码，可维护性和可扩展性极差，一年之后，不得不进行大规模重构，得不偿失。 【参考】系统设计主要目的是明确需求、理顺逻辑、后期维护，次要目的用于指导编码。 说明：避免为了设计而设计，系统设计文档有助于后期的系统维护，所以设计结果需要进行分类归档保存。 【参考】设计的本质就是识别和表达系统难点，找到系统的变化点，并隔离变化点。 说明：世间众多设计模式目的是相同的，即隔离系统变化点。 【参考】系统架构设计的目的： 确定系统边界。确定系统在技术层面上的做与不做。 确定系统内模块之间的关系。确定模块之间的依赖关系及模块的宏观输入与输出。 确定指导后续设计与演化的原则。使后续的子系统或模块设计在规定的框架内继续演化。 确定非功能性需求。非功能性需求是指安全性、可用性、可扩展性等。 八、附录专有名词解释 POJO（Plain Ordinary Java Object）: 在本手册中，POJO专指只有setter / getter / toString的简单类，包括DO/DTO/BO/VO等。 GAV（GroupId、ArtifactctId、Version）: Maven坐标，是用来唯一标识jar包。 OOP（Object Oriented Programming）: 本手册泛指类、对象的编程处理方式。 ORM（Object Relation Mapping）: 对象关系映射，对象领域模型与底层数据之间的转换，本文泛指iBATIS, mybatis等框架。 NPE（java.lang.NullPointerException）: 空指针异常。 SOA（Service-Oriented Architecture）: 面向服务架构，它可以根据需求通过网络对松散以耦以的粗粒度应用组件进行分布式部署、组合和使用，有利于提升组件可重用性，可维护性。 IDE（Integrated Development Environment）: 用于提供程序开发环境的应用程序，一般包括代码编辑器、编译器、调试器和图形用户界面等工具，本《手册》泛指IntelliJ IDEA和eclipse。 OOM（Out Of Memory）: 源于java.lang.OutOfMemoryError，当JVM没有足够的内存来为对象分配空间并且垃圾回收器也无法回收空间时，系统出现的严重状况。 一方库: 本工程内部子项目模块依赖的库（jar包）。 二方库: 公司内部发布到中央仓库，可供公司内部其它应用依赖的库（jar包）。 三方库: 公司之外的开源库（jar包）。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[缓存那些事（四）]]></title>
    <url>%2F2018%2F10%2F08%2F%E7%BC%93%E5%AD%98%E9%82%A3%E4%BA%9B%E4%BA%8B%EF%BC%88%E5%9B%9B%EF%BC%89%2F</url>
    <content type="text"><![CDATA[缓存那些事（四）- Redis优化建议 图1图1是默认安装的redis在启动时给出的几条warning信息，已经告诉程序猿一些优化建议。 基本优化建议尽量使用短的key当然在精简的同时，不要忘了key的“见名知意”。对于value有些也可精简，比如性别使用0、1 避免使用keys *keys *这个命令是阻塞的，即操作执行期间，其它任何命令在你的实例中都无法执行。当redis中key数据量小时到无所谓，数据量大就很糟糕了。所以我们应该避免去使用这个命令。可以去使用SCAN来代替。 在存到Redis之前先把你的数据压缩下redis为每种数据类型都提供了两种内部编码方式，在不同的情况下redis会自动调整合适的编码方式 设置 key 有效期我们应该尽可能的利用key有效期。比如一些临时数据（短信校验码），过了有效期Redis就会自动为你清除 选择回收策略(maxmemory-policy)当Redis的实例空间被填满了之后，将会尝试回收一部分key。根据你的使用方式，强烈建议使用volatile-lru（默认）策略——前提是你对key已经设置了超时时间。但如果你运行的是一些类似于cache的东西，并且没有对 key 设置超时机制，可以考虑使用allkeys-lru回收机制，具体讲解查看 ,maxmemory-samples 3是说每次进行淘汰的时候 会随机抽取3个key 从里面淘汰最不经常使用的（默认选项） maxmemory-policy 六种方式 :volatile-lru：只对设置了过期时间的key进行LRU（默认值）allkeys-lru ： 是从所有key里 删除 不经常使用的keyvolatile-random：随机删除即将过期keyallkeys-random：随机删除volatile-ttl ： 删除即将过期的noeviction ： 永不过期，返回错误 使用bit位级别操作和byte字节级别操作来减少不必要的内存使用&gt; bit位级别操作：`GETRANGE`, `SETRANGE`, `GETBIT` and `SETBIT` byte字节级别操作：`GETRANGE` and `SETRANGE` 尽可能地使用hashes哈希存储当业务场景不需要数据持久化时，关闭所有的持久化方式可以获得最佳的性能想要一次添加多条数据的时候可以使用管道限制redis的内存大小&gt; 64位系统不限制内存，32位系统默认最多使用3GB内存。数据量不可预估，并且内存也有限的话，尽量限制下redis使用的内存大小，这样可以避免redis使用`swap分区`或者出现`OOM`错误。（使用`swap分区`，性能较低，如果限制了内存，当到达指定内存之后就不能添加数据了，否则会报`OOM`错误。可以设置`maxmemory-policy`，内存不足时删除数据。） SLOWLOG [get/reset/len] slowlog-log-slower-than 它决定要对执行时间大于多少微秒(microsecond，1秒 = 1,000,000 微秒)的命令进行记录。slowlog-max-len它决定 slowlog 最多能保存多少条日志，当发现redis性能下降的时候可以查看下是哪些命令导致的。 优化实例分析管道（Pipeline）的使用 图2图2展示了多条数据时用和不用管到在连接方便的消耗对比。redis的管道功能在命令行中没有，但是redis是支持管道的，在java的客户端(jedis)中是可以使用的。示例代码123456789101112131415161718192021222324252627282930/** * 不使用管道初始化1W条数据 * @throws Exception */@Testpublic void NOTUsePipeline() throws Exception &#123; Jedis jedis = JedisUtil.getJedis(); long start_time = System.currentTimeMillis(); for (int i = 0; i &lt; 10000; i++) &#123; jedis.set("aa_"+i, i+""); &#125; System.out.println(System.currentTimeMillis()-start_time);&#125;/** * 使用管道初始化1W条数据 * @throws Exception */@Testpublic void usePipeline() throws Exception &#123; Jedis jedis = JedisUtil.getJedis(); long start_time = System.currentTimeMillis(); Pipeline pipelined = jedis.pipelined(); for (int i = 0; i &lt; 10000; i++) &#123; pipelined.set("cc_"+i, i+""); &#125; pipelined.sync();//执行管道中的命令 System.out.println(System.currentTimeMillis()-start_time);&#125; Hash的使用例如要存储一个用户信息对象数据，包含以下信息：key为用户ID，value为用户对象（姓名，年龄，性别，生日等）如果用普通的key/value结构来存储，一般有以下2种存储方式: 将用户ID作为查找key,把其他信息封装成一个对象以序列化的方式存储缺点：增加了序列化/反序列化的开销，引入复杂适应系统（Complex adaptive system，简称CAS）修改其中一项信息时，需要把整个对象取回，并且修改操作需要对并发进行保护。 用户信息对象有多少成员就存成多少个key-value对虽然省去了序列化开销和并发问题，但是用户ID为重复存储。 Redis提供的Hash很好的解决了这个问题，提供了直接存取这个Map成员的接口;Key仍然是用户ID, value是一个Map，这个Map的key是成员的属性名，value是属性值。( 内部实现：Redis Hashd的Value内部有2种不同实现，Hash的成员比较少时Redis为了节省内存会采用类似一维数组的方式来紧凑存储，而不会采用真正的HashMap结构，对应的value redisObject的encoding为zipmap,当成员数量增大时会自动转成真正的HashMap,此时encoding为ht )。 宿主服务器优化本文开头的图1显示在启动时出现了三个warning，对于这三个warning可以采取redis宿主优化的方式解决 修改linux中TCP监听的最大容纳数量在高并发环境下你需要一个高backlog值来避免慢客户端连接问题。注意Linux内核默默地将这个值减小到/proc/sys/net/core/somaxconn的值，所以需要确认增大somaxconn和tcp_max_syn_backlog两个值来达到想要的效果。1echo 511 &gt; /proc/sys/net/core/somaxconn 注意：这个参数并不是限制redis的最大链接数。如果想限制redis的最大连接数需要修改maxclients 修改linux内核内存分配策略redis在备份数据的时候，会fork出一个子进程，理论上child进程所占用的内存和parent是一样的，比如parent占用的内存为8G，这个时候也要同样分配8G的内存给child,如果内存无法负担，往往会造成redis服务器的down机或者IO负载过高，效率下降;所以内存分配策略应该设置为 1（表示内核允许分配所有的物理内存，而不管当前的内存状态如何）;内存分配策略有三种(可选值：0、1、2) 0 表示内核将检查是否有足够的可用内存供应用进程使用；如果有足够的可用内存，内存申请允许；否则，内存申请失败，并把错误返回给应用进程 1 不管需要多少内存，都允许申请 2 只允许分配物理内存和交换内存的大小(交换内存一般是物理内存的一半) 关闭Transparent Huge Pages(THP)THP会造成内存锁影响redis性能，建议关闭 Transparent HugePages:用来提高内存管理的性能,Transparent Huge Pages在32位的RHEL 6中是不支持的,执行命令 echo never &gt; /sys/kernel/mm/ransparent_hugepage/enabled,把这条命令添加到这个文件中/etc/rc.local。 参考资料 Redis–优化详解 redis.cn]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>缓存</tag>
        <tag>缓存穿透</tag>
        <tag>缓存并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[缓存那些事（三）]]></title>
    <url>%2F2018%2F10%2F08%2F%E7%BC%93%E5%AD%98%E9%82%A3%E4%BA%9B%E4%BA%8B%EF%BC%88%E4%B8%89%EF%BC%89%2F</url>
    <content type="text"><![CDATA[本文主要介绍在MacOS及centos7.x上如何安装及配置Redis Mac安装redis1brew install redis 修改配置信息mac上redis的配置文件是/usr/local/etc/redis.conf，通过修改该文件你可以配置redis的对外服务端口号、监听IP及密码等。 常用命令123brew services start redis # 启动redisbrew services stop redis # 停止redisbrew services restart redis # 重启redis centos7.x安装redis1yum -y install redis 修改配置信息centos上redis的配置文件是/etc/redis.conf，通过修改该文件你可以配置redis的对外服务端口号、监听IP及密码等。 常用命令1234systemctl start redis.service #启动systemctl stop redis.service # 停止systemctl restart redis.service # 重启systemctl enable redis.service # 设置成开机自启 参考资料 mac上通过Homebrew安装redis Centos 7下使用yum安装redis redis配置认证密码 redis配置文件详解]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[缓存那些事（二）]]></title>
    <url>%2F2018%2F10%2F08%2F%E7%BC%93%E5%AD%98%E9%82%A3%E4%BA%9B%E4%BA%8B%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[简介Redis(REmote DIctionary Server)作为目前最流行的键值对存储数据库，是一个使用ANSI C编写的开源、支持网络、基于内存、可选持久性的键值对存储数据库，并提供多种语言的API。它通常被称为数据结构服务器，因为值（value）可以是 字符串(String), 哈希(Map), 列表(list), 集合(sets) 和 有序集合(sorted sets)等类型。从2015年6月开始，Redis的开发由Redis Labs赞助，而2013年5月至2015年6月期间，其开发由Pivotal赞助。在2013年5月之前，其开发由VMware赞助。 数据模型Redis的外围由一个键、值映射的字典构成。与其他非关系型数据库主要不同在于：Redis中值的类型不仅限于字符串，还支持如下抽象数据类型： 字符串列表 无序不重复的字符串集合 有序不重复的字符串集合 键、值都为字符串的哈希表 值的类型决定了值本身支持的操作。Redis支持不同无序、有序的列表，无序、有序的集合间的交集、并集等高级服务器端原子操作。 持久化Redis通常将全部的数据存储在内存中。2.4版本后可配置为使用虚拟内存，[9]一部分数据集存储在硬盘上，但这个特性废弃了。目前通过两种方式实现持久化： 使用快照，一种半持久耐用模式。不时的将数据集以异步方式从内存以RDB格式写入硬盘。 1.1版本开始使用更安全的AOF格式替代，一种只能追加的日志类型。将数据集修改操作记录起来。Redis能够在后台对只可追加的记录作修改来避免无限增长的日志。 同步Redis支持主从同步。数据可以从主服务器向任意数量的从服务器上同步，从服务器可以是关联其它从服务器的主服务器。这使得Redis可以执行单层树复制。从盘可以有意无意的对数据进行写操作。由于完全实现了发布/订阅的机制，是的从数据库在任何地方同步树时，可订阅一个频道并接收主服务器完整的消息发布记录。同步对读取操作的可扩展性和数据冗余很有帮助。 性能当数据依赖不再需要，Redis这种基于内存的性质，与在执行一个事务时将每个变化都写入硬盘的数据库系统相比就显得执行效率非常高。写与读操作速度没有明显差别。 参考资料 维基百科 官方]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[缓存那些事（一）]]></title>
    <url>%2F2018%2F09%2F29%2F%E7%BC%93%E5%AD%98%E9%82%A3%E4%BA%9B%E4%BA%8B%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[在日常的开发工作中程序猿会用到各种各样的缓存软件，不管是Redis还是Memcached抑或是其它类型的缓存软件，都会遇到缓存穿透、缓存并发、缓存失效三类问题 缓存穿透上图是大家使用缓存组件最常见的一个场景，那么它会有什么潜在的风险呢？在项目中使用缓存时通常都是先检查缓存中是否存在，如果存在直接返回缓存内容，如果不存在就直接查询数据库然后再缓存查询结果返回。这个时候如果我们查询的某一个数据在缓存中一直不存在，就会造成每一次请求都查询DB，这样缓存就失去了意义，在流量大时，可能DB就挂掉了。那么该如何解决这个问题呢？要是有人利用不存在的key频繁攻击我们的应用，这就是我们程序的漏洞。一种处理方法是将这个不存在的key预先设定一个值，比如(“key” , “&amp;&amp;”)，在返回这个”&amp;&amp;”值的时候，我们的应用就可以认为这是不存在的key，那我们的应用就可以决定是否继续等待继续访问，还是放弃掉这次操作。如果继续等待访问，过一个时间轮询点后，再次请求这个key，如果取到的值不再是&amp;&amp;，则可以认为这时候key有值了，从而避免了透传到数据库，从而把大量的类似请求挡在了缓存之中。还有一种处理办法是将系统中所有的key及对应的数据预先缓存起来，在系统中数据发生变更的时候，将单个变更的数据同步至缓存中，这样也可以避免出现缓存传统的情况发生，当然这种处理办法只适用于特定的业务场景。 缓存并发某些情况如果网站并发访问很高，某一个热点的缓存如果在此时失效，可能出现多个进程同时查询DB且同时设置缓存的情况，如果并发确实很大，这也可能造成DB压力过大，还有缓存频繁更新的问题。我们可以对缓存查询加锁，如果KEY不存在，就加锁，然后查DB入缓存，然后解锁；其他进程如果发现有锁就等待，然后等解锁后返回数据或者进入DB查询。这种处理方法和上述说的预先设定值问题有些类似，只不过利用锁的方式，但是会造成部分请求等待。 缓存失效平时我们都会设定一个缓存的过期时间，有一些会设置1分钟、5分钟等等;在高并发的时候可能会出在某一个时间同时生成了很多的缓存，并且过期时间都一样，当过期时间到后，这些缓存同时失效，请求会全部转发到DB，DB可能会压力过重。那么该如何解决这个问题呢？最简单的处理方式是将缓存失效时间分散开，比如我们可以在原有的失效时间基础上增加一个随机值（1-5分钟随机），这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。 参考资料 程序猿DD 深入分布式缓存：从原理到实践]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>缓存</tag>
        <tag>缓存穿透</tag>
        <tag>缓存并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM内存溢出分类及说明]]></title>
    <url>%2F2018%2F09%2F27%2FJVM%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA%E5%88%86%E7%B1%BB%E5%8F%8A%E8%AF%B4%E6%98%8E%2F</url>
    <content type="text"><![CDATA[Java程序猿在日常的开发工作中会遇到各种各样的内存溢出问题，本文中摘录了几种内存溢出的场景及其说明，即便于排查具体内存溢出的原因，也可以在技术面试中为自己增加筹码 堆（Heap）溢出java.lang.OutOfMemoryError Java heap spacejava堆用于存储对象的实例，只要不断的创建对象，并且保证GC Roots到对象之间有可达路径来避免垃圾回收机制清除这些对象，那么在对象数量达到最大堆的容量限制之后机会产生内存溢出异常。当出现java堆内存溢出时，异常堆栈信息“java.lang.OutOfMemoryError”会跟着进一步提示“Java heap space”。要解决这个区域的异常 ，一般会先通过内存映像分析工具对Dump出来的对转存储快照进行分析，重点是确认内存中的对象是否是必要的，若果内存中的对象确实都还必须活着，那就应当检查虚拟机的堆参数（-Xmx和Xms）,与机器物理内存对比是否还可以调大，从代码上检查是否存在某些对象生命周期过长，持有状态时间过长的情况，尝试减少程序运行期的内存消耗。 栈（Stacks）溢出StackOverflowError如果线程请求的栈深度大于虚拟机所允许的最大深度，将会抛出StackOverflowError。如果虚拟机在扩展栈时无法申请到足够的内存空间则抛出OutOfMemoryError。以上两种异常情况其实是对同一件事情的两种描述：当栈空间无法继续分配时，到底是栈内存太小，还是已经使用的栈空间太大。试验表明：在单个线程下，无论是由于栈帧太大还是虚拟机栈容量太小，当内存无法分配的时候，虚拟机抛出的StackOverflowError异常。如果不限于单线程，通过不断的建立线程的方式到可以产生内存溢出异常，但是这样产生的内存溢出异常与栈空间是否足够大并不存在任何联系，或者更准确的说，在这种情况下，为每一个线程的栈分配的内存越大，反而越容易产生内存溢出异常。如果是通过建立过多线程的方式到导致的内存溢出，在不能减少线程或者更换64位虚拟机的情况下，就只能通过减少最大堆和减少栈帧容量来换取跟多的线程。原因很简单：操作系统分配给每一个进程的内存是有限制的，比如每个对进程的限制为2GB，虚拟机提供了参数来控制java堆和方法区的这两部分内存的最大值。则剩余的内存为：2GB（操作系统限制的大小）-Xmx（最大堆容量）-MaxPermSize（最大方法区容量）。程序计数器消耗的内存很小基本可以忽略。如果虚拟机进程本身消耗的内存不计算在内，那么剩下的内存就由虚拟机的虚拟机栈和本地方法栈“瓜分”了。每个线程分配到的内存容量越大，可以建立的线程数量自然就越少，建立线程时就越容易将剩下的内存耗尽。 方法区和运行时常量池溢出OutOfMemoryError PermGen space若是运行时常量池溢出，在OutOfMemoryError后面跟随的提示信息是“PermGen space”，说明运行时常量池属于方法区（永久代）的一部分。方法区用于存放Class的相关信息，如类名，访问修饰符，常量池，字段描述，方法描述。若运行时产生大量的类去填满方法区，直达溢出。比如Spring 对类进行增强时（创建代理类），都会使用到cglib这类字节码技术，增强的类越多，就需要越大的方法区来保证动态生成的Class可以加载到内存。再比如大量JSP或动态产生JSP文件应用（JSP第一次运行时需要编译为java类）等。 本机直接内存溢出DirectMenory容量可通过-XX：MaxDirectMemorySize指定，如果不指定，则默认与java堆的容量最大值一样。在使用NIO方式使用Native函数库直接分配堆外内存，存储在Java堆中的DirectByteBuffer对象在进行分配内存是时候会抛出内存溢出异常。但是它抛出异常时并没有真正向操作系统申请分配内存，而是通过计算得知内存无法分配，于是手动抛出异常。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
        <tag>内存溢出</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM内存结构]]></title>
    <url>%2F2018%2F09%2F27%2FJVM%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[Java程序猿在日常的开发工作中会遇到各种各样的内存溢出问题，在弄清楚到底是什么引起的内存溢出之前，需要先熟悉下JVM的内存结构，这样既便于排查内存溢出的具体原因，也可以对JVM进行调优，更可以在技术面试中为自己增加筹码 内存结构简介简介 由上图可以很清晰的看出JVM的内存结构主要由三大块构成： 堆内存 方法区 栈堆内存堆内存是JVM中最大的一块，由年轻代和老年代组成，而年轻代内存又被分成Eden空间、From Survivor空间、To Survivor空间三部分组成，默认情况下这三个空间的内存是按照8:1:1的比例来分配的方法区方法区存储类信息、常量、静态变量等数据，是线程共享的区域，为了与堆内存区分，方法区还有一个别名叫Non-Heap（非堆）栈栈又分为Java虚拟机栈和本地方法栈，主要用于方法的执行如何控制各内存区域的内存大小由上图可以看出可以通过参数来控制各区域内存的大小 -Xms设置堆的最小空间大小 -Xmx设置堆的最大空间大小 -XX:NewSize设置新生代最小空间大小 -XX:MaxNewSize设置新生代最大空间大小 -XX:PermSize设置永久代最小空间大小 -XX:MaxPermSize设置永久代最大空间大小 -Xss设置每个线程的堆栈大小 目前还没有直接设置老年代内存大小的参数，但是可以通过设置堆空间、新生代空间大小的方法来间接设置（老年代空间大小=堆空间大小-年轻代空间大小） JVM和系统调用之间的关系方法区和对是所有线程共享的内存区域；而java栈、本地方法栈和程序员计数器是运行是线程私有的内存区域。 详细介绍Java堆（Heap）对于大多数应用来说，Java堆（Java Heap）是Java虚拟机所管理的内存中最大的一块。Java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。Java堆是垃圾收集器管理的主要区域，因此很多时候也被称做“GC堆”。如果从内存回收的角度看，由于现在收集器基本都是采用的分代收集算法，所以Java堆中还可以细分为：新生代和老年代；再细致一点的有Eden空间、From Survivor空间、To Survivor空间等。根据Java虚拟机规范的规定，Java堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可，就像我们的磁盘空间一样。在实现时，既可以实现成固定大小的，也可以是可扩展的，不过当前主流的虚拟机都是按照可扩展来实现的（通过-Xmx和-Xms控制）。如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出OutOfMemoryError异常。 方法区（Method Area）方法区（Method Area）与Java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然Java虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做Non-Heap（非堆），目的应该是与Java堆区分开来。对于习惯在HotSpot虚拟机上开发和部署程序的开发者来说，很多人愿意把方法区称为“永久代”（Permanent Generation），本质上两者并不等价，仅仅是因为HotSpot虚拟机的设计团队选择把GC分代收集扩展至方法区，或者说使用永久代来实现方法区而已。Java虚拟机规范对这个区域的限制非常宽松，除了和Java堆一样不需要连续的内存和可以选择固定大小或者可扩展外，还可以选择不实现垃圾收集。相对而言，垃圾收集行为在这个区域是比较少出现的，但并非数据进入了方法区就如永久代的名字一样“永久”存在了。这个区域的内存回收目标主要是针对常量池的回收和对类型的卸载，一般来说这个区域的回收“成绩”比较难以令人满意，尤其是类型的卸载，条件相当苛刻，但是这部分区域的回收确实是有必要的。根据Java虚拟机规范的规定，当方法区无法满足内存分配需求时，将抛出OutOfMemoryError异常。 程序计数器（Program Counter Register）程序计数器（Program Counter Register）是一块较小的内存空间，它的作用可以看做是当前线程所执行的字节码的行号指示器。在虚拟机的概念模型里（仅是概念模型，各种虚拟机可能会通过一些更高效的方式去实现），字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。由于Java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，在任何一个确定的时刻，一个处理器（对于多核处理器来说是一个内核）只会执行一条线程中的指令。因此，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各条线程之间的计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存。如果线程正在执行的是一个Java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是Natvie方法，这个计数器值则为空（Undefined）。此内存区域是唯一一个在Java虚拟机规范中没有规定任何OutOfMemoryError情况的区域。 JVM栈（JVM Stacks）与程序计数器一样，Java虚拟机栈（Java Virtual Machine Stacks）也是线程私有的，它的生命周期与线程相同。虚拟机栈描述的是Java方法执行的内存模型：每个方法被执行的时候都会同时创建一个栈帧（Stack Frame）用于存储局部变量表、操作栈、动态链接、方法出口等信息。每一个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。局部变量表存放了编译期可知的各种基本数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference类型，它不等同于对象本身，根据不同的虚拟机实现，它可能是一个指向对象起始地址的引用指针，也可能指向一个代表对象的句柄或者其他与此对象相关的位置）和returnAddress类型（指向了一条字节码指令的地址）。其中64位长度的long和double类型的数据会占用2个局部变量空间（Slot），其余的数据类型只占用1个。局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。在Java虚拟机规范中，对这个区域规定了两种异常状况：如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常；如果虚拟机栈可以动态扩展（当前大部分的Java虚拟机都可动态扩展，只不过Java虚拟机规范中也允许固定长度的虚拟机栈），当扩展时无法申请到足够的内存时会抛出OutOfMemoryError异常。 本地方法栈（Native Method Stacks）本地方法栈（Native Method Stacks）与虚拟机栈所发挥的作用是非常相似的，其区别不过是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则是为虚拟机使用到的Native方法服务。虚拟机规范中对本地方法栈中的方法使用的语言、使用方式与数据结构并没有强制规定，因此具体的虚拟机可以自由实现它。甚至有的虚拟机（譬如Sun HotSpot虚拟机）直接就把本地方法栈和虚拟机栈合二为一。与虚拟机栈一样，本地方法栈区域也会抛出StackOverflowError和OutOfMemoryError异常。 参考： 纯洁的微笑-JVM内存结构 深入理解Java虚拟机：JVM高级特性与最佳实践_周志明.高清扫描版.pdf Java虚拟机规范英文版 Java虚拟机规范中文版]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot定时器]]></title>
    <url>%2F2018%2F09%2F18%2Fspringboot%E5%AE%9A%E6%97%B6%E5%99%A8%2F</url>
    <content type="text"><![CDATA[描述在日常的项目开发过程中会遇到各种使用定时任务的需求，实现定时任务需求的方式也是多种多样。 QuartzQuartz的使用相当广泛，它是一个功能强大的调度器，但是使用起来会非常繁琐 Timerjava.util包里的Timer，它同样也可以实现定时任务，但是功能过于单一 ScheduleSchedule是spring自带的定时任务组件,可以把它看成一个轻量级、简化版的Quartz 实现定时任务开启定时任务12345678910111213141516import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.scheduling.annotation.EnableScheduling;/** * @author wangjunfeng * @date 2018-09-13 */@SpringBootApplication@EnableSchedulingpublic class TimerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(TimerApplication.class, args); &#125;&#125; 单线程123456789101112131415161718192021222324252627282930313233import com.kiwi.timer.util.DateTimeUtil;import lombok.extern.log4j.Log4j2;import org.springframework.scheduling.annotation.Scheduled;import org.springframework.stereotype.Component;import java.util.Date;/** * 单线程定时器demo * * @author wangjunfeng * @date 2018-09-13 */@Log4j2@Componentpublic class SingleDemo &#123; public final static long ONE_Minute = 60 * 1000; @Scheduled(fixedDelay = ONE_Minute) public void fixedDelayJob() &#123; log.info(DateTimeUtil.toDateTimeStr(new Date()) + " &gt;&gt;fixedDelay执行...."); &#125; @Scheduled(fixedRate = ONE_Minute) public void fixedRateJob() &#123; log.info(DateTimeUtil.toDateTimeStr(new Date()) + " &gt;&gt;fixedRate执行...."); &#125; @Scheduled(cron = "0/5 * * * * ?") public void cronJob() &#123; log.info("----" + DateTimeUtil.toDateTimeStr(new Date()) + " &gt;&gt;cron执行...."); &#125;&#125; 123456s.a.ScheduledAnnotationBeanPostProcessor : No TaskScheduler/ScheduledExecutorService bean found for scheduled processing2018-09-18 16:25:47.279 INFO 23151 --- [pool-1-thread-1] com.kiwi.timer.single.SingleDemo : 2018-09-18 16:25:47 &gt;&gt;fixedRate执行....2018-09-18 16:25:47.280 INFO 23151 --- [pool-1-thread-1] com.kiwi.timer.single.SingleDemo : 2018-09-18 16:25:47 &gt;&gt;fixedDelay执行....2018-09-18 16:25:47.324 INFO 23151 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 8080 (http) with context path &apos;&apos;2018-09-18 16:25:47.331 INFO 23151 --- [ main] com.kiwi.timer.TimerApplication : Started TimerApplication in 3.646 seconds (JVM running for 4.643)2018-09-18 16:25:50.006 INFO 23151 --- [pool-1-thread-1] com.kiwi.timer.single.SingleDemo : ----2018-09-18 16:25:50 &gt;&gt;cron执行.... 从上述控制台日志可以看出所有的定时任务都是由同一个线程来处理的，当定时任务过多的时候会造成任务队列的堆积 多线程123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import lombok.extern.log4j.Log4j2;import org.springframework.aop.interceptor.AsyncUncaughtExceptionHandler;import org.springframework.aop.interceptor.SimpleAsyncUncaughtExceptionHandler;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.scheduling.TaskScheduler;import org.springframework.scheduling.annotation.AsyncConfigurer;import org.springframework.scheduling.annotation.EnableAsync;import org.springframework.scheduling.annotation.SchedulingConfigurer;import org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler;import org.springframework.scheduling.config.ScheduledTaskRegistrar;import java.util.concurrent.Executor;/** * */@Configuration@EnableAsync@Log4j2public class MultiConfig implements SchedulingConfigurer, AsyncConfigurer &#123; @Override public void configureTasks(ScheduledTaskRegistrar scheduledTaskRegistrar) &#123; TaskScheduler taskScheduler = taskScheduler(); scheduledTaskRegistrar.setTaskScheduler(taskScheduler); &#125; @Bean(destroyMethod = "shutdown") public ThreadPoolTaskScheduler taskScheduler() &#123; ThreadPoolTaskScheduler scheduler = new ThreadPoolTaskScheduler(); scheduler.setPoolSize(20); // 设置线程名前缀 scheduler.setThreadNamePrefix("multiTask-"); // 线程内容执行完后60秒停在 scheduler.setAwaitTerminationSeconds(60); // 等待所有线程执行完 scheduler.setWaitForTasksToCompleteOnShutdown(true); return scheduler; &#125; @Override public Executor getAsyncExecutor() &#123; Executor executor = taskScheduler(); return executor; &#125; @Override public AsyncUncaughtExceptionHandler getAsyncUncaughtExceptionHandler() &#123; return new SimpleAsyncUncaughtExceptionHandler(); &#125;&#125; 1234562018-09-18 16:33:15.219 INFO 23197 --- [ multiTask-1] com.kiwi.timer.single.SingleDemo : 2018-09-18 16:33:15 &gt;&gt;fixedRate执行....2018-09-18 16:33:15.219 INFO 23197 --- [ multiTask-2] com.kiwi.timer.single.SingleDemo : 2018-09-18 16:33:15 &gt;&gt;fixedDelay执行....2018-09-18 16:33:15.247 INFO 23197 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 8080 (http) with context path &apos;&apos;2018-09-18 16:33:15.251 INFO 23197 --- [ main] com.kiwi.timer.TimerApplication : Started TimerApplication in 2.313 seconds (JVM running for 3.046)2018-09-18 16:33:20.001 INFO 23197 --- [ multiTask-3] com.kiwi.timer.single.SingleDemo : ----2018-09-18 16:33:20 &gt;&gt;cron执行....2018-09-18 16:33:25.001 INFO 23197 --- [ multiTask-2] com.kiwi.timer.single.SingleDemo : ----2018-09-18 16:33:25 &gt;&gt;cron执行.... 从上述日志可以看出已有线程池中的多个线程来实现定时任务 参考资料 github示例代码 Cron表达式详解 SpringBoot定时器#Schedule]]></content>
      <categories>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>springboot</tag>
        <tag>定时器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos安装node.js&更换默认软件源]]></title>
    <url>%2F2018%2F09%2F18%2Fcentos%E5%AE%89%E8%A3%85node-js-%E6%9B%B4%E6%8D%A2%E9%BB%98%E8%AE%A4%E8%BD%AF%E4%BB%B6%E6%BA%90%2F</url>
    <content type="text"><![CDATA[安装EPEL库1sudo yum -y install epel-release 安装nodejs1sudo yum -y install nodejs 安装npm1sudo yum -y install npm 校验安装12node --versionnpm --version 更换软件源创建文件.npmrc1vim ~/.npmrc 添加以下内容并保存12345678910registry = https://registry.npm.taobao.org/ disturl = https://npm.taobao.org/dist sass_binary_site = https://npm.taobao.org/mirrors/node-sass electron_mirror = https://npm.taobao.org/mirrors/electron/ puppeteer_download_host = https://npm.taobao.org/mirrors chromedriver_cdnurl = https://npm.taobao.org/mirrors/chromedriver operadriver_cdnurl = https://npm.taobao.org/mirrors/operadriver phantomjs_cdnurl = https://npm.taobao.org/mirrors/phantomjs selenium_cdnurl = http://npm.taobao.org/mirrors/selenium node_inspector_cdnurl = https://npm.taobao.org/mirrors/node-inspector 参考资料 如何在 CentOS 安装 node.js npm淘宝镜像]]></content>
      <tags>
        <tag>node</tag>
        <tag>npm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Homebrew更换软件源]]></title>
    <url>%2F2018%2F09%2F17%2FHomebrew%E6%9B%B4%E6%8D%A2%E8%BD%AF%E4%BB%B6%E6%BA%90%2F</url>
    <content type="text"><![CDATA[homebrew主要分两部分：git repo（位于GitHub）和二进制bottles（位于bintray），因为一些众所周知的原因，这两者在国内访问都不太顺畅；为了可以使用brew流畅的安装各种软件，你可以将其默认的软件源修改为访问国内的源镜像，以下以清华大学提供的源为例，演示如何更换本地的brew软件源为清华的brew源。 替换现有上游12345cd "$(brew --repo)"git remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/brew.gitcd "$(brew --repo)/Library/Taps/homebrew/homebrew-core"git remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-core.gitbrew update 使用homebrew-science或者homebrew-python12345cd "$(brew --repo)/Library/Taps/homebrew/homebrew-science"git remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-science.gitcd "$(brew --repo)/Library/Taps/homebrew/homebrew-python"git remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-python.gitbrew update 参考资料 清华大学开源软件镜像站 brew安装]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>homebrew</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos6.x 安装python3.6&pip3]]></title>
    <url>%2F2018%2F09%2F17%2Fcentos6-x-%E5%AE%89%E8%A3%85python3-6-pip3%2F</url>
    <content type="text"><![CDATA[安装环境准备12yum -y groupinstall 'Development Tools'yum install -y zlib-devel bzip2-devel openssl-devel ncurses-devel 下载并解压python3.6.112wget https://www.python.org/ftp/python/3.6.1/Python-3.6.1.tgztar zxvf Python-3.6.1.tgz 编译安装123cd Python-3.6.1./configure --prefix=/usr/local/python3make &amp;&amp; make install 设置环境变量1echo 'export PATH=$PATH:/usr/local/python3/bin' &gt;&gt; /etc/profile 刷下环境变量1source /etc/profile 验证是否安装成功12python3 -Vpip3 -V]]></content>
      <tags>
        <tag>python3.6</tag>
        <tag>pip3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MYSQL数据库设计规范与原则]]></title>
    <url>%2F2018%2F09%2F13%2FMYSQL%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AE%BE%E8%AE%A1%E8%A7%84%E8%8C%83%E4%B8%8E%E5%8E%9F%E5%88%99%2F</url>
    <content type="text"><![CDATA[mysql数据库设计规范数据库命名规范 采用26个英文字母(区分大小写)和0-9的自然数(经常不需要)加上下划线’_’组成; 命名简洁明确(长度不能超过30个字符);例如：user, stat, log, 也可以wifi_user, wifi_stat, wifi_log给数据库加个前缀; 除非是备份数据库可以加0-9的自然数：user_db_20151210; 数据库表名命名规范 采用26个英文字母(区分大小写)和0-9的自然数(经常不需要)加上下划线’_’组成; 命名简洁明确,多个单词用下划线’_’分隔;例如：user_login, user_profile, user_detail, user_role, user_role_relation,user_role_right,user_role_right_relation,表前缀’user_’可以有效的把相同关系的表显示在一起; 数据库表字段名命名规范 采用26个英文字母(区分大小写)和0-9的自然数(经常不需要)加上下划线’_’组成; 命名简洁明确,多个单词用下划线’_’分隔;例如：user_login表字段 user_id, user_name, pass_word, eamil, tickit, status, mobile, add_time; 每个表中必须有自增主键,add_time(默认系统时间) 表与表之间的相关联字段名称要求尽可能的相同; 数据库表字段类型规范 用尽量少的存储空间来存数一个字段的数据;例如：能使用int就不要使用varchar、char,能用varchar(16)就不要使用varchar(256);IP地址最好使用int类型;固定长度的类型最好使用char,例如：邮编;能使用tinyint就不要使用smallint,int;最好给每个字段一个默认值,最好不能为null; 数据库表索引规范 命名简洁明确,例如：user_login表user_name字段的索引应为user_name_index唯一索引; 为每个表创建一个主键索引; 为每个表创建合理的索引; 建立复合索引请慎重; 简单熟悉数据库范式 第一范式(1NF)：字段值具有原子性,不能再分(所有关系型数据库系统都满足第一范式);例如：姓名字段,其中姓和名是一个整体,如果区分姓和名那么必须设立两个独立字段; 第二范式(2NF)：一个表必须有主键,即每行数据都能被唯一的区分;备注：必须先满足第一范式; 第三范式(3NF)：一个表中不能包涵其他相关表中非关键字段的信息,即数据表不能有沉余字段;备注：必须先满足第二范式;备注：往往我们在设计表中不能遵守第三范式,因为合理的沉余字段将会给我们减少join的查询;例如：相册表中会添加图片的点击数字段,在相册图片表中也会添加图片的点击数字段; MYSQL数据库设计原则核心原则 不在数据库做运算; cpu计算务必移至业务层; 控制列数量(字段少而精,字段数建议在20以内); 平衡范式与冗余(效率优先；往往牺牲范式) 拒绝3B(拒绝大sql语句：big sql、拒绝大事物：big transaction、拒绝大批量：big batch); 字段类原则 用好数值类型(用合适的字段类型节约空间); 字符转化为数字(能转化的最好转化,同样节约空间、提高查询性能); 避免使用NULL字段(NULL字段很难查询优化、NULL字段的索引需要额外空间、NULL字段的复合索引无效); 少用text类型(尽量使用varchar代替text字段); 索引类原则 合理使用索引(改善查询,减慢更新,索引一定不是越多越好); 字符字段必须建前缀索引; 不在索引做列运算; innodb主键推荐使用自增列(主键建立聚簇索引,主键不应该被修改,字符串不应该做主键)(理解Innodb的索引保存结构就知道了);*不用外键(由程序保证约束); sql类原则 sql语句尽可能简单(一条sql只能在一个cpu运算,大语句拆小语句,减少锁时间,一条大sql可以堵死整个库); 简单的事务; 避免使用trig/func(触发器、函数不用客户端程序取而代之); 不用select *(消耗cpu,io,内存,带宽,这种程序不具有扩展性); OR改写为IN(or的效率是n级别); OR改写为UNION(mysql的索引合并很弱智); 12345select id from t where phone = '159' or name = ‘john’; =&gt; select id from t where phone='159'union select id from t where name='jonh' 避免负向%; 慎用count(*); limit高效分页(limit越大，效率越低); 使用union all替代union(union有去重开销); 少用连接join; 使用group by; 请使用同类型比较; 打散批量更新; 性能分析工具123456show profile; mysqlsla; mysqldumpslow; explain; show slow log; show processlist;]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RESTful API 设计指南]]></title>
    <url>%2F2018%2F09%2F10%2FRESTful-API-%E8%AE%BE%E8%AE%A1%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[协议API与客户端的通信协议，建议使用HTTPS协议 域名应该尽量将API部署在专用域名之下。 1https://api.example.com 如果确定API很简单，不会有进一步扩展，可以考虑放在主域名下。 1https://example.org/api/ 版本应该将API的版本号放入URL 1https://api.example.com/v1/ 另一种做法是将版本号放在HTTP头信息中，但不如放入URL方便和直观。Github采用这种做法。 路径路径又称”终点”（endpoint），表示API的具体网址。在RESTful架构中，每个网址代表一种资源（resource），所以网址中不能有动词，只能有名词，而且所用的名词往往与数据库的表格名对应。一般来说，数据库中的表都是同种记录的”集合”（collection），所以API中的名词也应该使用复数。举例来说，有一个API提供动物园（zoo）的信息，还包括各种动物和雇员的信息，则它的路径应该设计成下面这样。 123https://api.example.com/v1/zooshttps://api.example.com/v1/animalshttps://api.example.com/v1/employees HTTP动词对于资源的具体操作类型，由HTTP动词表示。常用的HTTP动词有下面五个（括号里是对应的SQL命令）。 12345GET（SELECT）：从服务器取出资源（一项或多项）。POST（CREATE）：在服务器新建一个资源。PUT（UPDATE）：在服务器更新资源（客户端提供改变后的完整资源）。PATCH（UPDATE）：在服务器更新资源（客户端提供改变的属性）。DELETE（DELETE）：从服务器删除资源。 还有两个不常用的HTTP动词。 12HEAD：获取资源的元数据。OPTIONS：获取信息，关于资源的哪些属性是客户端可以改变的。 下面是一些例子。 123456GET /star：列出所有明星信息POST /star：新增一个明星信息GET /star/ID：获取指定ID的明星信息PUT /star/ID：更新指定ID的明星信息（提供该明星的全部信息）PATCH /star/ID：更新指定ID的明星的信息（提供该明星的部分信息）DELETE /star/ID：删除指定ID的明星 过滤信息如果记录数量很多，服务器不可能都将它们返回给用户。API应该提供参数，过滤返回结果。下面是一些常见的参数。 123456?limit=10：指定返回记录的数量?offset=10：指定返回记录的开始位置。?page=2&amp;per_page=100：指定第几页，以及每页的记录数。?sortby=name&amp;order=asc：指定返回结果按照哪个属性排序，以及排序顺序。?animal_type_id=1：指定筛选条件参数的设计允许存在冗余，即允许API路径和URL参数偶尔有重复。比如，GET /zoo/ID/animals 与 GET /animals?zoo_id=ID 的含义是相同的。 状态码服务器向用户返回的状态码和提示信息，常见的有以下一些（方括号中是该状态码对应的HTTP动词）。 123456789101112200 OK - [GET]：服务器成功返回用户请求的数据，该操作是幂等的（Idempotent）。201 CREATED - [POST/PUT/PATCH]：用户新建或修改数据成功。202 Accepted - [*]：表示一个请求已经进入后台排队（异步任务）204 NO CONTENT - [DELETE]：用户删除数据成功。400 INVALID REQUEST - [POST/PUT/PATCH]：用户发出的请求有错误，服务器没有进行新建或修改数据的操作，该操作是幂等的。401 Unauthorized - [*]：表示用户没有权限（令牌、用户名、密码错误）。403 Forbidden - [*] 表示用户得到授权（与401错误相对），但是访问是被禁止的。404 NOT FOUND - [*]：用户发出的请求针对的是不存在的记录，服务器没有进行操作，该操作是幂等的。406 Not Acceptable - [GET]：用户请求的格式不可得（比如用户请求JSON格式，但是只有XML格式）。410 Gone -[GET]：用户请求的资源被永久删除，且不会再得到的。422 Unprocesable entity - [POST/PUT/PATCH] 当创建一个对象时，发生一个验证错误。500 INTERNAL SERVER ERROR - [*]：服务器发生错误，用户将无法判断发出的请求是否成功。 错误处理如果状态码是4xx，就应该向用户返回出错信息。一般来说，返回的信息中将error作为键名，出错信息作为键值即可。 123&#123; error: &quot;Invalid API key&quot;&#125; 返回结果针对不同操作，服务器向用户返回的结果应该符合以下规范。 123456GET /collection：返回资源对象的列表（数组）GET /collection/resource：返回单个资源对象POST /collection：返回新生成的资源对象PUT /collection/resource：返回完整的资源对象PATCH /collection/resource：返回完整的资源对象DELETE /collection/resource：返回一个空文档 Hypermedia APIRESTful API最好做到Hypermedia，即返回结果中提供链接，连向其他API方法，使得用户不查文档，也知道下一步应该做什么。比如，当用户向api.example.com的根目录发出请求，会得到这样一个文档。 123456&#123;"link": &#123; "rel": "collection https://www.example.com/zoos", "href": "https://api.example.com/zoos", "title": "List of zoos", "type": "application/vnd.yourformat+json"&#125;&#125; 上面代码表示，文档中有一个link属性，用户读取这个属性就知道下一步该调用什么API了。rel表示这个API与当前网址的关系（collection关系，并给出该collection的网址），href表示API的路径，title表示API的标题，type表示返回类型。Hypermedia API的设计被称为HATEOAS。Github的API就是这种设计，访问api.github.com会得到一个所有可用API的网址列表。 1234&#123; "current_user_url": "https://api.github.com/user", "authorizations_url": "https://api.github.com/authorizations"&#125; 从上面可以看到，如果想获取当前用户的信息，应该去访问api.github.com/user，然后就得到了下面结果。 1234&#123; "message": "Requires authentication", "documentation_url": "https://developer.github.com/v3"&#125; 上面代码表示，服务器给出了提示信息，以及文档的网址。 参考资料HTTPS协议GitHub]]></content>
      <categories>
        <category>http</category>
      </categories>
      <tags>
        <tag>http</tag>
        <tag>RESTful</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RESTful架构]]></title>
    <url>%2F2018%2F09%2F10%2FRESTful%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"><![CDATA[起源REST这个词，是Roy Thomas Fielding在他2000年的博士论文中提出的。Fielding是一个非常牛气的大神，他是HTTP协议（1.0版和1.1版）的主要设计者、Apache服务器软件的作者之一、Apache基金会的第一任主席。Fielding介绍博士论文的写作目的： 12&quot;本文研究计算机科学两大前沿----软件和网络----的交叉点。长期以来，软件研究主要关注软件设计的分类、设计方法的演化，很少客观地评估不同的设计选择对系统行为的影响。而相反地，网络研究主要关注系统之间通信行为的细节、如何改进特定通信机制的表现，常常忽视了一个事实，那就是改变应用程序的互动风格比改变互动协议，对整体表现有更大的影响。我这篇文章的写作目的，就是想在符合架构原理的前提下，理解和评估以网络为基础的应用软件的架构设计，得到一个功能强、性能好、适宜通信的架构。&quot;(This dissertation explores a junction on the frontiers of two research disciplines in computer science: software and networking. Software research has long been concerned with the categorization of software designs and the development of design methodologies, but has rarely been able to objectively evaluate the impact of various design choices on system behavior. Networking research, in contrast, is focused on the details of generic communication behavior between systems and improving the performance of particular communication techniques, often ignoring the fact that changing the interaction style of an application can have more impact on performance than the communication protocols used for that interaction. My work is motivated by the desire to understand and evaluate the architectural design of network-based application software through principled use of architectural constraints, thereby obtaining the functional, performance, and social properties desired of an architecture. ) 名称Fielding将他的互联网软件的架构原则，定名为REST，即Representational State Transfer（表现层状态转化）的缩写；如果一个架构符合REST原则，就可以将该架构称为REST架构。 资源（Resources）REST的名称”表现层状态转化”中，省略了主语。”表现层”其实指的是”资源”（Resources）的”表现层”。“资源”就是网络上的一个实体。它既可以是一段文本、一张图片、一首歌曲、一种服务，总之就是一个具体的实在。你可以用一个URI（统一资源定位符）指向它，每种资源对应一个特定的URI。要获取这个资源，访问它的URI就可以，因此URI就成了每一个资源的地址或独一无二的识别符。“上网”其实就是通过资源的URI与网络上一系列资源的互动。 表现层（Representation）“资源”是一种信息实体，它可以有多种外在表现形式。我们把”资源”具体呈现出来的形式，叫做它的”表现层”（Representation）。比如，文本可以用txt格式表现，也可以用HTML格式、XML格式、JSON格式表现，甚至可以采用二进制格式；图片可以用JPG格式表现，也可以用PNG格式表现。URI只代表资源的实体，不代表它的形式。严格地说，有些网址最后的”.html”后缀名是不必要的，因为这个后缀名表示格式，属于”表现层”范畴，而URI应该只代表”资源”的位置。它的具体表现形式，应该在HTTP请求的头信息中用Accept和Content-Type字段指定，这两个字段才是对”表现层”的描述。 状态转化（State Transfer）访问一个网站，就代表了客户端和服务器的一个互动过程。在这个过程中，势必涉及到数据和状态的变化。互联网通信协议HTTP协议，是一个无状态协议。这意味着，所有的状态都保存在服务器端。因此，如果客户端想要操作服务器，必须通过某种手段，让服务器端发生”状态转化”（State Transfer）。而这种转化是建立在表现层之上的，所以就是”表现层状态转化”。客户端用到的手段，只能是HTTP协议。具体来说，就是HTTP协议里面，四个表示操作方式的动词：GET、POST、PUT、DELETE。它们分别对应四种基本操作：GET用来获取资源，POST用来新建资源（也可以用于更新资源），PUT用来更新资源，DELETE用来删除资源。 什么是Restfull-API综上所属，总结一下什么是RESTful架构： 每一个URI代表一种资源； 客户端和服务器之间，传递这种资源的某种表现层； 客户端通过四个HTTP动词，对服务器端资源进行操作，实现”表现层状态转化”。 误区RESTful架构有一些典型的设计误区。最常见的一种设计错误，就是URI包含动词。因为”资源”表示一种实体，所以应该是名词，URI不应该有动词，动词应该放在HTTP协议中。举例来说，某个URI是/posts/show/1，其中show是动词，这个URI就设计错了，正确的写法应该是/posts/1，然后用GET方法表示show。如果某些动作是HTTP动词表示不了的，你就应该把动作做成一种资源。比如网上汇款，从账户1向账户2汇款500元，错误的URI是： 1 POST /accounts/1/transfer/500/to/2 正确的写法是把动词transfer改成名词transaction，资源不能是动词，但是可以是一种服务： 123 POST /transaction HTTP/1.1 Host: 127.0.0.1 from=1&amp;to=2&amp;amount=500.00 参考资料 表现层状态转移 RESTful api接口规范]]></content>
      <categories>
        <category>http</category>
      </categories>
      <tags>
        <tag>http</tag>
        <tag>RESTful</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[什么是RESTful API]]></title>
    <url>%2F2018%2F09%2F10%2F%E4%BB%80%E4%B9%88%E6%98%AFRESTful-API%2F</url>
    <content type="text"><![CDATA[在弄清楚什么是RESTful API之前，首先要弄清楚什么是REST。REST – Representational State Transfer，英文直译过来的意思是“表现层状态转移”。RESTful即URL定位资源，用HTTP动词（GET,POST,PUT,DELETE)描述操作 Resource：资源，即数据。 Representational：某种表现形式，比如用JSON，XML，JPEG等； State Transfer：状态变化。通过HTTP动词实现。 所谓RESTful API就是REST风格的API。 那么在什么场景下使用RESTful API呢？在当今的互联网应用的前端展示媒介很丰富。有手机、有平板电脑还有PC以及其他的展示媒介。那么这些前端接收到的用户请求统一由一个后台来处理并返回给不同的前端肯定是最科学和最经济的方式，RESTful API就是一套协议来规范多种形式的前端和同一个后台的交互方式。RESTful API由后台也就是服务端来提供前端来调用。前端调用API向后台发起HTTP请求，后台响应请求将处理结果反馈给前端。也就是说RESTful 是典型的基于HTTP的协议。 RESTful API的设计规则与规范资源资源就是网络上的一个实体，一段文本，一张图片或者一首歌曲。资源总是要通过一种载体来反应它的内容。文本可以用TXT，也可以用HTML或者XML、图片可以用JPG格式或者PNG格式，JSON是现在最常用的资源表现形式。 统一接口RESTful风格的数据元操CRUD（create,read,update,delete）分别对应HTTP方法：GET用来获取资源，POST用来新建资源（也可以用于更新资源），PUT用来更新资源，DELETE用来删除资源，这样就统一了数据操作的接口。 URI可以用一个URI（统一资源定位符）指向资源，即每个URI都对应一个特定的资源。要获取这个资源访问它的URI就可以，因此URI就成了每一个资源的地址或识别符。一般的，每个资源至少有一个URI与之对应，最典型的URI就是URL。 无状态所谓无状态即所有的资源都可以URI定位，而且这个定位与其他资源无关，也不会因为其他资源的变化而变化。有状态和无状态的区别，举个例子说明一下，例如要查询员工工资的步骤为第一步：登录系统。第二步：进入查询工资的页面。第三步：搜索该员工。第四步：点击姓名查看工资。这样的操作流程就是有状态的，查询工资的每一个步骤都依赖于前一个步骤，只要前置操作不成功，后续操作就无法执行。如果输入一个URL就可以得到指定员工的工资，则这种情况就是无状态的，因为获取工资不依赖于其他资源或状态，且这种情况下，员工工资是一个资源，由一个URL与之对应可以通过HTTP中的GET方法得到资源，这就是典型的RESTful风格。 规范 应该将API的版本号放入URL。GET:http://www.xxx.com/v1/friend/123 URL中只能有名词而不能有动词，操作的表达是使用HTTP的动词GET,POST,PUT,DELETEL。URL只标识资源的地址，既然是资源那就是名词了 如果记录数量很多，服务器不可能都将它们返回给用户。API应该提供参数，过滤返回结果。?limit=10：指定返回记录的数量、?page=2&amp;per_page=100：指定第几页，以及每页的记录数。 参考资料 表现层状态转移 RESTful api接口规范]]></content>
      <categories>
        <category>http</category>
      </categories>
      <tags>
        <tag>http</tag>
        <tag>RESTful</tag>
        <tag>API</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[http状态码详解]]></title>
    <url>%2F2018%2F09%2F07%2Fhttp%E7%8A%B6%E6%80%81%E7%A0%81%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[状态码 详解 100 客户端应当继续发送请求。这个临时响应是用来通知客户端它的部分请求已经被服务器接收，且仍未被拒绝。客户端应当继续发送请求的剩余部分，或者如果请求已经完成，忽略这个响应。服务器必须在请求完成后向客户端发送一个最终响应。 101 服务器已经理解了客户端的请求，并将通过Upgrade 消息头通知客户端采用不同的协议来完成这个请求。在发送完这个响应最后的空行后，服务器将会切换到在Upgrade 消息头中定义的那些协议。只有在切换新的协议更有好处的时候才应该采取类似措施。例如，切换到新的HTTP 版本比旧版本更有优势，或者切换到一个实时且同步的协议以传送利用此类特性的资源。 102 由WebDAV（RFC 2518）扩展的状态码，代表处理将被继续执行。 200 请求已成功，请求所希望的响应头或数据体将随此响应返回。 201 请求已经被实现，而且有一个新的资源已经依据请求的需要而建立，且其 URI 已经随Location 头信息返回。假如需要的资源无法及时建立的话，应当返回 ‘202 Accepted’。 202 服务器已接受请求，但尚未处理。正如它可能被拒绝一样，最终该请求可能会也可能不会被执行。在异步操作的场合下，没有比发送这个状态码更方便的做法了。返回202状态码的响应的目的是允许服务器接受其他过程的请求（例如某个每天只执行一次的基于批处理的操作），而不必让客户端一直保持与服务器的连接直到批处理操作全部完成。在接受请求处理并返回202状态码的响应应当在返回的实体中包含一些指示处理当前状态的信息，以及指向处理状态监视器或状态预测的指针，以便用户能够估计操作是否已经完成。 203 服务器已成功处理了请求，但返回的实体头部元信息不是在原始服务器上有效的确定集合，而是来自本地或者第三方的拷贝。当前的信息可能是原始版本的子集或者超集。例如，包含资源的元数据可能导致原始服务器知道元信息的超级。使用此状态码不是必须的，而且只有在响应不使用此状态码便会返回200 OK的情况下才是合适的。 204 服务器成功处理了请求，但不需要返回任何实体内容，并且希望返回更新了的元信息。响应可能通过实体头部的形式，返回新的或更新后的元信息。如果存在这些头部信息，则应当与所请求的变量相呼应。如果客户端是浏览器的话，那么用户浏览器应保留发送了该请求的页面，而不产生任何文档视图上的变化，即使按照规范新的或更新后的元信息应当被应用到用户浏览器活动视图中的文档。 由于204响应被禁止包含任何消息体，因此它始终以消息头后的第一个空行结尾。 205 服务器成功处理了请求，且没有返回任何内容。但是与204响应不同，返回此状态码的响应要求请求者重置文档视图。该响应主要是被用于接受用户输入后，立即重置表单，以便用户能够轻松地开始另一次输入。与204响应一样，该响应也被禁止包含任何消息体，且以消息头后的第一个空行结束。 206 服务器已经成功处理了部分 GET 请求。类似于 FlashGet 或者迅雷这类的 HTTP 下载工具都是使用此类响应实现断点续传或者将一个大文档分解为多个下载段同时下载。该请求必须包含 Range 头信息来指示客户端希望得到的内容范围，并且可能包含 If-Range 来作为请求条件。响应必须包含如下的头部域：Content-Range 用以指示本次响应中返回的内容的范围；如果是 Content-Type 为 multipart/byteranges 的多段下载，则每一 multipart 段中都应包含 Content-Range 域用以指示本段的内容范围。假如响应中包含 Content-Length，那么它的数值必须匹配它返回的内容范围的真实字节数。Date ETag 和/或 Content-Location，假如同样的请求本应该返回200响应。Expires, Cache-Control，和/或 Vary，假如其值可能与之前相同变量的其他响应对应的值不同的话。假如本响应请求使用了 If-Range 强缓存验证，那么本次响应不应该包含其他实体头；假如本响应的请求使用了 If-Range 弱缓存验证，那么本次响应禁止包含其他实体头；这避免了缓存的实体内容和更新了的实体头信息之间的不一致。否则，本响应就应当包含所有本应该返回200响应中应当返回的所有实体头部域。假如 ETag 或 Last-Modified 头部不能精确匹配的话，则客户端缓存应禁止将206响应返回的内容与之前任何缓存过的内容组合在一起。任何不支持 Range 以及 Content-Range 头的缓存都禁止缓存206响应返回的内容。 207 由WebDAV(RFC 2518)扩展的状态码，代表之后的消息体将是一个XML消息，并且可能依照之前子请求数量的不同，包含一系列独立的响应代码。 300 被请求的资源有一系列可供选择的回馈信息，每个都有自己特定的地址和浏览器驱动的商议信息。用户或浏览器能够自行选择一个首选的地址进行重定向。除非这是一个 HEAD 请求，否则该响应应当包括一个资源特性及地址的列表的实体，以便用户或浏览器从中选择最合适的重定向地址。这个实体的格式由 Content-Type 定义的格式所决定。浏览器可能根据响应的格式以及浏览器自身能力，自动作出最合适的选择。当然，RFC 2616规范并没有规定这样的自动选择该如何进行。如果服务器本身已经有了首选的回馈选择，那么在 Location 中应当指明这个回馈的 URI；浏览器可能会将这个 Location 值作为自动重定向的地址。此外，除非额外指定，否则这个响应也是可缓存的。 301 被请求的资源已永久移动到新位置，并且将来任何对此资源的引用都应该使用本响应返回的若干个 URI 之一。如果可能，拥有链接编辑功能的客户端应当自动把请求的地址修改为从服务器反馈回来的地址。除非额外指定，否则这个响应也是可缓存的。新的永久性的 URI 应当在响应的 Location 域中返回。除非这是一个 HEAD 请求，否则响应的实体中应当包含指向新的 URI 的超链接及简短说明。如果这不是一个 GET 或者 HEAD 请求，因此浏览器禁止自动进行重定向，除非得到用户的确认，因为请求的条件可能因此发生变化。注意：对于某些使用 HTTP/1.0 协议的浏览器，当它们发送的 POST 请求得到了一个301响应的话，接下来的重定向请求将会变成 GET 方式。 302 请求的资源现在临时从不同的 URI 响应请求。由于这样的重定向是临时的，客户端应当继续向原有地址发送以后的请求。只有在Cache-Control或Expires中进行了指定的情况下，这个响应才是可缓存的。新的临时性的 URI 应当在响应的 Location 域中返回。除非这是一个 HEAD 请求，否则响应的实体中应当包含指向新的 URI 的超链接及简短说明。如果这不是一个 GET 或者 HEAD 请求，那么浏览器禁止自动进行重定向，除非得到用户的确认，因为请求的条件可能因此发生变化。注意：虽然RFC 1945和RFC 2068规范不允许客户端在重定向时改变请求的方法，但是很多现存的浏览器将302响应视作为303响应，并且使用 GET 方式访问在 Location 中规定的 URI，而无视原先请求的方法。状态码303和307被添加了进来，用以明确服务器期待客户端进行何种反应。 303 对应当前请求的响应可以在另一个 URI 上被找到，而且客户端应当采用 GET 的方式访问那个资源。这个方法的存在主要是为了允许由脚本激活的POST请求输出重定向到一个新的资源。这个新的 URI 不是原始资源的替代引用。同时，303响应禁止被缓存。当然，第二个请求（重定向）可能被缓存。 新的 URI 应当在响应的 Location 域中返回。除非这是一个 HEAD 请求，否则响应的实体中应当包含指向新的 URI 的超链接及简短说明。注意：许多 HTTP/1.1 版以前的 浏览器不能正确理解303状态。如果需要考虑与这些浏览器之间的互动，302状态码应该可以胜任，因为大多数的浏览器处理302响应时的方式恰恰就是上述规范要求客户端处理303响应时应当做的。 304 果客户端发送了一个带条件的 GET 请求且该请求已被允许，而文档的内容（自上次访问以来或者根据请求的条件）并没有改变，则服务器应当返回这个状态码。304响应禁止包含消息体，因此始终以消息头后的第一个空行结尾。 该响应必须包含以下的头信息：Date，除非这个服务器没有时钟。假如没有时钟的服务器也遵守这些规则，那么代理服务器以及客户端可以自行将 Date 字段添加到接收到的响应头中去（正如RFC 2068中规定的一样），缓存机制将会正常工作。ETag 和/或 Content-Location，假如同样的请求本应返回200响应。 Expires, Cache-Control，和/或Vary，假如其值可能与之前相同变量的其他响应对应的值不同的话。假如本响应请求使用了强缓存验证，那么本次响应不应该包含其他实体头；否则（例如，某个带条件的 GET 请求使用了弱缓存验证），本次响应禁止包含其他实体头；这避免了缓存了的实体内容和更新了的实体头信息之间的不一致。假如某个304响应指明了当前某个实体没有缓存，那么缓存系统必须忽视这个响应，并且重复发送不包含限制条件的请求。假如接收到一个要求更新某个缓存条目的304响应，那么缓存系统必须更新整个条目以反映所有在响应中被更新的字段的值。 305 被请求的资源必须通过指定的代理才能被访问。Location 域中将给出指定的代理所在的 URI 信息，接收者需要重复发送一个单独的请求，通过这个代理才能访问相应资源。只有原始服务器才能建立305响应。注意：RFC 2068中没有明确305响应是为了重定向一个单独的请求，而且只能被原始服务器建立。忽视这些限制可能导致严重的安全后果。 306 在最新版的规范中，306状态码已经不再被使用。 307 请求的资源现在临时从不同的URI 响应请求。由于这样的重定向是临时的，客户端应当继续向原有地址发送以后的请求。只有在Cache-Control或Expires中进行了指定的情况下，这个响应才是可缓存的。新的临时性的URI 应当在响应的 Location 域中返回。除非这是一个HEAD 请求，否则响应的实体中应当包含指向新的URI 的超链接及简短说明。因为部分浏览器不能识别307响应，因此需要添加上述必要信息以便用户能够理解并向新的 URI 发出访问请求。 如果这不是一个GET 或者 HEAD 请求，那么浏览器禁止自动进行重定向，除非得到用户的确认，因为请求的条件可能因此发生变化。 400 1、语义有误，当前请求无法被服务器理解。除非进行修改，否则客户端不应该重复提交这个请求。2、请求参数有误。 401 当前请求需要用户验证。该响应必须包含一个适用于被请求资源的 WWW-Authenticate 信息头用以询问用户信息。客户端可以重复提交一个包含恰当的 Authorization 头信息的请求。如果当前请求已经包含了Authorization 证书，那么401响应代表着服务器验证已经拒绝了那些证书。如果401响应包含了与前一个响应相同的身份验证询问，且浏览器已经至少尝试了一次验证，那么浏览器应当向用户展示响应中包含的实体信息，因为这个实体信息中可能包含了相关诊断信息。参见RFC 2617。 402 该状态码是为了将来可能的需求而预留的。 403 服务器已经理解请求，但是拒绝执行它。与401响应不同的是，身份验证并不能提供任何帮助，而且这个请求也不应该被重复提交。如果这不是一个 HEAD 请求，而且服务器希望能够讲清楚为何请求不能被执行，那么就应该在实体内描述拒绝的原因。当然服务器也可以返回一个404响应，假如它不希望让客户端获得任何信息。 404 请求失败，请求所希望得到的资源未被在服务器上发现。没有信息能够告诉用户这个状况到底是暂时的还是永久的。假如服务器知道情况的话，应当使用410状态码来告知旧资源因为某些内部的配置机制问题，已经永久的不可用，而且没有任何可以跳转的地址。404这个状态码被广泛应用于当服务器不想揭示到底为何请求被拒绝或者没有其他适合的响应可用的情况下。 405 请求行中指定的请求方法不能被用于请求相应的资源。该响应必须返回一个Allow 头信息用以表示出当前资源能够接受的请求方法的列表。鉴于 PUT，DELETE 方法会对服务器上的资源进行写操作，因而绝大部分的网页服务器都不支持或者在默认配置下不允许上述请求方法，对于此类请求均会返回405错误。 406 请求的资源的内容特性无法满足请求头中的条件，因而无法生成响应实体。除非这是一个 HEAD 请求，否则该响应就应当返回一个包含可以让用户或者浏览器从中选择最合适的实体特性以及地址列表的实体。实体的格式由 Content-Type 头中定义的媒体类型决定。浏览器可以根据格式及自身能力自行作出最佳选择。但是，规范中并没有定义任何作出此类自动选择的标准。 407 与401响应类似，只不过客户端必须在代理服务器上进行身份验证。代理服务器必须返回一个 Proxy-Authenticate 用以进行身份询问。客户端可以返回一个 Proxy-Authorization 信息头用以验证。参见RFC 2617。 408 请求超时。客户端没有在服务器预备等待的时间内完成一个请求的发送。客户端可以随时再次提交这一请求而无需进行任何更改。 409 由于和被请求的资源的当前状态之间存在冲突，请求无法完成。这个代码只允许用在这样的情况下才能被使用：用户被认为能够解决冲突，并且会重新提交新的请求。该响应应当包含足够的信息以便用户发现冲突的源头。冲突通常发生于对 PUT 请求的处理中。例如，在采用版本检查的环境下，某次 PUT 提交的对特定资源的修改请求所附带的版本信息与之前的某个（第三方）请求向冲突，那么此时服务器就应该返回一个409错误，告知用户请求无法完成。此时，响应实体中很可能会包含两个冲突版本之间的差异比较，以便用户重新提交归并以后的新版本。 410 被请求的资源在服务器上已经不再可用，而且没有任何已知的转发地址。这样的状况应当被认为是永久性的。如果可能，拥有链接编辑功能的客户端应当在获得用户许可后删除所有指向这个地址的引用。如果服务器不知道或者无法确定这个状况是否是永久的，那么就应该使用404状态码。除非额外说明，否则这个响应是可缓存的。410响应的目的主要是帮助网站管理员维护网站，通知用户该资源已经不再可用，并且服务器拥有者希望所有指向这个资源的远端连接也被删除。这类事件在限时、增值服务中很普遍。同样，410响应也被用于通知客户端在当前服务器站点上，原本属于某个个人的资源已经不再可用。当然，是否需要把所有永久不可用的资源标记为’410 Gone’，以及是否需要保持此标记多长时间，完全取决于服务器拥有者。 411 服务器拒绝在没有定义 Content-Length 头的情况下接受请求。在添加了表明请求消息体长度的有效 Content-Length 头之后，客户端可以再次提交该请求。 412 服务器在验证在请求的头字段中给出先决条件时，没能满足其中的一个或多个。这个状态码允许客户端在获取资源时在请求的元信息（请求头字段数据）中设置先决条件，以此避免该请求方法被应用到其希望的内容以外的资源上。 413 服务器拒绝处理当前请求，因为该请求提交的实体数据大小超过了服务器愿意或者能够处理的范围。此种情况下，服务器可以关闭连接以免客户端继续发送此请求。如果这个状况是临时的，服务器应当返回一个 Retry-After 的响应头，以告知客户端可以在多少时间以后重新尝试。 414 请求的URI 长度超过了服务器能够解释的长度，因此服务器拒绝对该请求提供服务。这比较少见，通常的情况包括：本应使用POST方法的表单提交变成了GET方法，导致查询字符串（Query String）过长。重定向URI “黑洞”，例如每次重定向把旧的 URI 作为新的 URI 的一部分，导致在若干次重定向后 URI 超长。客户端正在尝试利用某些服务器中存在的安全漏洞攻击服务器。这类服务器使用固定长度的缓冲读取或操作请求的 URI，当 GET 后的参数超过某个数值后，可能会产生缓冲区溢出，导致任意代码被执行[1]。没有此类漏洞的服务器，应当返回414状态码。 415 对于当前请求的方法和所请求的资源，请求中提交的实体并不是服务器中所支持的格式，因此请求被拒绝。 416 如果请求中包含了 Range 请求头，并且 Range 中指定的任何数据范围都与当前资源的可用范围不重合，同时请求中又没有定义 If-Range 请求头，那么服务器就应当返回416状态码。假如 Range 使用的是字节范围，那么这种情况就是指请求指定的所有数据范围的首字节位置都超过了当前资源的长度。服务器也应当在返回416状态码的同时，包含一个 Content-Range 实体头，用以指明当前资源的长度。这个响应也被禁止使用 multipart/byteranges 作为其 Content-Type。 417 在请求头 Expect 中指定的预期内容无法被服务器满足，或者这个服务器是一个代理服务器，它有明显的证据证明在当前路由的下一个节点上，Expect 的内容无法被满足。 421 从当前客户端所在的IP地址到服务器的连接数超过了服务器许可的最大范围。通常，这里的IP地址指的是从服务器上看到的客户端地址（比如用户的网关或者代理服务器地址）。在这种情况下，连接数的计算可能涉及到不止一个终端用户。 422 从当前客户端所在的IP地址到服务器的连接数超过了服务器许可的最大范围。通常，这里的IP地址指的是从服务器上看到的客户端地址（比如用户的网关或者代理服务器地址）。在这种情况下，连接数的计算可能涉及到不止一个终端用户。 423 请求格式正确，但是由于含有语义错误，无法响应。（RFC 4918 WebDAV）423 Locked 当前资源被锁定。（RFC 4918 WebDAV） 424 由于之前的某个请求发生的错误，导致当前请求失败，例如 PROPPATCH。（RFC 4918 WebDAV） 425 在WebDav Advanced Collections 草案中定义，但是未出现在《WebDAV 顺序集协议》（RFC 3658）中。 426 客户端应当切换到TLS/1.0。（RFC 2817） 449 由微软扩展，代表请求应当在执行完适当的操作后进行重试。 500 服务器遇到了一个未曾预料的状况，导致了它无法完成对请求的处理。一般来说，这个问题都会在服务器的程序码出错时出现。 501 服务器不支持当前请求所需要的某个功能。当服务器无法识别请求的方法，并且无法支持其对任何资源的请求。 502 作为网关或者代理工作的服务器尝试执行请求时，从上游服务器接收到无效的响应。 503 由于临时的服务器维护或者过载，服务器当前无法处理请求。这个状况是临时的，并且将在一段时间以后恢复。如果能够预计延迟时间，那么响应中可以包含一个 Retry-After 头用以标明这个延迟时间。如果没有给出这个 Retry-After 信息，那么客户端应当以处理500响应的方式处理它。注意：503状态码的存在并不意味着服务器在过载的时候必须使用它。某些服务器只不过是希望拒绝客户端的连接。 504 作为网关或者代理工作的服务器尝试执行请求时，未能及时从上游服务器（URI标识出的服务器，例如HTTP、FTP、LDAP）或者辅助服务器（例如DNS）收到响应。注意：某些代理服务器在DNS查询超时时会返回400或者500错误 505 服务器不支持，或者拒绝支持在请求中使用的 HTTP 版本。这暗示着服务器不能或不愿使用与客户端相同的版本。响应中应当包含一个描述了为何版本不被支持以及服务器支持哪些协议的实体。 506 由《透明内容协商协议》（RFC 2295）扩展，代表服务器存在内部配置错误：被请求的协商变元资源被配置为在透明内容协商中使用自己，因此在一个协商处理中不是一个合适的重点。 507 服务器无法存储完成请求所必须的内容。这个状况被认为是临时的。WebDAV (RFC 4918) 509 服务器达到带宽限制。这不是一个官方的状态码，但是仍被广泛使用。 510 获取资源所需要的策略并没有没满足。（RFC 2774） 参考资料 HTTP状态码详解 WebDAV HTTP状态码]]></content>
      <categories>
        <category>http</category>
      </categories>
      <tags>
        <tag>http</tag>
        <tag>WebDAV</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos安装git2.3]]></title>
    <url>%2F2018%2F09%2F06%2Fcentos%E5%AE%89%E8%A3%85git2-3%2F</url>
    <content type="text"><![CDATA[安装依赖的包12sudo yum -y updatesudo yum install -y curl-devel expat-devel gettext-devel openssl-devel zlib-devel gcc perl-ExtUtils-MakeMaker 下载git源码并解压缩123wget https://www.kernel.org/pub/software/scm/git/git-2.3.0.tar.gztar -zxvf git-2.3.0.tar.gzcd git-2.3.0 编译安装12make prefix=/usr/local/git allsudo make prefix=/usr/local/git install 将git安装路径添加到PATH变量1234sudo vim /etc/profile## 在最后一行添加export PATH=/usr/local/git/bin:$PATH 保存退出 验证是否安装成功12source /etc/profilegit --version]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Neo4j企业版下载地址]]></title>
    <url>%2F2018%2F08%2F28%2FNeo4j%E4%BC%81%E4%B8%9A%E7%89%88%E4%B8%8B%E8%BD%BD%E5%9C%B0%E5%9D%80%2F</url>
    <content type="text"><![CDATA[版本 企业 社区 2.3.1 http://dist.neo4j.org/neo4j-enterprise-2.3.1-unix.tar.gz http://dist.neo4j.org/neo4j-community-2.3.1-unix.tar.gz 2.3.0 http://dist.neo4j.org/neo4j-enterprise-2.3.0-unix.tar.gz http://dist.neo4j.org/neo4j-community-2.3.0-unix.tar.gz 2.3.10 http://dist.neo4j.org/neo4j-enterprise-2.3.10-unix.tar.gz http://dist.neo4j.org/neo4j-community-2.3.10-unix.tar.gz 2.3.11 http://dist.neo4j.org/neo4j-enterprise-2.3.11-unix.tar.gz http://dist.neo4j.org/neo4j-community-2.3.11-unix.tar.gz 2.3.12 http://dist.neo4j.org/neo4j-enterprise-2.3.12-unix.tar.gz http://dist.neo4j.org/neo4j-community-2.3.12-unix.tar.gz 2.3.2 http://dist.neo4j.org/neo4j-enterprise-2.3.2-unix.tar.gz http://dist.neo4j.org/neo4j-community-2.3.2-unix.tar.gz 2.3.3 http://dist.neo4j.org/neo4j-enterprise-2.3.3-unix.tar.gz http://dist.neo4j.org/neo4j-community-2.3.3-unix.tar.gz 2.3.4 http://dist.neo4j.org/neo4j-enterprise-2.3.4-unix.tar.gz http://dist.neo4j.org/neo4j-community-2.3.4-unix.tar.gz 2.3.5 http://dist.neo4j.org/neo4j-enterprise-2.3.5-unix.tar.gz http://dist.neo4j.org/neo4j-community-2.3.5-unix.tar.gz 2.3.6 http://dist.neo4j.org/neo4j-enterprise-2.3.6-unix.tar.gz http://dist.neo4j.org/neo4j-community-2.3.6-unix.tar.gz 2.3.7 http://dist.neo4j.org/neo4j-enterprise-2.3.7-unix.tar.gz http://dist.neo4j.org/neo4j-community-2.3.7-unix.tar.gz 2.3.8 http://dist.neo4j.org/neo4j-enterprise-2.3.8-unix.tar.gz http://dist.neo4j.org/neo4j-community-2.3.8-unix.tar.gz 2.3.9 http://dist.neo4j.org/neo4j-enterprise-2.3.9-unix.tar.gz http://dist.neo4j.org/neo4j-community-2.3.9-unix.tar.gz 3.0.12 http://dist.neo4j.org/neo4j-enterprise-3.0.12-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.0.12-unix.tar.gz 3.0.0 http://dist.neo4j.org/neo4j-enterprise-3.0.0-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.0.0-unix.tar.gz 3.0.1 http://dist.neo4j.org/neo4j-enterprise-3.0.1-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.0.1-unix.tar.gz 3.0.10 http://dist.neo4j.org/neo4j-enterprise-3.0.10-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.0.10-unix.tar.gz 3.0.11 http://dist.neo4j.org/neo4j-enterprise-3.0.11-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.0.11-unix.tar.gz 3.0.12 http://dist.neo4j.org/neo4j-enterprise-3.0.12-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.0.12-unix.tar.gz 3.0.2 http://dist.neo4j.org/neo4j-enterprise-3.0.2-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.0.2-unix.tar.gz 3.0.3 http://dist.neo4j.org/neo4j-enterprise-3.0.3-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.0.3-unix.tar.gz 3.0.4 http://dist.neo4j.org/neo4j-enterprise-3.0.4-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.0.4-unix.tar.gz 3.0.5 http://dist.neo4j.org/neo4j-enterprise-3.0.5-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.0.5-unix.tar.gz 3.0.6 http://dist.neo4j.org/neo4j-enterprise-3.0.6-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.0.6-unix.tar.gz 3.0.7 http://dist.neo4j.org/neo4j-enterprise-3.0.7-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.0.7-unix.tar.gz 3.0.8 http://dist.neo4j.org/neo4j-enterprise-3.0.8-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.0.8-unix.tar.gz 3.0.9 http://dist.neo4j.org/neo4j-enterprise-3.0.9-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.0.9-unix.tar.gz 3.1.0 http://dist.neo4j.org/neo4j-enterprise-3.1.0-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.1.0-unix.tar.gz 3.1.9 http://dist.neo4j.org/neo4j-enterprise-3.1.9-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.1.9-unix.tar.gz 3.1.1 http://dist.neo4j.org/neo4j-enterprise-3.1.1-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.1.1-unix.tar.gz 3.1.2 http://dist.neo4j.org/neo4j-enterprise-3.1.2-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.1.2-unix.tar.gz 3.1.3 http://dist.neo4j.org/neo4j-enterprise-3.1.3-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.1.3-unix.tar.gz 3.1.4 http://dist.neo4j.org/neo4j-enterprise-3.1.4-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.1.4-unix.tar.gz 3.1.5 http://dist.neo4j.org/neo4j-enterprise-3.1.5-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.1.5-unix.tar.gz 3.1.6 http://dist.neo4j.org/neo4j-enterprise-3.1.6-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.1.6-unix.tar.gz 3.1.7 http://dist.neo4j.org/neo4j-enterprise-3.1.7-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.1.7-unix.tar.gz 3.1.8 http://dist.neo4j.org/neo4j-enterprise-3.1.8-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.1.8-unix.tar.gz 3.1.9 http://dist.neo4j.org/neo4j-enterprise-3.1.9-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.1.9-unix.tar.gz 3.2.12 http://dist.neo4j.org/neo4j-enterprise-3.2.12-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.2.12-unix.tar.gz 3.2.0 http://dist.neo4j.org/neo4j-enterprise-3.2.0-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.2.0-unix.tar.gz 3.2.1 http://dist.neo4j.org/neo4j-enterprise-3.2.1-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.2.1-unix.tar.gz 3.2.10 http://dist.neo4j.org/neo4j-enterprise-3.2.10-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.2.10-unix.tar.gz 3.2.11 http://dist.neo4j.org/neo4j-enterprise-3.2.11-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.2.11-unix.tar.gz 3.2.12 http://dist.neo4j.org/neo4j-enterprise-3.2.12-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.2.12-unix.tar.gz 3.2.2 http://dist.neo4j.org/neo4j-enterprise-3.2.2-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.2.2-unix.tar.gz 3.2.3 http://dist.neo4j.org/neo4j-enterprise-3.2.3-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.2.3-unix.tar.gz 3.2.5 http://dist.neo4j.org/neo4j-enterprise-3.2.5-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.2.5-unix.tar.gz 3.2.6 http://dist.neo4j.org/neo4j-enterprise-3.2.6-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.2.6-unix.tar.gz 3.2.7 http://dist.neo4j.org/neo4j-enterprise-3.2.7-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.2.7-unix.tar.gz 3.2.8 http://dist.neo4j.org/neo4j-enterprise-3.2.8-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.2.8-unix.tar.gz 3.2.9 http://dist.neo4j.org/neo4j-enterprise-3.2.9-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.2.9-unix.tar.gz 3.3.0 http://dist.neo4j.org/neo4j-enterprise-3.3.0-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.3.0-unix.tar.gz 3.3.1 http://dist.neo4j.org/neo4j-enterprise-3.3.1-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.3.1-unix.tar.gz 3.3.2 http://dist.neo4j.org/neo4j-enterprise-3.3.2-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.3.2-unix.tar.gz 3.3.3 http://dist.neo4j.org/neo4j-enterprise-3.3.3-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.3.3-unix.tar.gz 3.3.4 http://dist.neo4j.org/neo4j-enterprise-3.3.4-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.3.4-unix.tar.gz 3.3.5 http://dist.neo4j.org/neo4j-enterprise-3.3.5-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.3.5-unix.tar.gz 3.3.6 http://dist.neo4j.org/neo4j-enterprise-3.3.6-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.3.6-unix.tar.gz 3.4.0 http://dist.neo4j.org/neo4j-enterprise-3.4.0-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.4.0-unix.tar.gz 3.4.1 http://dist.neo4j.org/neo4j-enterprise-3.4.1-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.4.1-unix.tar.gz 3.4.4 http://dist.neo4j.org/neo4j-enterprise-3.4.4-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.4.4-unix.tar.gz 3.4.5 http://dist.neo4j.org/neo4j-enterprise-3.4.5-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.4.5-unix.tar.gz 3.4.6 http://dist.neo4j.org/neo4j-enterprise-3.4.6-unix.tar.gz http://dist.neo4j.org/neo4j-community-3.4.6-unix.tar.gz 参考资料 neo4j repo-info]]></content>
      <categories>
        <category>知识图谱</category>
      </categories>
      <tags>
        <tag>neo4j</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Neo4j社区版与企业版的区别]]></title>
    <url>%2F2018%2F08%2F28%2FNeo4j%E7%A4%BE%E5%8C%BA%E7%89%88%E4%B8%8E%E4%BC%81%E4%B8%9A%E7%89%88%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[容量：社区版最多支持 320 亿个节点、320 亿个关系和 640 亿个属性，而企业版没有这个限制； 并发：社区版只能部署成单实例，不能做集群。而企业版可以部署成高可用集群或因果集群，从而可以解决高并发量的问题； 容灾：由于企业版支持集群，部分实例出故障不会影响整个系统正常运行； 热备：社区版只支持冷备份，即需要停止服务后才能进行备份，而企业版支持热备，第一次是全量备份，后续是增量备份； 性能：社区版最多用到 4 个内核，而企业能用到全部内核，且对性能做了精心的优化； 支持：企业版客户能得到 5X10 电话支持（Neo4j 美国电话、邮件，微云数聚电话、微信、邮件）；]]></content>
      <categories>
        <category>知识图谱</category>
      </categories>
      <tags>
        <tag>neo4j</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[neo4j备份与恢复]]></title>
    <url>%2F2018%2F08%2F28%2Fneo4j%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D%2F</url>
    <content type="text"><![CDATA[tips 本文涉及到的备份和恢复命令均在社区版的neo4j中验证通过，执行命令前需要先关闭neo4j数据库 在实时应用程序中，我们需要定期备份应用程序数据库，以便在任何故障点恢复到某种工作状态 社区版neo4j不支持热备份，备份和恢复都需要停止neo4j的服务 企业版neo4j支持热备，第一次是全量备份，后续是增量备份 Neo4j的neo4j-admin工具提供 dump 和 load 功能，可使用neo4j-admin进行数据的备份和导出 备份1neo4j-admin dump --database=graph.db --to=/opt/neo4j/backup 恢复1neo4j-admin load --from=/opt/neo4j/backup --database=graph.db --force 注意：如果还原后数据库无法启动，则到 neo4j.conf中将如下属性前的#号去掉，使其生效]]></content>
      <categories>
        <category>知识图谱</category>
      </categories>
      <tags>
        <tag>neo4j</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac多版本python]]></title>
    <url>%2F2018%2F08%2F15%2FMac%E5%A4%9A%E7%89%88%E6%9C%ACpython%2F</url>
    <content type="text"><![CDATA[经常遇到这样的情况：系统自带的Python是2.x，自己需要Python 3.x，测试尝鲜；系统是2.6.x，开发环境是2.7.x由于Mac机器系统保护的原因，默认的Python中无法对PIP一些包升级，需要组建新的Python环境。此时需要在系统中安装多个Python，但又不能影响系统自带的Python，即需要实现Python的多版本共存。pyenv就是这样一个Python版本管理器。 安装Homebrew1/usr/bin/ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)" 1brew -v # 验证是否安装成功 安装pyenv1brew install pyenv 1pyenv -v # 验证是否安装成功 pyenv 常用命令 pyenv install –list # 查看可以安装的python版本 pyenv install x.x.x # 安装x.x.x版本 pyenv rehash # 安装之后记得一定要rehash pyenv version # 查看当前激活的版本 pyenv versions # 查看已安装的版本 pyenv global x.x.x # 将全局切换为x.x.x版本 pyenv local x.x.x # 将当前用户切换为x.x.x版本 tips 某些机器pyenv命令不生效的解决方法Add to your shell (~/.bashrc or ~/.zshrc) 12export PATH="/Users/username/.pyenv:$PATH"eval "$(pyenv init -)"]]></content>
      <tags>
        <tag>python</tag>
        <tag>pynev</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ZooKeeper简介]]></title>
    <url>%2F2018%2F08%2F15%2FZooKeeper%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[ZooKeeper是什么 Apache ZooKeeper是Apache软件基金会的一个软件项目，他为大型分布式计算提供开源的分布式配置服务、同步服务和命名注册，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。 ZooKeeper的架构通过冗余服务实现高可用性。因此，如果第一次无应答，客户端就可以询问另一台ZooKeeper主机。ZooKeeper节点将它们的数据存储于一个分层的命名空间，非常类似于一个文件系统或一个前缀树结构。客户端可以在节点读写，从而以这种方式拥有一个共享的配置服务，而更新是全局有序的。 客户端的读请求可以被集群中的任意一台机器处理，如果读请求在节点上注册了监听器，这个监听器也是由所连接的zookeeper机器来处理。对于写请求，这些请求会同时发给其他zookeeper机器并且达成一致后，请求才会返回成功。因此，随着zookeeper的集群机器增多，读请求的吞吐会提高但是写请求的吞吐会下降。 有序性是zookeeper中非常重要的一个特性，所有的更新都是全局有序的，每个更新都有一个唯一的时间戳，这个时间戳称为zxid（Zookeeper Transaction Id）。而读请求只会相对于更新有序，也就是读请求的返回结果中会带有这个zookeeper最新的zxid。 ZooKeeper提供了什么 文件系统 Zookeeper提供一个多层级的节点命名空间（节点称为znode）。与文件系统不同的是，这些节点都可以设置关联的数据，而文件系统中只有文件节点可以存放数据而目录节点不行。Zookeeper为了保证高吞吐和低延迟，在内存中维护了这个树状的目录结构，这种特性使得Zookeeper不能用于存放大量的数据，每个节点的存放数据上限为1M。 通知机制 client端会对某个znode建立一个watcher事件，当该znode发生变化时，这些client会收到zk的通知，然后client可以根据znode变化来做出业务上的改变等。 参考资料 官网 维基百科 百度百科]]></content>
      <categories>
        <category>ZooKeeper</category>
      </categories>
      <tags>
        <tag>ZooKeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lombok是什么]]></title>
    <url>%2F2018%2F08%2F14%2Flombok%E6%98%AF%E4%BB%80%E4%B9%88%2F</url>
    <content type="text"><![CDATA[简介Project Lombok is a java library that automatically plugs into your editor and build tools, spicing up your java.Never write another getter or equals method again. Early access to future java features such as val, and much more. Lombok是一个可以通过简单的注解形式来帮助我们简化消除一些必须有但显得很臃肿的Java代码的工具，通过使用对应的注解，可以在编译源码的时候生成对应的方法。 为什么使用lombok我们在开发过程中，通常都会定义大量的JavaBean，然后通过IDE去生成其属性的构造器、getter、setter、equals、hashcode、toString方法，当要增加属性或者对某个属性进行改变时，比如命名、类型等，都需要重新去生成上面提到的这些方法。这样重复的劳动没有任何意义，Lombok里面的注解可以轻松解决这些问题。 features val: final 像动态语言一样，声明一个fianl的变量。 var: 同JDK10 @Data：注解在类上，将类提供的所有属性都添加get、set方法，并添加、equals、canEquals、hashCode、toString方法 @Setter：注解在类上，为所有属性添加set方法、注解在属性上为该属性提供set方法 @Getter：注解在类上，为所有的属性添加get方法、注解在属性上为该属性提供get方法 @NotNull：在参数中使用时，如果调用时传了null值，就会抛出空指针异常 @Synchronized 用于方法，可以锁定指定的对象，如果不指定，则默认创建一个对象锁定 @Log作用于类，创建一个log属性 @Builder：使用builder模式创建对象 @NoArgsConstructor：创建一个无参构造函数 @AllArgsConstructor：创建一个全参构造函数 @ToString：创建一个toString方法 @Accessors(chain = true)使用链式设置属性，set方法返回的是this对象。 @RequiredArgsConstructor：创建对象, 例: 在class上添加@RequiredArgsConstructor(staticName = “of”)会创建生成一个静态方法 @UtilityClass:工具类 @ExtensionMethod:设置父类 @FieldDefaults：设置属性的使用范围，如private、public等，也可以设置属性是否被final修饰。 @Cleanup: 关闭流、连接点。 @EqualsAndHashCode：重写equals和hashcode方法。 @toString：创建toString方法。示例1234567891011121314@Setter@Getter@Accessors(chain = true)public class User &#123; private String id; private String name; private Integer age;&#125;public static void main(String[] args) &#123; //使用@Accessors(chain = true) User userChain = new User(); userChain.setId("1").setName("chain").setAge(1);&#125; 参考资料 官网 features lombok @Data github]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>lombok</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot 简介]]></title>
    <url>%2F2018%2F08%2F13%2FSpring-Boot-%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[Spring Boot 是一个轻量级框架，可以完成基于 Spring 的应用程序的大部分配置工作。在本教程中，将学习如何使用 Spring Boot 的 starter、特性和可执行 JAR 文件结构，快速创建能直接运行的基于 Spring 的应用程序。 Spring Boot 是什么？Spring Boot 的目的是提供一组工具，以便快速构建容易配置的 Spring 应用程序。Spring Boot 使您能轻松地创建独立的、生产级的、基于 Spring 且能直接运行的应用程序。基本上讲，这意味着您只需极少的配置，就可以快速获得一个正常运行的 Spring 应用程序，而且这些极少的配置采用了注释的形式。 关键点Starterstarter 是 Spring Boot 的一个重要组成部分，用于限制您需要执行的手动配置依赖项数量。starter 实际上是一组依赖项（比如 Maven POM），这些依赖项是 starter 所表示的应用程序类型所独有的。所有 starter 都使用以下命名约定：spring-boot-starter-XYZ，其中 XYZ 是想要构建的应用程序类型。下面是一些常用的starter及时说明 spring-boot-starter-web 用于构建 RESTful Web 服务，它使用 Spring MVC 和 Tomcat 作为嵌入式应用程序容器。 spring-boot-starter-jersey 是 spring-boot-starter-web 的一个替代，它使用 Apache Jersey 而不是 Spring MVC。 spring-boot-starter-jdbc 用于建立 JDBC 连接池。它基于 Tomcat 的 JDBC 连接池实现。 自动配置Spring Boot 会使用其 @EnableAutoConfiguration 注释自动配置您的应用程序。自动配置基于类路径中的 JAR 和定义 bean 的方式： Spring Boot 使用您在 CLASSPATH 中指定的 JAR，形成一个有关如何配置某个自动行为的观点。例如，如果类路径中有 H2 数据库 JAR，而且您没有配置任何其他 DataSource bean，您的应用程序会自动配置一个内存型数据库。 Spring Boot 使用您定义 bean 的方式来确定如何自动配置自身。例如，如果您为 JPA bean 添加了 @Entity 注释，Spring Boot 会自动配置 JPA，这样您就不需要 persistence.xml 文件。 运行Spring Boot 旨在帮助开发人员快速创建能直接运行的应用程序。为实现该目的，它会将应用程序及其依赖项包装在一个可执行 JAR 中。你可以以jar的形式直接运行你的程序，如：1java -jar PATH_TO_EXECUTABLE_JAR/executableJar.jar 优势|劣势优势 使用 Spring 项目引导页面可以在几秒构建一个项目 方便对外输出各种形式的服务，如 REST API、WebSocket、Web、Streaming、Tasks 非常简洁的安全策略集成 支持关系数据库和非关系数据库 支持运行期内嵌容器，如 Tomcat、Jetty 强大的开发包，支持热启动 自动管理依赖 自带应用监控 支持各种 IED，如 IntelliJ IDEA 、NetBeans 劣势集成度过高，没有一定的经验你根本就不知道springboot自动做了什么，对于新入门的程序员来说这是件很可怕的事情 参考资料： Spring Boot 基础 Spring Boot 优缺点]]></content>
      <categories>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[修改easy_install和pip为国内源]]></title>
    <url>%2F2018%2F08%2F13%2F%E4%BF%AE%E6%94%B9easy-install%E5%92%8Cpip%E4%B8%BA%E5%9B%BD%E5%86%85%E6%BA%90%2F</url>
    <content type="text"><![CDATA[因为一些众所周知的原因，easy_install和pip默认的源速度实在是太慢了，严重影响到正常的开发工作，因此需要将其默认源修改为国内的源，以下相关配置采用的是豆瓣的源，若使用其他的源请自行替换，本文的示例仅为Mac和Linux系统，其他版本的系统（Windows）请自行谷歌。 pip源修改123cd ~mkdir .pipvi .pip/pip.conf 在pip.conf中输入以下内容 123[global]index-url = http://pypi.douban.com/simpletrusted-host = pypi.douban.com easy_install源修改12cd ~vi .pydistutils.cfg 在.pydistutils.cfg输入以下内容 12[easy_install]index-url=http://pypi.douban.com/simple]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>pip</tag>
        <tag>easy_install</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos时钟同步]]></title>
    <url>%2F2018%2F08%2F10%2Fcentos%E6%97%B6%E9%92%9F%E5%90%8C%E6%AD%A5%2F</url>
    <content type="text"><![CDATA[在使用centos服务器的时候，有时会遇到时间不准确的问题，尤其是在搭建服务器集群的时候会因服务器时间不准确给集群服务器的搭建带来各种未知的问题，下面介绍一种centos服务器使用NTP与互联网上的时间服务器进行时钟同步的方法。 安装ntpdate1yum install -y ntpdate 将服务器的时区调整为东八区1cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 执行时钟同步动作1ntpdate us.pool.ntp.org 利用crontab，定时同步时钟1crontab -e #编辑当前用户的定时任务 10-59/10 * * * * /usr/sbin/ntpdate us.pool.ntp.org | logger -t NTP #设置为每十分钟同步一次 经过以上4步，centos服务器时间不准确的问题即可得到解决，当然你也可以在服务器集群上搭建一个时间服务器，其他的服务器与该服务器进行时钟同步即可。]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>时钟同步</tag>
        <tag>ntpdate</tag>
        <tag>crontab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos更换yum源]]></title>
    <url>%2F2018%2F08%2F10%2Fcentos%E6%9B%B4%E6%8D%A2yum%E6%BA%90%2F</url>
    <content type="text"><![CDATA[备份你的原始镜像源，以免后续出错后可以恢复1mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup 下载新的CentOS-Base.repo 到/etc/yum.repos.d/ centos5 1wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-5.repo centos6 1wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-6.repo centos7 1wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo 运行yum makecache生成缓存12yum clean allyum makecache]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>centos7</tag>
        <tag>centos6</tag>
        <tag>centos5</tag>
        <tag>yum源</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关系抽取简介]]></title>
    <url>%2F2018%2F08%2F09%2F%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[简介信息抽取的只要目的是将非结构化或半结构化描述的自然语言转换成结构化数据,关系抽取是其重要的子任务，主要负责从文本中识别出实体，抽取实体之间的语义关系。如“Bill Gates is the founder of MicrosoftInc”，这句话中包含两个实体（Bill Gates，MicrosoftInc），这对实体之间的关系为founder（创建）。 技术目前主流的关系抽取技术分为有监督式的学习方法、半监督式的学习方法和无监督式的学习方法 有监督式的学习方法将关系抽取任务当成分类问题，依据训练数据设计有效的特征，从而学习各种分类模型，在使用训练过的分类器预测关系；该方法存在的问题为需要大量的人工标注训练语料，而语料的准备工作通常会非常耗时耗力 半监督式的学习方法主要采用Bootstrapping进行关系抽取，对于要抽取的关系，首先人工设定若干种子实力，然后逐步迭代的从数据抽取关系对应的模版和更多的实例 无监督式的学习方法首先会假设已经存在相同语义关系的实体对和拥有相似的上下文关系；因此可以利用每个实体对去对应上下文信息来表示该实体对的语义关系，并对所有实体对的语义关系进行聚类。将上述三种学习方法进行对比，有监督的学习方法能够抽取更有效的特征，故其拥有较高的准备率和召回率。]]></content>
      <tags>
        <tag>非结构化</tag>
        <tag>半结构化</tag>
        <tag>关系抽取</tag>
        <tag>实体</tag>
        <tag>语义关系</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker安装MongoDB]]></title>
    <url>%2F2018%2F08%2F07%2FDocker%E5%AE%89%E8%A3%85MongoDB%2F</url>
    <content type="text"><![CDATA[拉取镜像1docker pull mongo:3.6.5 创建mongodb的工作目录并赋予权限12mkdir -p /data/mongochown 1000:1000 /data/mongo 新建并启动mongodb1docker run --name mongo -p 27017:27017 -v /data/mongo:/data/db -d mongo:3.6.5 --auth 新建mongodb管理员进入 mongo shell1docker exec -it mongo mongo admin 创建管理员1db.createUser(&#123; user: 'admin', pwd: '123456', roles: [ &#123; role: 'userAdminAnyDatabase', db: 'admin' &#125; ]&#125;);]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>docker</tag>
        <tag>mongodb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker常用命令]]></title>
    <url>%2F2018%2F08%2F07%2Fdocker%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[将待挂载的本地文件赋予权限12chcon -Rt svirt_sandbox_file_t /tmp #tmp为待挂载的文件chown 1000:1000 /tmp #tmp为待挂载的文件 搜索镜像 1docker search ubuntu:16.04 下载镜像 1docker pull ubuntu:16.04 列出本地的镜像 1docker images 删除本地某个镜像 1docker rmi 镜像ID # 通过第四部的命令可以查看镜像ID tip：删除镜像时需要先通知运行该镜像的容器新建并启动容器1docker run -t -i ubuntu:14.04 /bin/bash 上面的命令是启动一个 bash 终端，允许用户进行交互 停止运行中的容器1docker 容器ID stop 删除容器1docker rm 容器ID 提交对容器的修改1docker commit 容器ID learn/ping # learn/ping为容器tag]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker安装mysql]]></title>
    <url>%2F2018%2F08%2F06%2Fdocker%E5%AE%89%E8%A3%85mysql%2F</url>
    <content type="text"><![CDATA[拉取镜像1docker pull mysql:5.7.22 创建mysql的工作目录并赋予权限12sudo mkdir -p /data/mysqlsudo chown 1000:1000 /data/mysql 新建并启动mysql1docker run --name mysql -p 3306:3306 -v /data/mysql:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7.22 --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci 其他命令12docker exec -it mysql bash # 进入mysql容器docker stop mysql # 停止mysql]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>centos7</tag>
        <tag>mysql:5.7.22</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker安装jenkins]]></title>
    <url>%2F2018%2F08%2F06%2Fdocker%E5%AE%89%E8%A3%85jenkins%2F</url>
    <content type="text"><![CDATA[拉取长期支持版镜像1docker pull jenkins/jenkins:lts 创建jenkins的工作目录并赋予权限12sudo mkdir /data/jenkinssudo chown 1000:1000 /data/jenkins 新建并启动Jenkins1sudo docker run -p 8080:8080 -p 50000:50000 -v /data/jenkins:/var/jenkins_home --name jenkins -d jenkins/jenkins:lts 其他命令12345docker jenkins start # 启动jenkinsdocker jenkins stop # 停止jenkinsdocker jenkins restart # restart jenkinsdocker exec -it jenkins /bin/bash # 进入jenkins容器]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>centos7</tag>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos6.x安装docker]]></title>
    <url>%2F2018%2F08%2F06%2Fcentos6-x%E5%AE%89%E8%A3%85docker%2F</url>
    <content type="text"><![CDATA[tips1不建议在centos6系列的服务器上安装，会带来各种未知的问题 安装EPEL仓库1rpm -iUvh http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm 更新yum源1yum update -y 安装docker包1yum -y install docker-io 启动 docker 守护进程1service docker start 配置让 docker 服务随系统自动启动1sudo chkconfig docker on 验证 docker 是否安装成功1docker --version]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>centos6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos7安装docker]]></title>
    <url>%2F2018%2F08%2F06%2Fcentos7%E5%AE%89%E8%A3%85docker%2F</url>
    <content type="text"><![CDATA[更新系统1sudo yum -y update 添加 yum 仓库12345678sudo tee /etc/yum.repos.d/docker.repo &lt;&lt;-'EOF'[dockerrepo]name=Docker Repositorybaseurl=https://yum.dockerproject.org/repo/main/centos/$releasever/enabled=1gpgcheck=1gpgkey=https://yum.dockerproject.org/gpgEOF 安装docker包1sudo yum -y install docker-engine 启动 docker 守护进程1sudo systemctl start docker.service 配置让 docker 服务随系统自动启动1sudo chkconfig docker on 验证 docker 是否安装成功1sudo systemctl enable docker.service]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>centos7</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker安装neo4j]]></title>
    <url>%2F2018%2F08%2F06%2Fdocker%E5%AE%89%E8%A3%85neo4j%2F</url>
    <content type="text"><![CDATA[拉取镜像1docker pull neo4j:3.4 启动镜像1docker run --publish=7474:7474 --publish=7687:7687 --volume=/data/docker/neo4j/data:/data --volume=/data/docker/neo4j/logs:/logs]]></content>
      <categories>
        <category>知识图谱</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>neo4j</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos安装nginx]]></title>
    <url>%2F2018%2F08%2F05%2Fcentos%E5%AE%89%E8%A3%85nginx%2F</url>
    <content type="text"><![CDATA[在/etc/yum.repos.d/目录下创建nginx.repo12cd /etc/yum.repos.d/ vim nginx.repo 填写如下内容12345[nginx]name=nginx repobaseurl=http://nginx.org/packages/centos/$releasever/$basearch/gpgcheck=0enabled=1 保存，则会产生一个/etc/yum.repos.d/nginx.repo文件 安装nginx1yum install nginx -y 启动nginx1service nginx start 将nginx加入开机启动1chkconfig nginx on 开放防火墙12345iptables -I INPUT 5 -i eth0 -p tcp --dport 80 -m state --state NEW,ESTABLISHED -j ACCEPT service iptables save service iptables restart nginx常用命令123service nginx start # 启动service nginx stop # 停止service nginx restart # 重启]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker简介]]></title>
    <url>%2F2018%2F08%2F03%2Fdocker%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[概述Docker 是世界领先的软件容器平台。开发人员利用 Docker 可以消除协作编码时“在我的机器上可正常工作”的问题。运维人员利用 Docker 可以在隔离容器中并行运行和管理应用，获得更好的计算密度。企业利用 Docker 可以构建敏捷的软件交付管道，以更快的速度、更高的安全性和可靠的信誉为 Linux 和 Windows Server 应用发布新功能。其英文官网为https://www.docker.com ，中文官网为https://www.docker-cn.com 架构 Docker daemon（Docker守护进行）Docker daemon是一个运行在宿主机（DOCKER_HOST）的后台进程。可通过Docker客户端与之通信。 client（Docker客户端）Docker客户端是Docker的用户界面，它可以接受用户命令和配置标识，并于Docker daemon通信。 Images（Docker镜像）Docker镜像是一个只读模版，其包含创建Docker容器的说明。它与系统安装光盘类似—使用安装光盘可以安装系统，同理适用Docker镜像可以运行镜像中的程序。 Container（容器）容器是镜像的可运行实例。镜像和容器的关系类似于面向对象中，类和对象的关系。可通过Docker API或CLI命令来启停、移动、删除容器。 Registry（仓库）Docker Registry是一个集中存储与分发镜像的服务。构建完Docker镜像后，即可在当前宿主机器上运行。但如果需要在其他机器上运行这个镜像，就需要手动复制。此时可借助Docker Registry来避免镜像的手动复制。一个Docker Registry可包含多个Docker仓库，每个仓库可以包含多个镜像标签，每个标签对应一个Docker镜像。Docker Registry可以分为共有仓库和私有仓库。最常用的Docker Registry莫过于官方的Docker Hub，其也是默认的Docker Registry。Docker Hub上存放着大量的优秀镜像，可适用Docker命令下载和使用。]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[声明]]></title>
    <url>%2F2018%2F08%2F02%2F%E5%A3%B0%E6%98%8E%2F</url>
    <content type="text"><![CDATA[本站内所有的演示代码或示例代码均在Centos6.x、Centos7.x、Mac os中正常运行，其他版本的操作系统暂未支持。 本站内的相关文章内容均摘自于互联网和相关书籍，如有侵权请发邮件至junfengwang11@aliyun.com，将会在第一时间删除。]]></content>
      <categories>
        <category>声明</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>Mac os</tag>
      </tags>
  </entry>
</search>
