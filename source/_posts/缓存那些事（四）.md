---
title: 缓存那些事（四）
date: 2018-10-08 11:25:46
tags:
    - redis
    - 缓存
    - 缓存穿透
    - 缓存并发
categories: Java
---
**缓存那些事（四）- Redis优化建议**
<center>![](20160502211355.png)</center>
<center>图1</center>
图1是默认安装的redis在启动时给出的几条warning信息，已经告诉程序猿一些优化建议。
### 基本优化建议
#### 尽量使用短的key
当然在精简的同时，不要忘了key的“见名知意”。对于value有些也可精简，比如性别使用0、1
#### 避免使用`keys *`
`keys *`这个命令是`阻塞的`，即操作执行期间，其它任何命令在你的实例中都无法执行。当redis中key数据量小时到无所谓，数据量大就很糟糕了。所以我们应该避免去使用这个命令。可以去使用`SCAN`来代替。
#### 在存到Redis之前先把你的数据压缩下
redis为每种数据类型都提供了两种内部编码方式，在不同的情况下redis会自动调整合适的编码方式
#### 设置 key 有效期
我们应该尽可能的利用key有效期。比如一些临时数据（短信校验码），过了有效期Redis就会自动为你清除
#### 选择回收策略(maxmemory-policy)
当Redis的`实例空间`被`填满`了之后，将会尝试`回收一部分key`。根据你的使用方式，强烈建议使用`volatile-lru`（默认）策略——前提是你`对key已经设置了超时时间`。但如果你运行的是一些类似于`cache`的东西，并且没有对 key 设置超时机制，可以考虑使用`allkeys-lru`回收机制，[具体讲解查看](https://redis.io/topics/lru-cache#eviction-policies) ,`maxmemory-samples 3 `是说每次进行淘汰的时候 会随机抽取`3`个key 从里面淘汰最不经常使用的（默认选项）
> maxmemory-policy 六种方式 :
volatile-lru：只对设置了过期时间的key进行LRU（默认值）
allkeys-lru ： 是从所有key里 删除 不经常使用的key
volatile-random：随机删除即将过期key
allkeys-random：随机删除
volatile-ttl ： 删除即将过期的
noeviction ： 永不过期，返回错误
#### 使用`bit`位级别操作和`byte`字节级别操作来减少不必要的内存使用
    > bit位级别操作：`GETRANGE`, `SETRANGE`, `GETBIT` and `SETBIT`
    byte字节级别操作：`GETRANGE` and `SETRANGE`
#### 尽可能地使用hashes哈希存储
#### 当业务场景不需要数据持久化时，关闭所有的持久化方式可以获得最佳的性能
#### 想要一次添加多条数据的时候可以使用管道
#### 限制redis的内存大小
    > 64位系统不限制内存，32位系统默认最多使用3GB内存。数据量不可预估，并且内存也有限的话，尽量限制下redis使用的内存大小，这样可以避免redis使用`swap分区`或者出现`OOM`错误。（使用`swap分区`，性能较低，如果限制了内存，当到达指定内存之后就不能添加数据了，否则会报`OOM`错误。可以设置`maxmemory-policy`，内存不足时删除数据。）
* SLOWLOG [get/reset/len]
    > `slowlog-log-slower-than` 它决定要对执行时间大于多少微秒(`microsecond，1秒 = 1,000,000 微秒`)的命令进行记录。
`slowlog-max-len `它决定 `slowlog` 最多能保存多少条日志，当发现redis性能下降的时候可以查看下是哪些命令导致的。

### 优化实例分析
#### 管道（`Pipeline`）的使用
<center>![管道](20160427172349.png)</center>
<center>图2</center>
图2展示了多条数据时用和不用管到在连接方便的消耗对比。
redis的管道功能在命令行中没有，但是redis是支持管道的，在java的客户端(`jedis`)中是可以使用的。
**示例代码**
```java
/**
 * 不使用管道初始化1W条数据
 * @throws Exception
 */
@Test
public void NOTUsePipeline() throws Exception {
    Jedis jedis = JedisUtil.getJedis();
    long start_time = System.currentTimeMillis();
    for (int i = 0; i < 10000; i++) {
        jedis.set("aa_"+i, i+"");
    }
    System.out.println(System.currentTimeMillis()-start_time);
}

/**
 * 使用管道初始化1W条数据
 * @throws Exception
 */
@Test
public void usePipeline() throws Exception {
    Jedis jedis = JedisUtil.getJedis();

    long start_time = System.currentTimeMillis();
    Pipeline pipelined = jedis.pipelined();
    for (int i = 0; i < 10000; i++) {
        pipelined.set("cc_"+i, i+"");
    }
    pipelined.sync();//执行管道中的命令
    System.out.println(System.currentTimeMillis()-start_time);
}
```
#### Hash的使用
例如要存储一个用户信息对象数据，包含以下信息：
key为用户ID，value为用户对象（姓名，年龄，性别，生日等）如果用普通的key/value结构来存储，一般有以下2种存储方式:
* 将用户ID作为查找key,把其他信息封装成一个对象以`序列化`的方式存储
缺点：增加了`序列化`/`反序列化`的开销，引入复杂适应系统（`Complex adaptive system`，简称`CAS`）修改其中一项信息时，需要把整个对象取回，并且修改操作需要对并发进行保护。
* 用户信息对象有多少成员就存成多少个key-value对
虽然省去了序列化开销和并发问题，但是用户ID为重复存储。

Redis提供的`Hash`很好的解决了这个问题，提供了直接存取这个Map成员的接口;Key仍然是用户ID, value是一个Map，这个Map的key是成员的属性名，value是属性值。( 内部实现：`Redis Hashd`的`Value`内部有2种不同实现，Hash的成员比较少时Redis为了节省内存会采用类似`一维数组`的方式来`紧凑存储`，而不会采用真正的`HashMap`结构，对应的`value redisObject`的`encoding`为`zipmap`,当成员数量增大时会自动转成真正的`HashMap`,此时`encoding`为`ht` )。
#### 宿主服务器优化
本文开头的图1显示在启动时出现了三个warning，对于这三个warning可以采取redis宿主优化的方式解决
* 修改linux中`TCP`监听的`最大容纳`数量
在高并发环境下你需要一个高`backlog`值来避免慢客户端连接问题。注意Linux内核默默地将这个值减小到`/proc/sys/net/core/somaxconn`的值，所以需要确认增大`somaxconn`和`tcp_max_syn_backlog`两个值来达到想要的效果。
```shell
echo 511 > /proc/sys/net/core/somaxconn
```
**注意**：这个参数并不是限制redis的最大链接数。如果想限制redis的最大连接数需要修改`maxclients`
* 修改linux内核`内存分配策略`
redis在备份数据的时候，会`fork`出一个`子进程`，理论上child进程所占用的内存和parent是一样的，比如parent占用的内存为8G，这个时候也要同样分配8G的内存给child,如果内存无法负担，往往会造成redis服务器的down机或者`IO`负载过高，效率下降;所以内存分配策略应该设置为 1（表示内核允许分配所有的物理内存，而不管当前的内存状态如何）;内存分配策略有三种(可选值：0、1、2)
    * 0 表示内核将检查是否有足够的可用内存供应用进程使用；如果有足够的可用内存，内存申请允许；否则，内存申请失败，并把错误返回给应用进程
    * 1 不管需要多少内存，都允许申请
    * 2 只允许分配物理内存和交换内存的大小(交换内存一般是物理内存的一半)
* 关闭`Transparent Huge Pages`(`THP`)
THP会造成内存锁影响redis性能，建议关闭

>Transparent HugePages:用来提高内存管理的性能,Transparent Huge Pages在32位的RHEL 6中是不支持的,执行命令 `echo never > /sys/kernel/mm/ransparent_hugepage/enabled`,把这条命令添加到这个文件中`/etc/rc.local`。

**参考资料**
* [Redis--优化详解](https://blog.xiaoxiaomo.com/2016/05/02/Redis-%E4%BC%98%E5%8C%96%E8%AF%A6%E8%A7%A3/)
* [redis.cn](http://www.redis.cn/)
